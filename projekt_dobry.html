<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>projekt</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="projekt_dobry_files/libs/clipboard/clipboard.min.js"></script>
<script src="projekt_dobry_files/libs/quarto-html/quarto.js"></script>
<script src="projekt_dobry_files/libs/quarto-html/popper.min.js"></script>
<script src="projekt_dobry_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="projekt_dobry_files/libs/quarto-html/anchor.min.js"></script>
<link href="projekt_dobry_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="projekt_dobry_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="projekt_dobry_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="projekt_dobry_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="projekt_dobry_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#temat-i-cel-projektu" id="toc-temat-i-cel-projektu" class="nav-link active" data-scroll-target="#temat-i-cel-projektu"><span class="toc-section-number">1</span>  Temat i cel projektu</a>
  <ul class="collapse">
  <li><a href="#analiza-i-przewidywanie-ataku-serca" id="toc-analiza-i-przewidywanie-ataku-serca" class="nav-link" data-scroll-target="#analiza-i-przewidywanie-ataku-serca"><span class="toc-section-number">1.1</span>  <em>Analiza i przewidywanie ataku serca</em></a></li>
  </ul></li>
  <li><a href="#zbiór-danych-i-opis-zmiennych" id="toc-zbiór-danych-i-opis-zmiennych" class="nav-link" data-scroll-target="#zbiór-danych-i-opis-zmiennych"><span class="toc-section-number">2</span>  Zbiór danych i opis zmiennych</a>
  <ul class="collapse">
  <li><a href="#budowa-modeli-klasyfikacyjnych" id="toc-budowa-modeli-klasyfikacyjnych" class="nav-link" data-scroll-target="#budowa-modeli-klasyfikacyjnych"><span class="toc-section-number">2.1</span>  Budowa modeli klasyfikacyjnych</a>
  <ul class="collapse">
  <li><a href="#model-regresji-logistycznej" id="toc-model-regresji-logistycznej" class="nav-link" data-scroll-target="#model-regresji-logistycznej"><span class="toc-section-number">2.1.1</span>  Model regresji logistycznej</a></li>
  <li><a href="#drzewo-klasyfikacyjne" id="toc-drzewo-klasyfikacyjne" class="nav-link" data-scroll-target="#drzewo-klasyfikacyjne"><span class="toc-section-number">2.1.2</span>  Drzewo klasyfikacyjne</a></li>
  <li><a href="#las-losowy" id="toc-las-losowy" class="nav-link" data-scroll-target="#las-losowy"><span class="toc-section-number">2.1.3</span>  Las losowy</a></li>
  <li><a href="#model-k-nn" id="toc-model-k-nn" class="nav-link" data-scroll-target="#model-k-nn"><span class="toc-section-number">2.1.4</span>  Model k-NN</a></li>
  <li><a href="#model-lda" id="toc-model-lda" class="nav-link" data-scroll-target="#model-lda"><span class="toc-section-number">2.1.5</span>  Model LDA</a></li>
  <li><a href="#model-qda" id="toc-model-qda" class="nav-link" data-scroll-target="#model-qda"><span class="toc-section-number">2.1.6</span>  Model QDA</a></li>
  <li><a href="#model-mda" id="toc-model-mda" class="nav-link" data-scroll-target="#model-mda"><span class="toc-section-number">2.1.7</span>  Model MDA</a></li>
  <li><a href="#model-rf" id="toc-model-rf" class="nav-link" data-scroll-target="#model-rf"><span class="toc-section-number">2.1.8</span>  Model RF</a></li>
  <li><a href="#model-gbm" id="toc-model-gbm" class="nav-link" data-scroll-target="#model-gbm"><span class="toc-section-number">2.1.9</span>  Model GBM</a></li>
  </ul></li>
  <li><a href="#wykresy" id="toc-wykresy" class="nav-link" data-scroll-target="#wykresy"><span class="toc-section-number">2.2</span>  Wykresy</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">projekt</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell" data-massage="false">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
✔ ggplot2 3.4.0     ✔ purrr   0.3.5
✔ tibble  3.1.8     ✔ dplyr   1.1.0
✔ tidyr   1.2.1     ✔ stringr 1.5.0
✔ readr   2.1.3     ✔ forcats 0.5.2
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rattle)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Ładowanie wymaganego pakietu: bitops
Rattle: A free graphical interface for data science with R.
Version 5.5.1 Copyright (c) 2006-2021 Togaware Pty Ltd.
Type 'rattle()' to shake, rattle, and roll your data.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Ładowanie wymaganego pakietu: lattice

Dołączanie pakietu: 'caret'

Następujący obiekt został zakryty z 'package:purrr':

    lift</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mice)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Dołączanie pakietu: 'mice'

Następujący obiekt został zakryty z 'package:stats':

    filter

Następujące obiekty zostały zakryte z 'package:base':

    cbind, rbind</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(purrr)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──
✔ broom        1.0.2     ✔ rsample      1.1.1
✔ dials        1.1.0     ✔ tune         1.0.1
✔ infer        1.0.4     ✔ workflows    1.1.3
✔ modeldata    1.1.0     ✔ workflowsets 1.0.0
✔ parsnip      1.0.4     ✔ yardstick    1.1.0
✔ recipes      1.0.5     
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ scales::discard()        masks purrr::discard()
✖ mice::filter()           masks dplyr::filter(), stats::filter()
✖ recipes::fixed()         masks stringr::fixed()
✖ dplyr::lag()             masks stats::lag()
✖ caret::lift()            masks purrr::lift()
✖ yardstick::precision()   masks caret::precision()
✖ yardstick::recall()      masks caret::recall()
✖ yardstick::sensitivity() masks caret::sensitivity()
✖ yardstick::spec()        masks readr::spec()
✖ yardstick::specificity() masks caret::specificity()
✖ recipes::step()          masks stats::step()
• Dig deeper into tidy modeling with R at https://www.tmwr.org</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Dołączanie pakietu: 'rpart'

Następujący obiekt został zakryty z 'package:dials':

    prune</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="temat-i-cel-projektu" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Temat i cel projektu</h1>
<section id="analiza-i-przewidywanie-ataku-serca" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="analiza-i-przewidywanie-ataku-serca"><span class="header-section-number">1.1</span> <em>Analiza i przewidywanie ataku serca</em></h2>
<p><img src="heartanalysis.jpg" class="img-fluid" width="669"></p>
<p><strong>Celem projektu</strong> jest zbudowanie optymalnego modelu klasyfikacyjnego (klasyfikacja binarna), który na podstawie danych pacjenta będzie w stanie przewidzieć ryzyko wystąpienia ataku serca. Analiza ataku serca pozwala na ustalenie i potwierdzenie diagnozy. Poprzez badanie objawów, wyników testów laboratoryjnych oraz obrazowych (np. elektrokardiogram - EKG), lekarze mogą dokonać trafnej diagnozy ataku serca. Jest to istotne dla dalszego leczenia i planowania opieki medycznej.</p>
</section>
</section>
<section id="zbiór-danych-i-opis-zmiennych" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Zbiór danych i opis zmiennych</h1>
<p>Zbiór danych pochodzi z 2021r. ,zawiera 14 zmiennych oraz 303 obserwacje.</p>
<p><code>age</code> - wiek pacjenta,</p>
<p><code>sex</code> - płeć pacjenta (1-mężczyzna, 0-kobieta),</p>
<p><code>cp</code> - typ bólu w klatce piersiowej (0-typowy (wywołany atakiem kaszlu), 1-nietypowy, 2-niepowiązany z kaszlem, 3-bezobjawowy,</p>
<p><code>trtbps</code> - spoczynkowe ciśnienie krwi (w mm Hg),</p>
<p><code>chol</code> - cholesterol w mg/dl pobrany przez czujnik BMI,</p>
<p><code>fbs</code> - cukier we krwi na czczo &gt; 120 mg/dl (1-tak, 0-nie),</p>
<p><code>restecg</code> - spoczynkowy wynik elektrokardiograficzny (0 = prawidłowy, 1 = posiadanie nieprawidłowości w układzie ST-T (uniesienie lub obniżenie odcinka ST), 2 = przerost lewej komory serca),</p>
<p><code>thalach</code> - osiągnięte maksymalne tętno,</p>
<p><code>exng</code> - dusznica bolesna (1-tak, 0-nie),</p>
<p><code>oldpeak</code> - stosunek depresji ST wywołana przez wysiłek fizyczny do spoczynku,</p>
<p><code>slp</code> - ocena skosu odcinka ST na elektrokardiogramie EKG,</p>
<p><code>caa</code> - liczba tętnic wieńcowych serca,</p>
<p><code>thall</code> - wynik testu na stres Thalium (0-bardzo niski poziom stresu, 1-normalny/przeciętny poziom, 2-ponadprzeciętnie zestresowany, 3-często wysoki poziom stresu),</p>
<p><code>output</code> -prawdopodobieństwo/ryzyko wystąpienia ataku serca (0- niska szansa na atak serca, 1-wysoka szansa na atak serca)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>heart <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"C:/Users/Dell/Desktop/3 rok/VI SEMESTR/eksploracja/heart.csv"</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>heart<span class="sc">$</span>output <span class="ot">&lt;-</span> <span class="fu">factor</span>(heart<span class="sc">$</span>output)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>heart<span class="sc">$</span>sex <span class="ot">&lt;-</span> <span class="fu">factor</span>(heart<span class="sc">$</span>sex)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>heart<span class="sc">$</span>cp <span class="ot">&lt;-</span> <span class="fu">factor</span>(heart<span class="sc">$</span>cp)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>heart<span class="sc">$</span>fbs <span class="ot">&lt;-</span> <span class="fu">factor</span>(heart<span class="sc">$</span>fbs)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>heart<span class="sc">$</span>restecg <span class="ot">&lt;-</span> <span class="fu">factor</span>(heart<span class="sc">$</span>restecg)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>heart<span class="sc">$</span>exng <span class="ot">&lt;-</span> <span class="fu">factor</span>(heart<span class="sc">$</span>exng)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>heart<span class="sc">$</span>slp <span class="ot">&lt;-</span> <span class="fu">factor</span>(heart<span class="sc">$</span>slp)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>heart<span class="sc">$</span>caa <span class="ot">&lt;-</span> <span class="fu">factor</span>(heart<span class="sc">$</span>caa)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>heart<span class="sc">$</span>thall <span class="ot">&lt;-</span> <span class="fu">factor</span>(heart<span class="sc">$</span>thall)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#podział na zbiór uczący i testowy</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2023</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>indeks <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y=</span>heart<span class="sc">$</span>output, <span class="at">p =</span> <span class="fl">0.7</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>dt_ucz <span class="ot">&lt;-</span> heart[indeks,]</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>dt_test <span class="ot">&lt;-</span> heart[<span class="sc">-</span>indeks,]</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(dt_ucz<span class="sc">$</span>output)[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="st">"low"</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(dt_ucz<span class="sc">$</span>output)[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="st">"high"</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(dt_test<span class="sc">$</span>output)[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="st">"low"</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(dt_test<span class="sc">$</span>output)[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="st">"high"</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dt_ucz)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  age sex cp trtbps chol fbs restecg thalachh exng oldpeak slp caa thall output
2  37   1  2    130  250   0       1      187    0     3.5   0   0     2   high
3  41   0  1    130  204   0       0      172    0     1.4   2   0     2   high
4  56   1  1    120  236   0       1      178    0     0.8   2   0     2   high
5  57   0  0    120  354   0       1      163    1     0.6   2   0     2   high
6  57   1  0    140  192   0       1      148    0     0.4   1   0     1   high
7  56   0  1    140  294   0       0      153    0     1.3   1   0     2   high</code></pre>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dt_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   age sex cp trtbps chol fbs restecg thalachh exng oldpeak slp caa thall
1   63   1  3    145  233   1       0      150    0     2.3   0   0     1
9   52   1  2    172  199   1       1      162    0     0.5   2   0     3
13  49   1  1    130  266   0       1      171    0     0.6   2   0     2
17  58   0  2    120  340   0       1      172    0     0.0   2   0     2
18  66   0  3    150  226   0       1      114    0     2.6   0   0     2
19  43   1  0    150  247   0       1      171    0     1.5   2   0     2
   output
1    high
9    high
13   high
17   high
18   high
19   high</code></pre>
</div>
</div>
<p>Za kontrolę uczenia maszynowego w modelach będzie odpowiadać 5-krotna walidacja krzyżowa 5-krotnie powtórzona.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"repeatedcv"</span>,<span class="at">number =</span> <span class="dv">5</span>, <span class="at">repeats =</span> <span class="dv">5</span>,</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>                          <span class="at">summaryFunction=</span>twoClassSummary,</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">classProbs =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="budowa-modeli-klasyfikacyjnych" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="budowa-modeli-klasyfikacyjnych"><span class="header-section-number">2.1</span> Budowa modeli klasyfikacyjnych</h2>
<section id="model-regresji-logistycznej" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="model-regresji-logistycznej"><span class="header-section-number">2.1.1</span> Model regresji logistycznej</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>mod.log<span class="ot">&lt;-</span> <span class="fu">train</span>(output<span class="sc">~</span>., </span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">data=</span>dt_ucz,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">method =</span> <span class="st">"glm"</span>,</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">trControl =</span> control,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>                <span class="at">metric =</span> <span class="st">"ROC"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
predykcja z dopasowania z niedoborem rang może być myląca

Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
predykcja z dopasowania z niedoborem rang może być myląca

Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
predykcja z dopasowania z niedoborem rang może być myląca

Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
predykcja z dopasowania z niedoborem rang może być myląca</code></pre>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>mod.log</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generalized Linear Model 

213 samples
 13 predictor
  2 classes: 'low', 'high' 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 5 times) 
Summary of sample sizes: 170, 171, 170, 170, 171, 170, ... 
Resampling results:

  ROC        Sens       Spec    
  0.8796728  0.7868421  0.847971</code></pre>
</div>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>pred.log <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod.log, <span class="at">newdata =</span> dt_test,<span class="at">type=</span><span class="st">"prob"</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>pred.log.class <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod.log, <span class="at">newdata =</span> dt_test)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(pred.log.class, dt_test<span class="sc">$</span>output)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction low high
      low   31    5
      high  10   44
                                        
               Accuracy : 0.8333        
                 95% CI : (0.74, 0.9036)
    No Information Rate : 0.5444        
    P-Value [Acc &gt; NIR] : 7.067e-09     
                                        
                  Kappa : 0.6606        
                                        
 Mcnemar's Test P-Value : 0.3017        
                                        
            Sensitivity : 0.7561        
            Specificity : 0.8980        
         Pos Pred Value : 0.8611        
         Neg Pred Value : 0.8148        
             Prevalence : 0.4556        
         Detection Rate : 0.3444        
   Detection Prevalence : 0.4000        
      Balanced Accuracy : 0.8270        
                                        
       'Positive' Class : low           
                                        </code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(pred.log.class, dt_test<span class="sc">$</span>output,<span class="at">positive=</span><span class="st">"high"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction low high
      low   31    5
      high  10   44
                                        
               Accuracy : 0.8333        
                 95% CI : (0.74, 0.9036)
    No Information Rate : 0.5444        
    P-Value [Acc &gt; NIR] : 7.067e-09     
                                        
                  Kappa : 0.6606        
                                        
 Mcnemar's Test P-Value : 0.3017        
                                        
            Sensitivity : 0.8980        
            Specificity : 0.7561        
         Pos Pred Value : 0.8148        
         Neg Pred Value : 0.8611        
             Prevalence : 0.5444        
         Detection Rate : 0.4889        
   Detection Prevalence : 0.6000        
      Balanced Accuracy : 0.8270        
                                        
       'Positive' Class : high          
                                        </code></pre>
</div>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>tab <span class="ot">&lt;-</span> <span class="fu">table</span>(pred.log.class, dt_test<span class="sc">$</span>output)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>tab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              
pred.log.class low high
          low   31    5
          high  10   44</code></pre>
</div>
</div>
<p>Ze zbudowanego modelu wynika ….</p>
</section>
<section id="drzewo-klasyfikacyjne" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="drzewo-klasyfikacyjne"><span class="header-section-number">2.1.2</span> Drzewo klasyfikacyjne</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>drzewo.rpart <span class="ot">&lt;-</span> <span class="fu">rpart</span>(output<span class="sc">~</span>., </span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> dt_ucz)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>drzewo.rpart</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>n= 213 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

 1) root 213 97 high (0.45539906 0.54460094)  
   2) thall=0,1,3 97 23 low (0.76288660 0.23711340)  
     4) cp=0 63  6 low (0.90476190 0.09523810) *
     5) cp=1,2,3 34 17 low (0.50000000 0.50000000)  
      10) slp=1 22  7 low (0.68181818 0.31818182)  
        20) caa=1,3 11  1 low (0.90909091 0.09090909) *
        21) caa=0,4 11  5 high (0.45454545 0.54545455) *
      11) slp=0,2 12  2 high (0.16666667 0.83333333) *
   3) thall=2 116 23 high (0.19827586 0.80172414)  
     6) caa=1,2,3 29 14 high (0.48275862 0.51724138)  
      12) cp=0,3 14  3 low (0.78571429 0.21428571) *
      13) cp=1,2 15  3 high (0.20000000 0.80000000) *
     7) caa=0,4 87  9 high (0.10344828 0.89655172) *</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">#aby ocenic jakie sa zdolnosci generalizacyjne modelu,sprawdzamy macierz klasyfikacji</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>pred.drzewo.rpart<span class="ot">&lt;-</span><span class="fu">predict</span>(drzewo.rpart, <span class="at">newdata=</span>dt_test, <span class="at">type=</span><span class="st">"class"</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>pred.drzewo.rpart</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   1    9   13   17   18   19   20   23   30   34   35   39   40   44   47   54 
high high high high high high  low high high high  low high high high high high 
  58   62   63   74   76   78   83   84   86   89   92   93   98   99  101  104 
high high high high high high high high high high  low high  low high  low high 
 106  107  111  114  117  124  128  130  133  139  141  147  150  155  157  160 
high  low high  low high high high high high  low high high high high high high 
 164  166  167  172  173  176  178  179  180  181  184  187  190  200  212  226 
high  low  low high high  low high  low  low  low  low  low  low  low  low  low 
 228  230  234  243  245  246  249  252  253  256  257  258  262  265  266  269 
 low high  low  low  low  low high  low  low  low  low  low  low  low  low  low 
 272  273  276  281  287  288  291  293  295  301 
 low high  low  low  low high  low  low  low  low 
Levels: low high</code></pre>
</div>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>tab.rpart<span class="ot">&lt;-</span><span class="fu">table</span>(<span class="at">predykcja=</span>pred.drzewo.rpart, <span class="at">obserwacja=</span>dt_test<span class="sc">$</span>output)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>tab.rpart</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         obserwacja
predykcja low high
     low   34    8
     high   7   41</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sum</span>(<span class="fu">diag</span>(tab.rpart))<span class="sc">/</span><span class="fu">sum</span>(tab.rpart)<span class="sc">*</span><span class="dv">100</span>,<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 83.3</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(drzewo.rpart)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="projekt_dobry_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">#sprawdzamy czy nie jest konieczne przyciecie naszego drzewa</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">printcp</span>(drzewo.rpart)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Classification tree:
rpart(formula = output ~ ., data = dt_ucz)

Variables actually used in tree construction:
[1] caa   cp    slp   thall

Root node error: 97/213 = 0.4554

n= 213 

        CP nsplit rel error  xerror     xstd
1 0.525773      0   1.00000 1.00000 0.074930
2 0.041237      1   0.47423 0.48454 0.062394
3 0.010309      5   0.30928 0.47423 0.061912
4 0.010000      6   0.29897 0.50515 0.063323</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(drzewo.rpart)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="projekt_dobry_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co">#przyciete drzewo</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>drzewo.p<span class="ot">&lt;-</span><span class="fu">prune</span>(drzewo.rpart, <span class="at">cp =</span> <span class="fl">0.041237</span> )</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(drzewo.p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Call:
rpart(formula = output ~ ., data = dt_ucz)
  n= 213 

          CP nsplit rel error    xerror       xstd
1 0.52577320      0 1.0000000 1.0000000 0.07492958
2 0.04123711      1 0.4742268 0.4845361 0.06239380
3 0.04123700      5 0.3092784 0.4742268 0.06191211

Variable importance
   thall      caa thalachh  oldpeak       cp      sex     exng      slp 
      27       13       13       12       10        9        8        5 
  trtbps      age 
       2        2 

Node number 1: 213 observations,    complexity param=0.5257732
  predicted class=high  expected loss=0.4553991  P(node) =1
    class counts:    97   116
   probabilities: 0.455 0.545 
  left son=2 (97 obs) right son=3 (116 obs)
  Primary splits:
      thall   splits as  LLRL,      improve=33.68049, (0 missing)
      caa     splits as  RLLLR,     improve=28.08877, (0 missing)
      cp      splits as  LRRR,      improve=25.46676, (0 missing)
      oldpeak &lt; 0.75  to the right, improve=20.34223, (0 missing)
      exng    splits as  RL,        improve=19.96176, (0 missing)
  Surrogate splits:
      thalachh &lt; 150.5 to the left,  agree=0.709, adj=0.361, (0 split)
      caa      splits as  RLLLR,     agree=0.676, adj=0.289, (0 split)
      exng     splits as  RL,        agree=0.671, adj=0.278, (0 split)
      oldpeak  &lt; 0.95  to the right, agree=0.671, adj=0.278, (0 split)
      sex      splits as  RL,        agree=0.667, adj=0.268, (0 split)

Node number 2: 97 observations,    complexity param=0.04123711
  predicted class=low   expected loss=0.2371134  P(node) =0.4553991
    class counts:    74    23
   probabilities: 0.763 0.237 
  left son=4 (63 obs) right son=5 (34 obs)
  Primary splits:
      cp      splits as  LRRR,      improve=7.235641, (0 missing)
      oldpeak &lt; 0.7   to the right, improve=7.093761, (0 missing)
      caa     splits as  RLLLR,     improve=6.169976, (0 missing)
      exng    splits as  RL,        improve=3.358940, (0 missing)
      chol    &lt; 240.5 to the right, improve=3.069766, (0 missing)
  Surrogate splits:
      age      &lt; 66.5  to the left,  agree=0.691, adj=0.118, (0 split)
      thalachh &lt; 172   to the left,  agree=0.680, adj=0.088, (0 split)
      exng     splits as  RL,        agree=0.680, adj=0.088, (0 split)
      oldpeak  &lt; 0.7   to the right, agree=0.680, adj=0.088, (0 split)
      trtbps   &lt; 107.5 to the right, agree=0.670, adj=0.059, (0 split)

Node number 3: 116 observations,    complexity param=0.04123711
  predicted class=high  expected loss=0.1982759  P(node) =0.5446009
    class counts:    23    93
   probabilities: 0.198 0.802 
  left son=6 (29 obs) right son=7 (87 obs)
  Primary splits:
      caa      splits as  RLLLR,     improve=6.258621, (0 missing)
      cp       splits as  LRRL,      improve=5.015674, (0 missing)
      oldpeak  &lt; 2.2   to the right, improve=4.281180, (0 missing)
      exng     splits as  RL,        improve=3.961015, (0 missing)
      thalachh &lt; 155.5 to the left,  improve=3.876785, (0 missing)
  Surrogate splits:
      age     &lt; 62.5  to the right, agree=0.793, adj=0.172, (0 split)
      oldpeak &lt; 3.55  to the right, agree=0.759, adj=0.034, (0 split)

Node number 4: 63 observations
  predicted class=low   expected loss=0.0952381  P(node) =0.2957746
    class counts:    57     6
   probabilities: 0.905 0.095 

Node number 5: 34 observations,    complexity param=0.04123711
  predicted class=low   expected loss=0.5  P(node) =0.1596244
    class counts:    17    17
   probabilities: 0.500 0.500 
  left son=10 (22 obs) right son=11 (12 obs)
  Primary splits:
      slp      splits as  RLR,       improve=4.121212, (0 missing)
      caa      splits as  RLLLR,     improve=2.922807, (0 missing)
      thalachh &lt; 143   to the left,  improve=2.318182, (0 missing)
      oldpeak  &lt; 1.95  to the right, improve=2.248677, (0 missing)
      chol     &lt; 228   to the right, improve=1.556777, (0 missing)
  Surrogate splits:
      thalachh &lt; 164   to the left,  agree=0.765, adj=0.333, (0 split)
      oldpeak  &lt; 0.35  to the right, agree=0.765, adj=0.333, (0 split)
      trtbps   &lt; 103   to the right, agree=0.706, adj=0.167, (0 split)
      sex      splits as  RL,        agree=0.676, adj=0.083, (0 split)
      chol     &lt; 201   to the right, agree=0.676, adj=0.083, (0 split)

Node number 6: 29 observations,    complexity param=0.04123711
  predicted class=high  expected loss=0.4827586  P(node) =0.1361502
    class counts:    14    15
   probabilities: 0.483 0.517 
  left son=12 (14 obs) right son=13 (15 obs)
  Primary splits:
      cp      splits as  LRRL,      improve=4.968473, (0 missing)
      slp     splits as  LLR,       improve=3.987809, (0 missing)
      sex     splits as  RL,        improve=3.867374, (0 missing)
      restecg splits as  LR-,       improve=3.604981, (0 missing)
      oldpeak &lt; 0.85  to the right, improve=3.072232, (0 missing)
  Surrogate splits:
      oldpeak  &lt; 0.85  to the right, agree=0.793, adj=0.571, (0 split)
      slp      splits as  LLR,       agree=0.759, adj=0.500, (0 split)
      sex      splits as  RL,        agree=0.690, adj=0.357, (0 split)
      trtbps   &lt; 129   to the left,  agree=0.690, adj=0.357, (0 split)
      thalachh &lt; 125.5 to the left,  agree=0.690, adj=0.357, (0 split)

Node number 7: 87 observations
  predicted class=high  expected loss=0.1034483  P(node) =0.4084507
    class counts:     9    78
   probabilities: 0.103 0.897 

Node number 10: 22 observations
  predicted class=low   expected loss=0.3181818  P(node) =0.1032864
    class counts:    15     7
   probabilities: 0.682 0.318 

Node number 11: 12 observations
  predicted class=high  expected loss=0.1666667  P(node) =0.05633803
    class counts:     2    10
   probabilities: 0.167 0.833 

Node number 12: 14 observations
  predicted class=low   expected loss=0.2142857  P(node) =0.0657277
    class counts:    11     3
   probabilities: 0.786 0.214 

Node number 13: 15 observations
  predicted class=high  expected loss=0.2  P(node) =0.07042254
    class counts:     3    12
   probabilities: 0.200 0.800 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(drzewo.p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="projekt_dobry_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="las-losowy" class="level3" data-number="2.1.3">
<h3 data-number="2.1.3" class="anchored" data-anchor-id="las-losowy"><span class="header-section-number">2.1.3</span> Las losowy</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>randomForest 4.7-1.1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Type rfNews() to see new features/changes/bug fixes.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Dołączanie pakietu: 'randomForest'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Następujący obiekt został zakryty z 'package:rattle':

    importance</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Następujący obiekt został zakryty z 'package:dplyr':

    combine</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Następujący obiekt został zakryty z 'package:ggplot2':

    margin</code></pre>
</div>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(output<span class="sc">~</span>., <span class="at">data =</span> dt_ucz)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>rf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
 randomForest(formula = output ~ ., data = dt_ucz) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 3

        OOB estimate of  error rate: 17.84%
Confusion matrix:
     low high class.error
low   79   18   0.1855670
high  20   96   0.1724138</code></pre>
</div>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>pred.las <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf, <span class="at">newdata =</span> dt_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co">#cm &lt;- pred |&gt; conf_mat(truth = output, estimate = pred) </span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="co">#summary(cm)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="model-k-nn" class="level3" data-number="2.1.4">
<h3 data-number="2.1.4" class="anchored" data-anchor-id="model-k-nn"><span class="header-section-number">2.1.4</span> Model k-NN</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>grid<span class="ot">&lt;-</span><span class="fu">expand.grid</span>(<span class="at">k=</span><span class="dv">2</span><span class="sc">:</span><span class="dv">30</span>)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>mod.knn<span class="ot">&lt;-</span> <span class="fu">train</span>(output<span class="sc">~</span>.,</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">data=</span>dt_ucz,</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>                <span class="at">method=</span><span class="st">"knn"</span>,</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>                <span class="at">trControl=</span>control,</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>                <span class="at">tuneGrid=</span>grid,</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>                <span class="at">metric=</span><span class="st">"ROC"</span>)</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>mod.knn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>k-Nearest Neighbors 

213 samples
 13 predictor
  2 classes: 'low', 'high' 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 5 times) 
Summary of sample sizes: 170, 171, 171, 170, 170, 171, ... 
Resampling results across tuning parameters:

  k   ROC        Sens       Spec     
   2  0.6124079  0.5195789  0.6311594
   3  0.6434981  0.5096842  0.6864493
   4  0.6596450  0.5154737  0.6914493
   5  0.6589839  0.5322105  0.7038406
   6  0.6558998  0.5407368  0.7023188
   7  0.6571137  0.5347368  0.7038406
   8  0.6576952  0.5180000  0.6880435
   9  0.6586062  0.5283158  0.6847101
  10  0.6617786  0.5301053  0.6935507
  11  0.6726449  0.5427368  0.7054348
  12  0.6805142  0.5551579  0.6917391
  13  0.6945549  0.5735789  0.7086232
  14  0.7051722  0.5650526  0.7069565
  15  0.7104863  0.5698947  0.7311594
  16  0.7136990  0.5730526  0.7122464
  17  0.7191904  0.5634737  0.7415217
  18  0.7228735  0.5776842  0.7431159
  19  0.7241713  0.5593684  0.7467391
  20  0.7252099  0.5486316  0.7415942
  21  0.7269915  0.5405263  0.7521014
  22  0.7288660  0.5116842  0.7417391
  23  0.7322619  0.5223158  0.7536232
  24  0.7334898  0.5194737  0.7518841
  25  0.7341541  0.5237895  0.7553623
  26  0.7373819  0.5093684  0.7605797
  27  0.7406281  0.5237895  0.7658696
  28  0.7414852  0.5255789  0.7728261
  29  0.7431150  0.5157895  0.7814493
  30  0.7387315  0.5136842  0.7727536

ROC was used to select the optimal model using the largest value.
The final value used for the model was k = 29.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>pred.knn<span class="ot">&lt;-</span><span class="fu">predict</span>(mod.knn, <span class="at">newdata=</span>dt_test, <span class="at">type=</span><span class="st">"prob"</span>)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>pred.knn.class<span class="ot">&lt;-</span><span class="fu">predict</span>(mod.knn, <span class="at">newdata=</span>dt_test)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(pred.knn.class, dt_test<span class="sc">$</span>output, <span class="at">positive=</span><span class="st">"high"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction low high
      low   23   13
      high  18   36
                                         
               Accuracy : 0.6556         
                 95% CI : (0.548, 0.7526)
    No Information Rate : 0.5444         
    P-Value [Acc &gt; NIR] : 0.02136        
                                         
                  Kappa : 0.2986         
                                         
 Mcnemar's Test P-Value : 0.47250        
                                         
            Sensitivity : 0.7347         
            Specificity : 0.5610         
         Pos Pred Value : 0.6667         
         Neg Pred Value : 0.6389         
             Prevalence : 0.5444         
         Detection Rate : 0.4000         
   Detection Prevalence : 0.6000         
      Balanced Accuracy : 0.6478         
                                         
       'Positive' Class : high           
                                         </code></pre>
</div>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co">#najsłabszy model dotychczas</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="model-lda" class="level3" data-number="2.1.5">
<h3 data-number="2.1.5" class="anchored" data-anchor-id="model-lda"><span class="header-section-number">2.1.5</span> Model LDA</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>mod.lda<span class="ot">&lt;-</span><span class="fu">train</span>(output<span class="sc">~</span>.,</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>               <span class="at">data=</span>dt_ucz,</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">method=</span><span class="st">"lda"</span>,</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">trControl=</span>control,</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">metric=</span><span class="st">"ROC"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in lda.default(x, grouping, ...): zmienne są współliniowe</code></pre>
</div>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>mod.lda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear Discriminant Analysis 

213 samples
 13 predictor
  2 classes: 'low', 'high' 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 5 times) 
Summary of sample sizes: 171, 170, 171, 170, 170, 171, ... 
Resampling results:

  ROC        Sens       Spec    
  0.9044851  0.7910526  0.868913</code></pre>
</div>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>pred.lda<span class="ot">&lt;-</span><span class="fu">predict</span>(mod.lda, <span class="at">newdata=</span>dt_test, <span class="at">type=</span><span class="st">"prob"</span>)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>pred.lda.class<span class="ot">&lt;-</span><span class="fu">predict</span>(mod.lda, <span class="at">newdata=</span>dt_test)</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(pred.lda.class, dt_test<span class="sc">$</span>output, <span class="at">positive=</span><span class="st">"high"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction low high
      low   32    5
      high   9   44
                                          
               Accuracy : 0.8444          
                 95% CI : (0.7528, 0.9123)
    No Information Rate : 0.5444          
    P-Value [Acc &gt; NIR] : 1.629e-09       
                                          
                  Kappa : 0.6839          
                                          
 Mcnemar's Test P-Value : 0.4227          
                                          
            Sensitivity : 0.8980          
            Specificity : 0.7805          
         Pos Pred Value : 0.8302          
         Neg Pred Value : 0.8649          
             Prevalence : 0.5444          
         Detection Rate : 0.4889          
   Detection Prevalence : 0.5889          
      Balanced Accuracy : 0.8392          
                                          
       'Positive' Class : high            
                                          </code></pre>
</div>
</div>
</section>
<section id="model-qda" class="level3" data-number="2.1.6">
<h3 data-number="2.1.6" class="anchored" data-anchor-id="model-qda"><span class="header-section-number">2.1.6</span> Model QDA</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>mod.qda<span class="ot">&lt;-</span><span class="fu">train</span>(output<span class="sc">~</span>.,</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>               <span class="at">data=</span>dt_ucz,</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">method=</span><span class="st">"stepQDA"</span>,</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">trControl=</span>control,</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">metric=</span><span class="st">"ROC"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.78856;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.86 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.78954;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.81 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.78399;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        1.02 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>170 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.78235;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.83 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>169 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.77574;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.86 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.77712;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.88 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.76634;  in: "thall3";  variables (1): thall3 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.84 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.77745;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.83 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>169 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.81103;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
        0.0         0.0         0.8 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>170 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.78824;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.76 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>169 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.76985;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
        0.0         0.0         0.8 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.77092;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        1.06 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>170 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.81176;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.84 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.7781;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
        0.0         0.0         0.8 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.7902;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.75 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.78333;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.82 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.75458;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.76 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.76013;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.86 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>170 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.8;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
        0.0         0.0         0.8 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>169 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.82243;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.77 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>170 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.79412;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.85 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>170 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.76471;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.89 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>170 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.78235;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
        0.0         0.0         0.8 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.79575;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.78 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>171 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.78431;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.83 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> `stepwise classification', using 10-fold cross-validated correctness rate of method qda'.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>213 observations of 22 variables in 2 classes; direction: both</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>stop criterion: improvement less than 5%.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>correctness rate: 0.78463;  in: "thall2";  variables (1): thall2 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step

Warning in cv.rate(vars = c(model, tryvar), data = data, grouping = grouping, :
error(s) in modeling/prediction step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 hr.elapsed min.elapsed sec.elapsed 
       0.00        0.00        0.83 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb250"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb250-1"><a href="#cb250-1" aria-hidden="true" tabindex="-1"></a>mod.qda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Quadratic Discriminant Analysis with Stepwise Feature Selection 

213 samples
 13 predictor
  2 classes: 'low', 'high' 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 5 times) 
Summary of sample sizes: 171, 171, 171, 170, 169, 171, ... 
Resampling results:

  ROC        Sens       Spec     
  0.7808204  0.7596842  0.8019565

Tuning parameter 'maxvar' was held constant at a value of Inf
Tuning
 parameter 'direction' was held constant at a value of both</code></pre>
</div>
<div class="sourceCode cell-code" id="cb252"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb252-1"><a href="#cb252-1" aria-hidden="true" tabindex="-1"></a>pred.qda<span class="ot">&lt;-</span><span class="fu">predict</span>(mod.qda, <span class="at">newdata=</span>dt_test, <span class="at">type=</span><span class="st">"prob"</span>)</span>
<span id="cb252-2"><a href="#cb252-2" aria-hidden="true" tabindex="-1"></a>pred.qda.class<span class="ot">&lt;-</span><span class="fu">predict</span>(mod.qda, <span class="at">newdata=</span>dt_test)</span>
<span id="cb252-3"><a href="#cb252-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb252-4"><a href="#cb252-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(pred.qda.class, dt_test<span class="sc">$</span>output, <span class="at">positive=</span><span class="st">"high"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction low high
      low   28   12
      high  13   37
                                          
               Accuracy : 0.7222          
                 95% CI : (0.6178, 0.8115)
    No Information Rate : 0.5444          
    P-Value [Acc &gt; NIR] : 0.0004108       
                                          
                  Kappa : 0.4389          
                                          
 Mcnemar's Test P-Value : 1.0000000       
                                          
            Sensitivity : 0.7551          
            Specificity : 0.6829          
         Pos Pred Value : 0.7400          
         Neg Pred Value : 0.7000          
             Prevalence : 0.5444          
         Detection Rate : 0.4111          
   Detection Prevalence : 0.5556          
      Balanced Accuracy : 0.7190          
                                          
       'Positive' Class : high            
                                          </code></pre>
</div>
</div>
</section>
<section id="model-mda" class="level3" data-number="2.1.7">
<h3 data-number="2.1.7" class="anchored" data-anchor-id="model-mda"><span class="header-section-number">2.1.7</span> Model MDA</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb254"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb254-1"><a href="#cb254-1" aria-hidden="true" tabindex="-1"></a>grid<span class="ot">&lt;-</span><span class="fu">expand.grid</span>(<span class="at">subclasses=</span><span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>)</span>
<span id="cb254-2"><a href="#cb254-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb254-3"><a href="#cb254-3" aria-hidden="true" tabindex="-1"></a>mod.mda<span class="ot">&lt;-</span><span class="fu">train</span>(output<span class="sc">~</span>.,</span>
<span id="cb254-4"><a href="#cb254-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">data=</span>dt_ucz,</span>
<span id="cb254-5"><a href="#cb254-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">method=</span><span class="st">"mda"</span>,</span>
<span id="cb254-6"><a href="#cb254-6" aria-hidden="true" tabindex="-1"></a>               <span class="at">trControl=</span>control,</span>
<span id="cb254-7"><a href="#cb254-7" aria-hidden="true" tabindex="-1"></a>               <span class="at">tuneGrid=</span>grid,</span>
<span id="cb254-8"><a href="#cb254-8" aria-hidden="true" tabindex="-1"></a>               <span class="at">metric=</span><span class="st">"ROC"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold5.Rep2: subclasses=2 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold5.Rep2: subclasses=3 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold5.Rep2: subclasses=4 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold5.Rep2: subclasses=5 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold1.Rep3: subclasses=2 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold1.Rep3: subclasses=3 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold1.Rep3: subclasses=4 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold1.Rep3: subclasses=5 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold4.Rep3: subclasses=2 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold4.Rep3: subclasses=3 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold4.Rep3: subclasses=4 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold4.Rep3: subclasses=5 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold4.Rep4: subclasses=2 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold4.Rep4: subclasses=3 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold4.Rep4: subclasses=4 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold4.Rep4: subclasses=5 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold5.Rep4: subclasses=2 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold5.Rep4: subclasses=3 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold5.Rep4: subclasses=4 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: predictions failed for Fold5.Rep4: subclasses=5 Error in maxdist[l] &lt;- x[l, i] : 
  wartości NA nie są dozwolone w przypisaniach indeksowych</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :
There were missing values in resampled performance measures.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb276"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb276-1"><a href="#cb276-1" aria-hidden="true" tabindex="-1"></a>mod.mda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mixture Discriminant Analysis 

213 samples
 13 predictor
  2 classes: 'low', 'high' 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 5 times) 
Summary of sample sizes: 170, 170, 170, 171, 171, 170, ... 
Resampling results across tuning parameters:

  subclasses  ROC        Sens       Spec     
  2           0.8900248  0.7885526  0.8707428
  3           0.8794270  0.7676316  0.8468297
  4           0.8691752  0.7573684  0.8557065
  5           0.8458972  0.7497368  0.8209239

ROC was used to select the optimal model using the largest value.
The final value used for the model was subclasses = 2.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb278"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb278-1"><a href="#cb278-1" aria-hidden="true" tabindex="-1"></a>pred.mda<span class="ot">&lt;-</span><span class="fu">predict</span>(mod.mda, <span class="at">newdata=</span>dt_test, <span class="at">type=</span><span class="st">"prob"</span>)</span>
<span id="cb278-2"><a href="#cb278-2" aria-hidden="true" tabindex="-1"></a>pred.mda.class<span class="ot">&lt;-</span><span class="fu">predict</span>(mod.mda, <span class="at">newdata=</span>dt_test)</span>
<span id="cb278-3"><a href="#cb278-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb278-4"><a href="#cb278-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(pred.mda.class, dt_test<span class="sc">$</span>output, <span class="at">positive=</span><span class="st">"high"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction low high
      low   33    6
      high   8   43
                                          
               Accuracy : 0.8444          
                 95% CI : (0.7528, 0.9123)
    No Information Rate : 0.5444          
    P-Value [Acc &gt; NIR] : 1.629e-09       
                                          
                  Kappa : 0.6852          
                                          
 Mcnemar's Test P-Value : 0.7893          
                                          
            Sensitivity : 0.8776          
            Specificity : 0.8049          
         Pos Pred Value : 0.8431          
         Neg Pred Value : 0.8462          
             Prevalence : 0.5444          
         Detection Rate : 0.4778          
   Detection Prevalence : 0.5667          
      Balanced Accuracy : 0.8412          
                                          
       'Positive' Class : high            
                                          </code></pre>
</div>
</div>
</section>
<section id="model-rf" class="level3" data-number="2.1.8">
<h3 data-number="2.1.8" class="anchored" data-anchor-id="model-rf"><span class="header-section-number">2.1.8</span> Model RF</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb280"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb280-1"><a href="#cb280-1" aria-hidden="true" tabindex="-1"></a>grid<span class="ot">&lt;-</span><span class="fu">expand.grid</span>(<span class="at">mtry=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">7</span>,<span class="dv">10</span>,<span class="dv">15</span>,<span class="dv">20</span>))</span>
<span id="cb280-2"><a href="#cb280-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb280-3"><a href="#cb280-3" aria-hidden="true" tabindex="-1"></a>mod.rf<span class="ot">&lt;-</span><span class="fu">train</span>(output<span class="sc">~</span>.,</span>
<span id="cb280-4"><a href="#cb280-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">data=</span>dt_ucz,</span>
<span id="cb280-5"><a href="#cb280-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">method=</span><span class="st">"rf"</span>,</span>
<span id="cb280-6"><a href="#cb280-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">trControl=</span>control,</span>
<span id="cb280-7"><a href="#cb280-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">tuneGrid=</span>grid,</span>
<span id="cb280-8"><a href="#cb280-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">metric=</span><span class="st">"ROC"</span>)</span>
<span id="cb280-9"><a href="#cb280-9" aria-hidden="true" tabindex="-1"></a>mod.rf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest 

213 samples
 13 predictor
  2 classes: 'low', 'high' 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 5 times) 
Summary of sample sizes: 170, 171, 170, 171, 170, 170, ... 
Resampling results across tuning parameters:

  mtry  ROC        Sens       Spec     
   5    0.8719395  0.7326316  0.8197101
   7    0.8680260  0.7263158  0.8110145
  10    0.8616404  0.7200000  0.8058696
  15    0.8555383  0.7238947  0.8076087
  20    0.8530726  0.7240000  0.8057971

ROC was used to select the optimal model using the largest value.
The final value used for the model was mtry = 5.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb282"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb282-1"><a href="#cb282-1" aria-hidden="true" tabindex="-1"></a>pred.rf<span class="ot">&lt;-</span><span class="fu">predict</span>(mod.rf, <span class="at">newdata=</span>dt_test, <span class="at">type=</span><span class="st">"prob"</span>)</span>
<span id="cb282-2"><a href="#cb282-2" aria-hidden="true" tabindex="-1"></a>pred.rf.class<span class="ot">&lt;-</span><span class="fu">predict</span>(mod.rf, <span class="at">newdata=</span>dt_test)</span>
<span id="cb282-3"><a href="#cb282-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb282-4"><a href="#cb282-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(pred.rf.class, dt_test<span class="sc">$</span>output, <span class="at">positive=</span><span class="st">"high"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction low high
      low   30    9
      high  11   40
                                          
               Accuracy : 0.7778          
                 95% CI : (0.6779, 0.8587)
    No Information Rate : 0.5444          
    P-Value [Acc &gt; NIR] : 3.689e-06       
                                          
                  Kappa : 0.5502          
                                          
 Mcnemar's Test P-Value : 0.8231          
                                          
            Sensitivity : 0.8163          
            Specificity : 0.7317          
         Pos Pred Value : 0.7843          
         Neg Pred Value : 0.7692          
             Prevalence : 0.5444          
         Detection Rate : 0.4444          
   Detection Prevalence : 0.5667          
      Balanced Accuracy : 0.7740          
                                          
       'Positive' Class : high            
                                          </code></pre>
</div>
</div>
</section>
<section id="model-gbm" class="level3" data-number="2.1.9">
<h3 data-number="2.1.9" class="anchored" data-anchor-id="model-gbm"><span class="header-section-number">2.1.9</span> Model GBM</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb284"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb284-1"><a href="#cb284-1" aria-hidden="true" tabindex="-1"></a>grid<span class="ot">&lt;-</span><span class="fu">expand.grid</span>(<span class="at">n.trees=</span><span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">500</span>,<span class="dv">1000</span>),</span>
<span id="cb284-2"><a href="#cb284-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">interaction.depth=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,</span>
<span id="cb284-3"><a href="#cb284-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">shrinkage=</span><span class="fl">0.1</span>,</span>
<span id="cb284-4"><a href="#cb284-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">n.minobsinnode=</span><span class="dv">10</span>)</span>
<span id="cb284-5"><a href="#cb284-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb284-6"><a href="#cb284-6" aria-hidden="true" tabindex="-1"></a>mod.gbm<span class="ot">&lt;-</span><span class="fu">train</span>(output<span class="sc">~</span>.,</span>
<span id="cb284-7"><a href="#cb284-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">data=</span>dt_ucz,</span>
<span id="cb284-8"><a href="#cb284-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">method=</span><span class="st">"gbm"</span>,</span>
<span id="cb284-9"><a href="#cb284-9" aria-hidden="true" tabindex="-1"></a>              <span class="at">trControl=</span>control,</span>
<span id="cb284-10"><a href="#cb284-10" aria-hidden="true" tabindex="-1"></a>              <span class="at">tuneGrid=</span>grid,</span>
<span id="cb284-11"><a href="#cb284-11" aria-hidden="true" tabindex="-1"></a>              <span class="at">metric=</span><span class="st">"ROC"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3242             nan     0.1000    0.0272
     2        1.2819             nan     0.1000    0.0174
     3        1.2357             nan     0.1000    0.0200
     4        1.1969             nan     0.1000    0.0157
     5        1.1659             nan     0.1000    0.0115
     6        1.1476             nan     0.1000    0.0010
     7        1.1236             nan     0.1000    0.0093
     8        1.1000             nan     0.1000    0.0091
     9        1.0797             nan     0.1000    0.0063
    10        1.0658             nan     0.1000   -0.0062
    20        0.9168             nan     0.1000    0.0036
    40        0.7760             nan     0.1000   -0.0008
    60        0.6826             nan     0.1000   -0.0046
    80        0.6267             nan     0.1000   -0.0015
   100        0.5896             nan     0.1000   -0.0023
   120        0.5595             nan     0.1000   -0.0011
   140        0.5277             nan     0.1000   -0.0015
   160        0.5027             nan     0.1000   -0.0023
   180        0.4844             nan     0.1000   -0.0024
   200        0.4721             nan     0.1000   -0.0063
   220        0.4581             nan     0.1000   -0.0044
   240        0.4409             nan     0.1000   -0.0015
   260        0.4285             nan     0.1000   -0.0031
   280        0.4145             nan     0.1000   -0.0013
   300        0.3987             nan     0.1000   -0.0029
   320        0.3899             nan     0.1000   -0.0006
   340        0.3801             nan     0.1000   -0.0015
   360        0.3672             nan     0.1000   -0.0022
   380        0.3563             nan     0.1000   -0.0024
   400        0.3462             nan     0.1000   -0.0030
   420        0.3389             nan     0.1000   -0.0027
   440        0.3300             nan     0.1000   -0.0042
   460        0.3232             nan     0.1000   -0.0015
   480        0.3144             nan     0.1000   -0.0021
   500        0.3081             nan     0.1000   -0.0019
   520        0.2989             nan     0.1000   -0.0037
   540        0.2891             nan     0.1000   -0.0017
   560        0.2822             nan     0.1000   -0.0047
   580        0.2746             nan     0.1000   -0.0007
   600        0.2690             nan     0.1000   -0.0015
   620        0.2618             nan     0.1000   -0.0016
   640        0.2572             nan     0.1000   -0.0015
   660        0.2534             nan     0.1000   -0.0015
   680        0.2476             nan     0.1000   -0.0017
   700        0.2431             nan     0.1000   -0.0019
   720        0.2371             nan     0.1000   -0.0024
   740        0.2345             nan     0.1000   -0.0017
   760        0.2296             nan     0.1000   -0.0009
   780        0.2243             nan     0.1000   -0.0023
   800        0.2212             nan     0.1000   -0.0010
   820        0.2181             nan     0.1000   -0.0005
   840        0.2121             nan     0.1000   -0.0010
   860        0.2086             nan     0.1000   -0.0018
   880        0.2046             nan     0.1000   -0.0018
   900        0.1986             nan     0.1000   -0.0026
   920        0.1950             nan     0.1000   -0.0015
   940        0.1911             nan     0.1000   -0.0008
   960        0.1870             nan     0.1000   -0.0009
   980        0.1836             nan     0.1000   -0.0011
  1000        0.1777             nan     0.1000   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3036             nan     0.1000    0.0365
     2        1.2505             nan     0.1000    0.0212
     3        1.2012             nan     0.1000    0.0212
     4        1.1612             nan     0.1000    0.0086
     5        1.1164             nan     0.1000    0.0159
     6        1.0774             nan     0.1000    0.0139
     7        1.0501             nan     0.1000    0.0102
     8        1.0246             nan     0.1000    0.0081
     9        1.0002             nan     0.1000    0.0087
    10        0.9745             nan     0.1000    0.0102
    20        0.7867             nan     0.1000   -0.0005
    40        0.6268             nan     0.1000   -0.0014
    60        0.5448             nan     0.1000   -0.0027
    80        0.4823             nan     0.1000   -0.0056
   100        0.4205             nan     0.1000   -0.0014
   120        0.3784             nan     0.1000   -0.0039
   140        0.3366             nan     0.1000   -0.0006
   160        0.3103             nan     0.1000   -0.0028
   180        0.2802             nan     0.1000   -0.0016
   200        0.2537             nan     0.1000   -0.0051
   220        0.2327             nan     0.1000   -0.0040
   240        0.2163             nan     0.1000   -0.0009
   260        0.2010             nan     0.1000   -0.0008
   280        0.1827             nan     0.1000   -0.0013
   300        0.1693             nan     0.1000   -0.0015
   320        0.1588             nan     0.1000   -0.0019
   340        0.1464             nan     0.1000   -0.0006
   360        0.1334             nan     0.1000   -0.0012
   380        0.1230             nan     0.1000   -0.0009
   400        0.1147             nan     0.1000   -0.0013
   420        0.1071             nan     0.1000   -0.0006
   440        0.0987             nan     0.1000   -0.0009
   460        0.0920             nan     0.1000   -0.0000
   480        0.0861             nan     0.1000   -0.0011
   500        0.0810             nan     0.1000   -0.0009
   520        0.0758             nan     0.1000   -0.0010
   540        0.0706             nan     0.1000   -0.0005
   560        0.0667             nan     0.1000   -0.0008
   580        0.0627             nan     0.1000   -0.0002
   600        0.0571             nan     0.1000   -0.0007
   620        0.0537             nan     0.1000   -0.0006
   640        0.0497             nan     0.1000   -0.0008
   660        0.0460             nan     0.1000   -0.0005
   680        0.0433             nan     0.1000   -0.0004
   700        0.0410             nan     0.1000   -0.0003
   720        0.0385             nan     0.1000   -0.0005
   740        0.0352             nan     0.1000   -0.0001
   760        0.0328             nan     0.1000   -0.0005
   780        0.0311             nan     0.1000   -0.0004
   800        0.0293             nan     0.1000   -0.0002
   820        0.0272             nan     0.1000   -0.0003
   840        0.0257             nan     0.1000   -0.0003
   860        0.0244             nan     0.1000   -0.0002
   880        0.0233             nan     0.1000   -0.0001
   900        0.0217             nan     0.1000   -0.0002
   920        0.0207             nan     0.1000   -0.0001
   940        0.0194             nan     0.1000   -0.0001
   960        0.0182             nan     0.1000   -0.0001
   980        0.0169             nan     0.1000   -0.0001
  1000        0.0158             nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3000             nan     0.1000    0.0304
     2        1.2442             nan     0.1000    0.0270
     3        1.1897             nan     0.1000    0.0212
     4        1.1412             nan     0.1000    0.0133
     5        1.1034             nan     0.1000    0.0037
     6        1.0688             nan     0.1000    0.0118
     7        1.0273             nan     0.1000    0.0183
     8        0.9954             nan     0.1000    0.0059
     9        0.9606             nan     0.1000    0.0133
    10        0.9210             nan     0.1000    0.0140
    20        0.7397             nan     0.1000    0.0020
    40        0.5493             nan     0.1000   -0.0048
    60        0.4446             nan     0.1000   -0.0026
    80        0.3696             nan     0.1000   -0.0026
   100        0.3157             nan     0.1000   -0.0010
   120        0.2652             nan     0.1000   -0.0029
   140        0.2288             nan     0.1000   -0.0018
   160        0.2003             nan     0.1000   -0.0031
   180        0.1724             nan     0.1000   -0.0024
   200        0.1501             nan     0.1000   -0.0017
   220        0.1297             nan     0.1000   -0.0004
   240        0.1155             nan     0.1000   -0.0013
   260        0.1017             nan     0.1000   -0.0012
   280        0.0900             nan     0.1000   -0.0015
   300        0.0816             nan     0.1000   -0.0014
   320        0.0711             nan     0.1000   -0.0010
   340        0.0636             nan     0.1000   -0.0005
   360        0.0569             nan     0.1000   -0.0008
   380        0.0500             nan     0.1000   -0.0004
   400        0.0442             nan     0.1000   -0.0002
   420        0.0401             nan     0.1000   -0.0005
   440        0.0366             nan     0.1000   -0.0005
   460        0.0333             nan     0.1000   -0.0004
   480        0.0298             nan     0.1000   -0.0003
   500        0.0264             nan     0.1000   -0.0003
   520        0.0247             nan     0.1000   -0.0005
   540        0.0215             nan     0.1000   -0.0004
   560        0.0196             nan     0.1000   -0.0004
   580        0.0178             nan     0.1000   -0.0002
   600        0.0160             nan     0.1000   -0.0002
   620        0.0145             nan     0.1000   -0.0002
   640        0.0131             nan     0.1000   -0.0001
   660        0.0118             nan     0.1000   -0.0002
   680        0.0106             nan     0.1000   -0.0000
   700        0.0094             nan     0.1000   -0.0000
   720        0.0083             nan     0.1000   -0.0000
   740        0.0075             nan     0.1000   -0.0002
   760        0.0070             nan     0.1000   -0.0001
   780        0.0063             nan     0.1000   -0.0001
   800        0.0056             nan     0.1000   -0.0001
   820        0.0049             nan     0.1000   -0.0001
   840        0.0044             nan     0.1000   -0.0000
   860        0.0039             nan     0.1000   -0.0000
   880        0.0035             nan     0.1000   -0.0001
   900        0.0032             nan     0.1000   -0.0000
   920        0.0029             nan     0.1000   -0.0000
   940        0.0025             nan     0.1000   -0.0000
   960        0.0022             nan     0.1000   -0.0000
   980        0.0020             nan     0.1000   -0.0000
  1000        0.0019             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3139             nan     0.1000    0.0305
     2        1.2713             nan     0.1000    0.0229
     3        1.2304             nan     0.1000    0.0185
     4        1.2040             nan     0.1000    0.0119
     5        1.1750             nan     0.1000    0.0099
     6        1.1374             nan     0.1000    0.0124
     7        1.1095             nan     0.1000    0.0094
     8        1.0834             nan     0.1000    0.0088
     9        1.0642             nan     0.1000    0.0081
    10        1.0532             nan     0.1000   -0.0013
    20        0.9178             nan     0.1000    0.0030
    40        0.7904             nan     0.1000   -0.0021
    60        0.7097             nan     0.1000   -0.0031
    80        0.6572             nan     0.1000   -0.0034
   100        0.6228             nan     0.1000   -0.0012
   120        0.5917             nan     0.1000   -0.0021
   140        0.5736             nan     0.1000   -0.0043
   160        0.5472             nan     0.1000   -0.0025
   180        0.5267             nan     0.1000   -0.0018
   200        0.5115             nan     0.1000   -0.0040
   220        0.4910             nan     0.1000   -0.0056
   240        0.4718             nan     0.1000   -0.0016
   260        0.4551             nan     0.1000   -0.0021
   280        0.4386             nan     0.1000   -0.0031
   300        0.4290             nan     0.1000   -0.0028
   320        0.4173             nan     0.1000   -0.0016
   340        0.4050             nan     0.1000   -0.0024
   360        0.3956             nan     0.1000   -0.0009
   380        0.3883             nan     0.1000   -0.0015
   400        0.3770             nan     0.1000   -0.0025
   420        0.3701             nan     0.1000   -0.0030
   440        0.3596             nan     0.1000   -0.0024
   460        0.3522             nan     0.1000   -0.0042
   480        0.3433             nan     0.1000   -0.0054
   500        0.3335             nan     0.1000   -0.0011
   520        0.3269             nan     0.1000   -0.0031
   540        0.3204             nan     0.1000   -0.0032
   560        0.3163             nan     0.1000   -0.0025
   580        0.3132             nan     0.1000   -0.0024
   600        0.3024             nan     0.1000   -0.0022
   620        0.2963             nan     0.1000   -0.0018
   640        0.2916             nan     0.1000   -0.0026
   660        0.2823             nan     0.1000   -0.0012
   680        0.2779             nan     0.1000   -0.0026
   700        0.2731             nan     0.1000   -0.0022
   720        0.2677             nan     0.1000   -0.0020
   740        0.2619             nan     0.1000   -0.0014
   760        0.2580             nan     0.1000   -0.0017
   780        0.2536             nan     0.1000   -0.0007
   800        0.2509             nan     0.1000   -0.0009
   820        0.2467             nan     0.1000   -0.0033
   840        0.2428             nan     0.1000   -0.0013
   860        0.2408             nan     0.1000   -0.0021
   880        0.2360             nan     0.1000   -0.0021
   900        0.2323             nan     0.1000   -0.0017
   920        0.2287             nan     0.1000   -0.0005
   940        0.2251             nan     0.1000   -0.0003
   960        0.2194             nan     0.1000   -0.0011
   980        0.2155             nan     0.1000   -0.0022
  1000        0.2135             nan     0.1000   -0.0018

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3041             nan     0.1000    0.0352
     2        1.2565             nan     0.1000    0.0227
     3        1.1951             nan     0.1000    0.0248
     4        1.1462             nan     0.1000    0.0169
     5        1.1084             nan     0.1000    0.0123
     6        1.0732             nan     0.1000    0.0146
     7        1.0395             nan     0.1000    0.0134
     8        1.0175             nan     0.1000    0.0029
     9        0.9987             nan     0.1000    0.0058
    10        0.9739             nan     0.1000    0.0082
    20        0.8273             nan     0.1000    0.0019
    40        0.6640             nan     0.1000   -0.0030
    60        0.5669             nan     0.1000   -0.0017
    80        0.5058             nan     0.1000   -0.0069
   100        0.4649             nan     0.1000   -0.0040
   120        0.4247             nan     0.1000   -0.0029
   140        0.3863             nan     0.1000   -0.0017
   160        0.3528             nan     0.1000   -0.0021
   180        0.3277             nan     0.1000   -0.0030
   200        0.3001             nan     0.1000   -0.0012
   220        0.2800             nan     0.1000   -0.0019
   240        0.2631             nan     0.1000   -0.0024
   260        0.2452             nan     0.1000   -0.0024
   280        0.2227             nan     0.1000   -0.0009
   300        0.2051             nan     0.1000   -0.0020
   320        0.1926             nan     0.1000   -0.0024
   340        0.1789             nan     0.1000   -0.0010
   360        0.1670             nan     0.1000   -0.0019
   380        0.1567             nan     0.1000   -0.0014
   400        0.1453             nan     0.1000   -0.0016
   420        0.1341             nan     0.1000   -0.0017
   440        0.1282             nan     0.1000   -0.0012
   460        0.1169             nan     0.1000   -0.0008
   480        0.1080             nan     0.1000   -0.0014
   500        0.1000             nan     0.1000   -0.0006
   520        0.0946             nan     0.1000   -0.0010
   540        0.0874             nan     0.1000   -0.0011
   560        0.0830             nan     0.1000   -0.0005
   580        0.0772             nan     0.1000   -0.0006
   600        0.0723             nan     0.1000   -0.0007
   620        0.0681             nan     0.1000   -0.0003
   640        0.0640             nan     0.1000   -0.0005
   660        0.0609             nan     0.1000   -0.0009
   680        0.0582             nan     0.1000   -0.0007
   700        0.0541             nan     0.1000   -0.0004
   720        0.0509             nan     0.1000   -0.0004
   740        0.0468             nan     0.1000   -0.0002
   760        0.0436             nan     0.1000   -0.0003
   780        0.0413             nan     0.1000   -0.0002
   800        0.0380             nan     0.1000   -0.0002
   820        0.0354             nan     0.1000   -0.0003
   840        0.0340             nan     0.1000   -0.0001
   860        0.0327             nan     0.1000   -0.0003
   880        0.0309             nan     0.1000   -0.0002
   900        0.0285             nan     0.1000   -0.0001
   920        0.0265             nan     0.1000   -0.0002
   940        0.0250             nan     0.1000   -0.0002
   960        0.0236             nan     0.1000   -0.0002
   980        0.0220             nan     0.1000   -0.0002
  1000        0.0208             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3011             nan     0.1000    0.0238
     2        1.2292             nan     0.1000    0.0271
     3        1.1744             nan     0.1000    0.0209
     4        1.1185             nan     0.1000    0.0206
     5        1.0801             nan     0.1000    0.0139
     6        1.0435             nan     0.1000    0.0114
     7        0.9993             nan     0.1000    0.0133
     8        0.9689             nan     0.1000    0.0110
     9        0.9503             nan     0.1000    0.0013
    10        0.9212             nan     0.1000    0.0082
    20        0.7522             nan     0.1000   -0.0003
    40        0.5788             nan     0.1000   -0.0048
    60        0.4771             nan     0.1000   -0.0042
    80        0.4085             nan     0.1000   -0.0036
   100        0.3538             nan     0.1000   -0.0020
   120        0.2997             nan     0.1000   -0.0026
   140        0.2614             nan     0.1000   -0.0021
   160        0.2269             nan     0.1000   -0.0039
   180        0.1986             nan     0.1000   -0.0007
   200        0.1715             nan     0.1000   -0.0011
   220        0.1494             nan     0.1000   -0.0009
   240        0.1306             nan     0.1000   -0.0011
   260        0.1185             nan     0.1000   -0.0011
   280        0.1072             nan     0.1000   -0.0012
   300        0.0939             nan     0.1000   -0.0014
   320        0.0852             nan     0.1000   -0.0007
   340        0.0743             nan     0.1000   -0.0007
   360        0.0677             nan     0.1000   -0.0003
   380        0.0597             nan     0.1000   -0.0004
   400        0.0517             nan     0.1000   -0.0005
   420        0.0474             nan     0.1000   -0.0002
   440        0.0439             nan     0.1000   -0.0005
   460        0.0398             nan     0.1000   -0.0004
   480        0.0353             nan     0.1000   -0.0002
   500        0.0317             nan     0.1000   -0.0002
   520        0.0281             nan     0.1000   -0.0001
   540        0.0251             nan     0.1000   -0.0002
   560        0.0223             nan     0.1000   -0.0002
   580        0.0199             nan     0.1000   -0.0002
   600        0.0180             nan     0.1000   -0.0001
   620        0.0163             nan     0.1000   -0.0001
   640        0.0144             nan     0.1000   -0.0001
   660        0.0129             nan     0.1000   -0.0001
   680        0.0114             nan     0.1000   -0.0001
   700        0.0103             nan     0.1000   -0.0000
   720        0.0090             nan     0.1000   -0.0001
   740        0.0082             nan     0.1000   -0.0001
   760        0.0073             nan     0.1000   -0.0000
   780        0.0067             nan     0.1000   -0.0001
   800        0.0060             nan     0.1000   -0.0000
   820        0.0055             nan     0.1000   -0.0001
   840        0.0049             nan     0.1000   -0.0001
   860        0.0043             nan     0.1000   -0.0001
   880        0.0038             nan     0.1000   -0.0000
   900        0.0035             nan     0.1000   -0.0000
   920        0.0031             nan     0.1000   -0.0000
   940        0.0028             nan     0.1000   -0.0000
   960        0.0025             nan     0.1000   -0.0000
   980        0.0023             nan     0.1000   -0.0000
  1000        0.0020             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3241             nan     0.1000    0.0313
     2        1.2648             nan     0.1000    0.0232
     3        1.2268             nan     0.1000    0.0145
     4        1.1949             nan     0.1000    0.0119
     5        1.1648             nan     0.1000    0.0118
     6        1.1256             nan     0.1000    0.0171
     7        1.0945             nan     0.1000    0.0116
     8        1.0695             nan     0.1000    0.0115
     9        1.0471             nan     0.1000    0.0083
    10        1.0237             nan     0.1000    0.0089
    20        0.8941             nan     0.1000    0.0005
    40        0.7507             nan     0.1000    0.0002
    60        0.6812             nan     0.1000   -0.0016
    80        0.6266             nan     0.1000   -0.0004
   100        0.5949             nan     0.1000   -0.0028
   120        0.5713             nan     0.1000   -0.0025
   140        0.5517             nan     0.1000   -0.0028
   160        0.5301             nan     0.1000   -0.0014
   180        0.5106             nan     0.1000   -0.0031
   200        0.4975             nan     0.1000   -0.0007
   220        0.4849             nan     0.1000   -0.0019
   240        0.4706             nan     0.1000   -0.0023
   260        0.4553             nan     0.1000   -0.0018
   280        0.4410             nan     0.1000   -0.0014
   300        0.4339             nan     0.1000   -0.0014
   320        0.4191             nan     0.1000   -0.0035
   340        0.4074             nan     0.1000   -0.0011
   360        0.4000             nan     0.1000   -0.0018
   380        0.3903             nan     0.1000   -0.0025
   400        0.3807             nan     0.1000   -0.0033
   420        0.3725             nan     0.1000   -0.0041
   440        0.3627             nan     0.1000   -0.0029
   460        0.3544             nan     0.1000   -0.0026
   480        0.3443             nan     0.1000   -0.0055
   500        0.3368             nan     0.1000   -0.0012
   520        0.3331             nan     0.1000   -0.0024
   540        0.3250             nan     0.1000   -0.0040
   560        0.3215             nan     0.1000    0.0002
   580        0.3148             nan     0.1000   -0.0010
   600        0.3121             nan     0.1000   -0.0019
   620        0.3052             nan     0.1000   -0.0035
   640        0.3005             nan     0.1000   -0.0025
   660        0.2937             nan     0.1000   -0.0010
   680        0.2901             nan     0.1000   -0.0010
   700        0.2858             nan     0.1000   -0.0012
   720        0.2790             nan     0.1000   -0.0016
   740        0.2745             nan     0.1000   -0.0039
   760        0.2677             nan     0.1000   -0.0012
   780        0.2620             nan     0.1000   -0.0026
   800        0.2605             nan     0.1000   -0.0023
   820        0.2556             nan     0.1000   -0.0014
   840        0.2515             nan     0.1000   -0.0029
   860        0.2480             nan     0.1000   -0.0012
   880        0.2415             nan     0.1000   -0.0014
   900        0.2393             nan     0.1000   -0.0012
   920        0.2335             nan     0.1000   -0.0010
   940        0.2282             nan     0.1000   -0.0024
   960        0.2248             nan     0.1000   -0.0011
   980        0.2222             nan     0.1000   -0.0014
  1000        0.2185             nan     0.1000   -0.0032

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2999             nan     0.1000    0.0278
     2        1.2453             nan     0.1000    0.0243
     3        1.1895             nan     0.1000    0.0215
     4        1.1505             nan     0.1000    0.0085
     5        1.1116             nan     0.1000    0.0178
     6        1.0775             nan     0.1000    0.0113
     7        1.0451             nan     0.1000    0.0118
     8        1.0174             nan     0.1000    0.0071
     9        0.9867             nan     0.1000    0.0086
    10        0.9617             nan     0.1000    0.0124
    20        0.7925             nan     0.1000    0.0012
    40        0.6267             nan     0.1000   -0.0043
    60        0.5363             nan     0.1000   -0.0044
    80        0.4833             nan     0.1000   -0.0039
   100        0.4338             nan     0.1000   -0.0030
   120        0.3921             nan     0.1000   -0.0022
   140        0.3588             nan     0.1000   -0.0033
   160        0.3220             nan     0.1000   -0.0030
   180        0.2945             nan     0.1000   -0.0061
   200        0.2736             nan     0.1000   -0.0022
   220        0.2461             nan     0.1000   -0.0012
   240        0.2257             nan     0.1000   -0.0023
   260        0.2102             nan     0.1000   -0.0020
   280        0.1961             nan     0.1000   -0.0008
   300        0.1854             nan     0.1000   -0.0021
   320        0.1741             nan     0.1000   -0.0012
   340        0.1623             nan     0.1000   -0.0012
   360        0.1529             nan     0.1000   -0.0007
   380        0.1394             nan     0.1000   -0.0009
   400        0.1293             nan     0.1000   -0.0008
   420        0.1200             nan     0.1000   -0.0007
   440        0.1098             nan     0.1000   -0.0010
   460        0.1015             nan     0.1000   -0.0004
   480        0.0947             nan     0.1000   -0.0005
   500        0.0885             nan     0.1000   -0.0009
   520        0.0826             nan     0.1000   -0.0006
   540        0.0777             nan     0.1000   -0.0007
   560        0.0738             nan     0.1000   -0.0007
   580        0.0686             nan     0.1000   -0.0007
   600        0.0653             nan     0.1000   -0.0008
   620        0.0597             nan     0.1000   -0.0005
   640        0.0561             nan     0.1000   -0.0005
   660        0.0526             nan     0.1000   -0.0002
   680        0.0501             nan     0.1000   -0.0006
   700        0.0469             nan     0.1000   -0.0003
   720        0.0443             nan     0.1000   -0.0004
   740        0.0431             nan     0.1000   -0.0003
   760        0.0398             nan     0.1000   -0.0004
   780        0.0373             nan     0.1000   -0.0001
   800        0.0355             nan     0.1000   -0.0002
   820        0.0332             nan     0.1000   -0.0002
   840        0.0311             nan     0.1000   -0.0004
   860        0.0292             nan     0.1000   -0.0002
   880        0.0278             nan     0.1000   -0.0002
   900        0.0265             nan     0.1000   -0.0002
   920        0.0248             nan     0.1000   -0.0002
   940        0.0234             nan     0.1000   -0.0001
   960        0.0218             nan     0.1000   -0.0002
   980        0.0202             nan     0.1000   -0.0001
  1000        0.0196             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2970             nan     0.1000    0.0355
     2        1.2282             nan     0.1000    0.0288
     3        1.1670             nan     0.1000    0.0225
     4        1.1124             nan     0.1000    0.0223
     5        1.0690             nan     0.1000    0.0114
     6        1.0324             nan     0.1000    0.0078
     7        1.0039             nan     0.1000    0.0067
     8        0.9669             nan     0.1000    0.0156
     9        0.9423             nan     0.1000    0.0036
    10        0.9160             nan     0.1000    0.0075
    20        0.7246             nan     0.1000    0.0026
    40        0.5482             nan     0.1000   -0.0013
    60        0.4474             nan     0.1000   -0.0016
    80        0.3663             nan     0.1000   -0.0030
   100        0.3063             nan     0.1000   -0.0032
   120        0.2603             nan     0.1000   -0.0017
   140        0.2230             nan     0.1000   -0.0018
   160        0.1944             nan     0.1000   -0.0026
   180        0.1738             nan     0.1000   -0.0011
   200        0.1518             nan     0.1000   -0.0014
   220        0.1345             nan     0.1000   -0.0016
   240        0.1161             nan     0.1000   -0.0009
   260        0.1002             nan     0.1000   -0.0008
   280        0.0892             nan     0.1000   -0.0011
   300        0.0784             nan     0.1000   -0.0006
   320        0.0682             nan     0.1000   -0.0006
   340        0.0619             nan     0.1000   -0.0006
   360        0.0543             nan     0.1000   -0.0001
   380        0.0499             nan     0.1000   -0.0007
   400        0.0445             nan     0.1000   -0.0005
   420        0.0400             nan     0.1000   -0.0003
   440        0.0348             nan     0.1000   -0.0004
   460        0.0310             nan     0.1000   -0.0003
   480        0.0284             nan     0.1000   -0.0003
   500        0.0252             nan     0.1000   -0.0002
   520        0.0234             nan     0.1000   -0.0002
   540        0.0208             nan     0.1000   -0.0002
   560        0.0188             nan     0.1000   -0.0002
   580        0.0165             nan     0.1000   -0.0002
   600        0.0149             nan     0.1000   -0.0002
   620        0.0134             nan     0.1000   -0.0002
   640        0.0121             nan     0.1000   -0.0001
   660        0.0106             nan     0.1000   -0.0001
   680        0.0097             nan     0.1000   -0.0001
   700        0.0086             nan     0.1000   -0.0000
   720        0.0075             nan     0.1000   -0.0001
   740        0.0069             nan     0.1000   -0.0001
   760        0.0061             nan     0.1000   -0.0001
   780        0.0054             nan     0.1000   -0.0001
   800        0.0048             nan     0.1000   -0.0000
   820        0.0043             nan     0.1000   -0.0001
   840        0.0038             nan     0.1000   -0.0000
   860        0.0034             nan     0.1000   -0.0000
   880        0.0031             nan     0.1000   -0.0000
   900        0.0028             nan     0.1000   -0.0000
   920        0.0024             nan     0.1000   -0.0000
   940        0.0022             nan     0.1000   -0.0000
   960        0.0020             nan     0.1000   -0.0000
   980        0.0018             nan     0.1000   -0.0000
  1000        0.0016             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3375             nan     0.1000    0.0180
     2        1.2834             nan     0.1000    0.0308
     3        1.2274             nan     0.1000    0.0256
     4        1.1762             nan     0.1000    0.0191
     5        1.1425             nan     0.1000    0.0155
     6        1.1120             nan     0.1000    0.0116
     7        1.0825             nan     0.1000    0.0129
     8        1.0600             nan     0.1000    0.0099
     9        1.0372             nan     0.1000    0.0081
    10        1.0144             nan     0.1000    0.0069
    20        0.8703             nan     0.1000    0.0030
    40        0.7404             nan     0.1000   -0.0008
    60        0.6695             nan     0.1000   -0.0024
    80        0.6281             nan     0.1000   -0.0026
   100        0.5904             nan     0.1000   -0.0002
   120        0.5619             nan     0.1000   -0.0026
   140        0.5381             nan     0.1000   -0.0009
   160        0.5199             nan     0.1000   -0.0015
   180        0.5037             nan     0.1000   -0.0052
   200        0.4859             nan     0.1000   -0.0012
   220        0.4687             nan     0.1000   -0.0022
   240        0.4567             nan     0.1000   -0.0021
   260        0.4401             nan     0.1000   -0.0021
   280        0.4281             nan     0.1000   -0.0032
   300        0.4147             nan     0.1000   -0.0033
   320        0.4090             nan     0.1000   -0.0043
   340        0.3999             nan     0.1000   -0.0029
   360        0.3921             nan     0.1000   -0.0034
   380        0.3833             nan     0.1000   -0.0046
   400        0.3726             nan     0.1000   -0.0000
   420        0.3640             nan     0.1000   -0.0060
   440        0.3531             nan     0.1000   -0.0044
   460        0.3457             nan     0.1000   -0.0024
   480        0.3341             nan     0.1000   -0.0008
   500        0.3248             nan     0.1000   -0.0055
   520        0.3199             nan     0.1000   -0.0018
   540        0.3156             nan     0.1000   -0.0039
   560        0.3104             nan     0.1000   -0.0024
   580        0.3047             nan     0.1000   -0.0018
   600        0.2986             nan     0.1000   -0.0020
   620        0.2903             nan     0.1000   -0.0024
   640        0.2840             nan     0.1000   -0.0022
   660        0.2783             nan     0.1000   -0.0014
   680        0.2736             nan     0.1000   -0.0022
   700        0.2702             nan     0.1000   -0.0020
   720        0.2643             nan     0.1000   -0.0024
   740        0.2610             nan     0.1000   -0.0019
   760        0.2579             nan     0.1000   -0.0018
   780        0.2553             nan     0.1000   -0.0008
   800        0.2514             nan     0.1000   -0.0014
   820        0.2475             nan     0.1000   -0.0017
   840        0.2483             nan     0.1000   -0.0014
   860        0.2428             nan     0.1000   -0.0029
   880        0.2337             nan     0.1000   -0.0010
   900        0.2317             nan     0.1000   -0.0014
   920        0.2279             nan     0.1000   -0.0031
   940        0.2260             nan     0.1000   -0.0025
   960        0.2235             nan     0.1000   -0.0018
   980        0.2203             nan     0.1000   -0.0012
  1000        0.2178             nan     0.1000   -0.0014

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2843             nan     0.1000    0.0387
     2        1.2161             nan     0.1000    0.0298
     3        1.1681             nan     0.1000    0.0148
     4        1.1187             nan     0.1000    0.0151
     5        1.0784             nan     0.1000    0.0176
     6        1.0435             nan     0.1000    0.0127
     7        1.0111             nan     0.1000    0.0115
     8        0.9934             nan     0.1000    0.0010
     9        0.9745             nan     0.1000    0.0020
    10        0.9474             nan     0.1000    0.0089
    20        0.7676             nan     0.1000   -0.0012
    40        0.6010             nan     0.1000   -0.0019
    60        0.5263             nan     0.1000   -0.0053
    80        0.4673             nan     0.1000   -0.0070
   100        0.4078             nan     0.1000   -0.0002
   120        0.3682             nan     0.1000   -0.0013
   140        0.3403             nan     0.1000   -0.0075
   160        0.3063             nan     0.1000   -0.0008
   180        0.2778             nan     0.1000   -0.0032
   200        0.2526             nan     0.1000   -0.0037
   220        0.2320             nan     0.1000   -0.0051
   240        0.2154             nan     0.1000   -0.0018
   260        0.1975             nan     0.1000   -0.0029
   280        0.1823             nan     0.1000   -0.0008
   300        0.1697             nan     0.1000   -0.0011
   320        0.1579             nan     0.1000   -0.0027
   340        0.1459             nan     0.1000   -0.0007
   360        0.1336             nan     0.1000   -0.0014
   380        0.1240             nan     0.1000   -0.0011
   400        0.1129             nan     0.1000   -0.0009
   420        0.1035             nan     0.1000   -0.0002
   440        0.0975             nan     0.1000   -0.0004
   460        0.0897             nan     0.1000   -0.0004
   480        0.0812             nan     0.1000   -0.0012
   500        0.0756             nan     0.1000   -0.0009
   520        0.0694             nan     0.1000   -0.0011
   540        0.0639             nan     0.1000   -0.0012
   560        0.0609             nan     0.1000   -0.0005
   580        0.0565             nan     0.1000   -0.0009
   600        0.0512             nan     0.1000   -0.0003
   620        0.0483             nan     0.1000   -0.0001
   640        0.0458             nan     0.1000   -0.0002
   660        0.0431             nan     0.1000   -0.0005
   680        0.0395             nan     0.1000   -0.0004
   700        0.0375             nan     0.1000   -0.0003
   720        0.0357             nan     0.1000   -0.0004
   740        0.0335             nan     0.1000   -0.0004
   760        0.0316             nan     0.1000   -0.0005
   780        0.0289             nan     0.1000   -0.0002
   800        0.0270             nan     0.1000   -0.0004
   820        0.0248             nan     0.1000   -0.0002
   840        0.0232             nan     0.1000   -0.0002
   860        0.0222             nan     0.1000   -0.0001
   880        0.0207             nan     0.1000   -0.0002
   900        0.0191             nan     0.1000   -0.0002
   920        0.0183             nan     0.1000   -0.0003
   940        0.0168             nan     0.1000   -0.0001
   960        0.0156             nan     0.1000   -0.0001
   980        0.0144             nan     0.1000   -0.0002
  1000        0.0134             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2943             nan     0.1000    0.0365
     2        1.2124             nan     0.1000    0.0267
     3        1.1482             nan     0.1000    0.0244
     4        1.1106             nan     0.1000    0.0064
     5        1.0631             nan     0.1000    0.0180
     6        1.0206             nan     0.1000    0.0094
     7        0.9817             nan     0.1000    0.0107
     8        0.9498             nan     0.1000    0.0106
     9        0.9238             nan     0.1000    0.0077
    10        0.8899             nan     0.1000    0.0083
    20        0.7172             nan     0.1000    0.0043
    40        0.5256             nan     0.1000   -0.0030
    60        0.4153             nan     0.1000   -0.0028
    80        0.3526             nan     0.1000   -0.0033
   100        0.2923             nan     0.1000   -0.0065
   120        0.2490             nan     0.1000   -0.0033
   140        0.2137             nan     0.1000   -0.0026
   160        0.1835             nan     0.1000   -0.0014
   180        0.1593             nan     0.1000   -0.0023
   200        0.1392             nan     0.1000   -0.0010
   220        0.1214             nan     0.1000   -0.0013
   240        0.1052             nan     0.1000   -0.0009
   260        0.0919             nan     0.1000   -0.0004
   280        0.0819             nan     0.1000   -0.0014
   300        0.0720             nan     0.1000   -0.0006
   320        0.0649             nan     0.1000   -0.0010
   340        0.0566             nan     0.1000   -0.0001
   360        0.0494             nan     0.1000   -0.0007
   380        0.0430             nan     0.1000   -0.0005
   400        0.0365             nan     0.1000   -0.0001
   420        0.0322             nan     0.1000   -0.0003
   440        0.0288             nan     0.1000   -0.0003
   460        0.0251             nan     0.1000   -0.0002
   480        0.0227             nan     0.1000   -0.0001
   500        0.0202             nan     0.1000   -0.0002
   520        0.0182             nan     0.1000   -0.0002
   540        0.0164             nan     0.1000   -0.0001
   560        0.0149             nan     0.1000   -0.0002
   580        0.0129             nan     0.1000   -0.0001
   600        0.0115             nan     0.1000   -0.0001
   620        0.0103             nan     0.1000   -0.0001
   640        0.0092             nan     0.1000   -0.0001
   660        0.0081             nan     0.1000   -0.0001
   680        0.0073             nan     0.1000   -0.0001
   700        0.0063             nan     0.1000   -0.0000
   720        0.0055             nan     0.1000   -0.0001
   740        0.0048             nan     0.1000   -0.0000
   760        0.0044             nan     0.1000   -0.0000
   780        0.0040             nan     0.1000   -0.0000
   800        0.0035             nan     0.1000   -0.0000
   820        0.0031             nan     0.1000   -0.0000
   840        0.0027             nan     0.1000   -0.0000
   860        0.0024             nan     0.1000   -0.0000
   880        0.0021             nan     0.1000   -0.0000
   900        0.0019             nan     0.1000   -0.0000
   920        0.0017             nan     0.1000   -0.0000
   940        0.0015             nan     0.1000   -0.0000
   960        0.0013             nan     0.1000   -0.0000
   980        0.0011             nan     0.1000   -0.0000
  1000        0.0010             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3160             nan     0.1000    0.0293
     2        1.2656             nan     0.1000    0.0252
     3        1.2356             nan     0.1000    0.0073
     4        1.1914             nan     0.1000    0.0179
     5        1.1572             nan     0.1000    0.0152
     6        1.1314             nan     0.1000    0.0102
     7        1.1049             nan     0.1000    0.0089
     8        1.0842             nan     0.1000    0.0096
     9        1.0676             nan     0.1000    0.0035
    10        1.0504             nan     0.1000    0.0040
    20        0.9227             nan     0.1000    0.0022
    40        0.7961             nan     0.1000    0.0015
    60        0.7263             nan     0.1000   -0.0015
    80        0.6721             nan     0.1000   -0.0020
   100        0.6340             nan     0.1000   -0.0026
   120        0.6123             nan     0.1000   -0.0027
   140        0.5884             nan     0.1000   -0.0020
   160        0.5704             nan     0.1000   -0.0030
   180        0.5569             nan     0.1000   -0.0028
   200        0.5394             nan     0.1000   -0.0023
   220        0.5249             nan     0.1000   -0.0027
   240        0.5140             nan     0.1000   -0.0045
   260        0.4912             nan     0.1000   -0.0004
   280        0.4749             nan     0.1000   -0.0020
   300        0.4624             nan     0.1000   -0.0020
   320        0.4518             nan     0.1000   -0.0039
   340        0.4388             nan     0.1000   -0.0041
   360        0.4332             nan     0.1000   -0.0021
   380        0.4220             nan     0.1000   -0.0013
   400        0.4137             nan     0.1000   -0.0031
   420        0.4062             nan     0.1000   -0.0006
   440        0.3995             nan     0.1000   -0.0004
   460        0.3863             nan     0.1000   -0.0029
   480        0.3787             nan     0.1000   -0.0032
   500        0.3701             nan     0.1000   -0.0019
   520        0.3635             nan     0.1000   -0.0025
   540        0.3538             nan     0.1000   -0.0003
   560        0.3457             nan     0.1000   -0.0016
   580        0.3406             nan     0.1000   -0.0034
   600        0.3358             nan     0.1000   -0.0019
   620        0.3304             nan     0.1000   -0.0003
   640        0.3245             nan     0.1000   -0.0006
   660        0.3163             nan     0.1000   -0.0012
   680        0.3109             nan     0.1000   -0.0027
   700        0.3070             nan     0.1000   -0.0016
   720        0.3010             nan     0.1000   -0.0049
   740        0.2989             nan     0.1000   -0.0000
   760        0.2917             nan     0.1000   -0.0011
   780        0.2839             nan     0.1000   -0.0016
   800        0.2795             nan     0.1000   -0.0023
   820        0.2720             nan     0.1000   -0.0034
   840        0.2706             nan     0.1000   -0.0014
   860        0.2626             nan     0.1000   -0.0017
   880        0.2597             nan     0.1000   -0.0025
   900        0.2582             nan     0.1000   -0.0017
   920        0.2513             nan     0.1000   -0.0007
   940        0.2469             nan     0.1000   -0.0008
   960        0.2419             nan     0.1000   -0.0040
   980        0.2370             nan     0.1000   -0.0014
  1000        0.2366             nan     0.1000   -0.0012

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3083             nan     0.1000    0.0229
     2        1.2540             nan     0.1000    0.0246
     3        1.2025             nan     0.1000    0.0199
     4        1.1494             nan     0.1000    0.0186
     5        1.1119             nan     0.1000    0.0147
     6        1.0775             nan     0.1000    0.0133
     7        1.0403             nan     0.1000    0.0060
     8        1.0138             nan     0.1000    0.0058
     9        0.9895             nan     0.1000    0.0047
    10        0.9728             nan     0.1000    0.0004
    20        0.8104             nan     0.1000    0.0039
    40        0.6698             nan     0.1000   -0.0032
    60        0.5863             nan     0.1000   -0.0049
    80        0.5159             nan     0.1000   -0.0071
   100        0.4715             nan     0.1000   -0.0015
   120        0.4360             nan     0.1000   -0.0057
   140        0.4043             nan     0.1000   -0.0033
   160        0.3654             nan     0.1000   -0.0017
   180        0.3360             nan     0.1000   -0.0034
   200        0.3082             nan     0.1000   -0.0014
   220        0.2937             nan     0.1000   -0.0038
   240        0.2702             nan     0.1000   -0.0011
   260        0.2523             nan     0.1000   -0.0011
   280        0.2346             nan     0.1000   -0.0021
   300        0.2217             nan     0.1000   -0.0016
   320        0.2059             nan     0.1000   -0.0033
   340        0.1895             nan     0.1000   -0.0025
   360        0.1748             nan     0.1000   -0.0036
   380        0.1643             nan     0.1000   -0.0012
   400        0.1521             nan     0.1000   -0.0018
   420        0.1417             nan     0.1000   -0.0012
   440        0.1330             nan     0.1000   -0.0008
   460        0.1254             nan     0.1000   -0.0020
   480        0.1189             nan     0.1000   -0.0019
   500        0.1115             nan     0.1000   -0.0008
   520        0.1028             nan     0.1000   -0.0010
   540        0.0973             nan     0.1000   -0.0009
   560        0.0924             nan     0.1000   -0.0005
   580        0.0856             nan     0.1000   -0.0008
   600        0.0796             nan     0.1000   -0.0005
   620        0.0742             nan     0.1000   -0.0010
   640        0.0708             nan     0.1000   -0.0005
   660        0.0666             nan     0.1000   -0.0006
   680        0.0614             nan     0.1000   -0.0004
   700        0.0583             nan     0.1000   -0.0007
   720        0.0546             nan     0.1000   -0.0004
   740        0.0513             nan     0.1000   -0.0005
   760        0.0485             nan     0.1000   -0.0006
   780        0.0465             nan     0.1000   -0.0006
   800        0.0438             nan     0.1000   -0.0002
   820        0.0413             nan     0.1000   -0.0003
   840        0.0388             nan     0.1000   -0.0004
   860        0.0366             nan     0.1000   -0.0003
   880        0.0344             nan     0.1000   -0.0003
   900        0.0324             nan     0.1000   -0.0001
   920        0.0307             nan     0.1000   -0.0002
   940        0.0287             nan     0.1000   -0.0002
   960        0.0265             nan     0.1000   -0.0004
   980        0.0251             nan     0.1000   -0.0001
  1000        0.0234             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2946             nan     0.1000    0.0309
     2        1.2266             nan     0.1000    0.0254
     3        1.1747             nan     0.1000    0.0158
     4        1.1248             nan     0.1000    0.0124
     5        1.0851             nan     0.1000    0.0142
     6        1.0518             nan     0.1000    0.0054
     7        1.0232             nan     0.1000    0.0088
     8        0.9894             nan     0.1000    0.0088
     9        0.9627             nan     0.1000    0.0107
    10        0.9375             nan     0.1000    0.0052
    20        0.7646             nan     0.1000    0.0010
    40        0.5872             nan     0.1000   -0.0001
    60        0.4851             nan     0.1000   -0.0015
    80        0.4146             nan     0.1000   -0.0015
   100        0.3589             nan     0.1000   -0.0042
   120        0.3146             nan     0.1000   -0.0022
   140        0.2709             nan     0.1000   -0.0026
   160        0.2405             nan     0.1000   -0.0006
   180        0.2112             nan     0.1000   -0.0018
   200        0.1882             nan     0.1000   -0.0025
   220        0.1669             nan     0.1000   -0.0020
   240        0.1490             nan     0.1000   -0.0026
   260        0.1333             nan     0.1000   -0.0010
   280        0.1199             nan     0.1000   -0.0015
   300        0.1090             nan     0.1000   -0.0015
   320        0.0967             nan     0.1000   -0.0007
   340        0.0849             nan     0.1000   -0.0007
   360        0.0771             nan     0.1000   -0.0010
   380        0.0685             nan     0.1000   -0.0009
   400        0.0603             nan     0.1000   -0.0011
   420        0.0551             nan     0.1000   -0.0006
   440        0.0493             nan     0.1000   -0.0002
   460        0.0445             nan     0.1000   -0.0001
   480        0.0407             nan     0.1000   -0.0002
   500        0.0366             nan     0.1000   -0.0005
   520        0.0332             nan     0.1000   -0.0003
   540        0.0299             nan     0.1000   -0.0003
   560        0.0268             nan     0.1000   -0.0002
   580        0.0243             nan     0.1000   -0.0003
   600        0.0222             nan     0.1000   -0.0003
   620        0.0204             nan     0.1000   -0.0003
   640        0.0188             nan     0.1000   -0.0004
   660        0.0171             nan     0.1000   -0.0002
   680        0.0155             nan     0.1000   -0.0001
   700        0.0140             nan     0.1000   -0.0001
   720        0.0126             nan     0.1000   -0.0002
   740        0.0113             nan     0.1000   -0.0001
   760        0.0100             nan     0.1000   -0.0001
   780        0.0089             nan     0.1000   -0.0002
   800        0.0081             nan     0.1000   -0.0001
   820        0.0074             nan     0.1000   -0.0001
   840        0.0067             nan     0.1000   -0.0001
   860        0.0060             nan     0.1000   -0.0001
   880        0.0055             nan     0.1000   -0.0001
   900        0.0049             nan     0.1000   -0.0001
   920        0.0044             nan     0.1000   -0.0000
   940        0.0040             nan     0.1000   -0.0000
   960        0.0037             nan     0.1000   -0.0000
   980        0.0034             nan     0.1000   -0.0000
  1000        0.0031             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3252             nan     0.1000    0.0272
     2        1.2817             nan     0.1000    0.0214
     3        1.2476             nan     0.1000    0.0147
     4        1.2086             nan     0.1000    0.0168
     5        1.1715             nan     0.1000    0.0145
     6        1.1378             nan     0.1000    0.0051
     7        1.1099             nan     0.1000    0.0117
     8        1.0894             nan     0.1000    0.0071
     9        1.0735             nan     0.1000    0.0017
    10        1.0567             nan     0.1000    0.0082
    20        0.9259             nan     0.1000    0.0001
    40        0.7971             nan     0.1000   -0.0014
    60        0.7188             nan     0.1000   -0.0014
    80        0.6638             nan     0.1000   -0.0019
   100        0.6212             nan     0.1000   -0.0020
   120        0.5882             nan     0.1000   -0.0016
   140        0.5613             nan     0.1000   -0.0033
   160        0.5370             nan     0.1000   -0.0008
   180        0.5173             nan     0.1000   -0.0033
   200        0.5019             nan     0.1000   -0.0049
   220        0.4790             nan     0.1000   -0.0021
   240        0.4605             nan     0.1000   -0.0014
   260        0.4491             nan     0.1000   -0.0048
   280        0.4293             nan     0.1000   -0.0034
   300        0.4111             nan     0.1000   -0.0012
   320        0.3955             nan     0.1000   -0.0026
   340        0.3851             nan     0.1000   -0.0032
   360        0.3773             nan     0.1000   -0.0029
   380        0.3630             nan     0.1000   -0.0008
   400        0.3513             nan     0.1000   -0.0013
   420        0.3444             nan     0.1000   -0.0026
   440        0.3345             nan     0.1000   -0.0019
   460        0.3236             nan     0.1000   -0.0016
   480        0.3112             nan     0.1000   -0.0011
   500        0.3096             nan     0.1000   -0.0010
   520        0.3053             nan     0.1000   -0.0008
   540        0.2969             nan     0.1000   -0.0013
   560        0.2912             nan     0.1000   -0.0023
   580        0.2891             nan     0.1000   -0.0040
   600        0.2811             nan     0.1000   -0.0016
   620        0.2707             nan     0.1000   -0.0016
   640        0.2656             nan     0.1000   -0.0020
   660        0.2594             nan     0.1000   -0.0018
   680        0.2522             nan     0.1000   -0.0013
   700        0.2470             nan     0.1000   -0.0019
   720        0.2431             nan     0.1000   -0.0015
   740        0.2363             nan     0.1000   -0.0025
   760        0.2330             nan     0.1000   -0.0024
   780        0.2258             nan     0.1000   -0.0011
   800        0.2204             nan     0.1000   -0.0013
   820        0.2164             nan     0.1000   -0.0010
   840        0.2122             nan     0.1000   -0.0009
   860        0.2081             nan     0.1000   -0.0013
   880        0.2043             nan     0.1000   -0.0006
   900        0.2010             nan     0.1000   -0.0020
   920        0.1962             nan     0.1000   -0.0006
   940        0.1917             nan     0.1000   -0.0015
   960        0.1874             nan     0.1000   -0.0011
   980        0.1847             nan     0.1000   -0.0010
  1000        0.1818             nan     0.1000   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3011             nan     0.1000    0.0356
     2        1.2460             nan     0.1000    0.0256
     3        1.1950             nan     0.1000    0.0228
     4        1.1509             nan     0.1000    0.0214
     5        1.1132             nan     0.1000    0.0120
     6        1.0834             nan     0.1000    0.0083
     7        1.0514             nan     0.1000    0.0099
     8        1.0252             nan     0.1000    0.0057
     9        1.0005             nan     0.1000    0.0067
    10        0.9744             nan     0.1000    0.0009
    20        0.8263             nan     0.1000    0.0010
    40        0.6594             nan     0.1000   -0.0003
    60        0.5773             nan     0.1000   -0.0056
    80        0.5081             nan     0.1000   -0.0040
   100        0.4437             nan     0.1000   -0.0031
   120        0.3949             nan     0.1000   -0.0033
   140        0.3466             nan     0.1000   -0.0006
   160        0.3212             nan     0.1000   -0.0027
   180        0.2969             nan     0.1000   -0.0029
   200        0.2693             nan     0.1000   -0.0020
   220        0.2484             nan     0.1000   -0.0007
   240        0.2328             nan     0.1000   -0.0019
   260        0.2140             nan     0.1000   -0.0008
   280        0.2000             nan     0.1000   -0.0013
   300        0.1838             nan     0.1000    0.0001
   320        0.1696             nan     0.1000   -0.0021
   340        0.1551             nan     0.1000   -0.0010
   360        0.1426             nan     0.1000   -0.0007
   380        0.1349             nan     0.1000   -0.0018
   400        0.1249             nan     0.1000   -0.0012
   420        0.1160             nan     0.1000   -0.0013
   440        0.1060             nan     0.1000   -0.0013
   460        0.1002             nan     0.1000   -0.0007
   480        0.0920             nan     0.1000   -0.0006
   500        0.0867             nan     0.1000   -0.0011
   520        0.0819             nan     0.1000   -0.0006
   540        0.0758             nan     0.1000   -0.0008
   560        0.0709             nan     0.1000   -0.0003
   580        0.0665             nan     0.1000   -0.0007
   600        0.0620             nan     0.1000   -0.0007
   620        0.0574             nan     0.1000   -0.0006
   640        0.0528             nan     0.1000   -0.0006
   660        0.0490             nan     0.1000   -0.0001
   680        0.0456             nan     0.1000   -0.0004
   700        0.0423             nan     0.1000   -0.0002
   720        0.0389             nan     0.1000   -0.0002
   740        0.0368             nan     0.1000   -0.0004
   760        0.0349             nan     0.1000   -0.0003
   780        0.0325             nan     0.1000   -0.0002
   800        0.0303             nan     0.1000   -0.0004
   820        0.0278             nan     0.1000   -0.0002
   840        0.0257             nan     0.1000   -0.0003
   860        0.0244             nan     0.1000   -0.0001
   880        0.0228             nan     0.1000   -0.0001
   900        0.0213             nan     0.1000   -0.0001
   920        0.0198             nan     0.1000   -0.0001
   940        0.0185             nan     0.1000   -0.0001
   960        0.0177             nan     0.1000   -0.0001
   980        0.0162             nan     0.1000   -0.0002
  1000        0.0151             nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3019             nan     0.1000    0.0290
     2        1.2263             nan     0.1000    0.0313
     3        1.1586             nan     0.1000    0.0280
     4        1.1058             nan     0.1000    0.0161
     5        1.0706             nan     0.1000    0.0106
     6        1.0345             nan     0.1000    0.0196
     7        1.0025             nan     0.1000    0.0072
     8        0.9737             nan     0.1000    0.0071
     9        0.9492             nan     0.1000    0.0071
    10        0.9284             nan     0.1000    0.0006
    20        0.7454             nan     0.1000    0.0037
    40        0.5696             nan     0.1000   -0.0060
    60        0.4662             nan     0.1000   -0.0051
    80        0.3839             nan     0.1000   -0.0023
   100        0.3236             nan     0.1000   -0.0027
   120        0.2769             nan     0.1000   -0.0014
   140        0.2385             nan     0.1000   -0.0029
   160        0.2040             nan     0.1000   -0.0015
   180        0.1783             nan     0.1000   -0.0015
   200        0.1544             nan     0.1000   -0.0019
   220        0.1307             nan     0.1000   -0.0008
   240        0.1173             nan     0.1000   -0.0015
   260        0.1039             nan     0.1000   -0.0011
   280        0.0934             nan     0.1000   -0.0010
   300        0.0821             nan     0.1000   -0.0013
   320        0.0716             nan     0.1000   -0.0007
   340        0.0637             nan     0.1000   -0.0005
   360        0.0556             nan     0.1000   -0.0009
   380        0.0499             nan     0.1000   -0.0005
   400        0.0440             nan     0.1000   -0.0002
   420        0.0393             nan     0.1000   -0.0006
   440        0.0348             nan     0.1000   -0.0002
   460        0.0300             nan     0.1000   -0.0003
   480        0.0262             nan     0.1000   -0.0002
   500        0.0231             nan     0.1000   -0.0001
   520        0.0201             nan     0.1000   -0.0003
   540        0.0178             nan     0.1000   -0.0002
   560        0.0160             nan     0.1000   -0.0002
   580        0.0146             nan     0.1000   -0.0002
   600        0.0130             nan     0.1000   -0.0001
   620        0.0116             nan     0.1000   -0.0001
   640        0.0105             nan     0.1000   -0.0001
   660        0.0093             nan     0.1000   -0.0001
   680        0.0084             nan     0.1000   -0.0000
   700        0.0077             nan     0.1000   -0.0001
   720        0.0068             nan     0.1000   -0.0001
   740        0.0060             nan     0.1000   -0.0000
   760        0.0053             nan     0.1000   -0.0000
   780        0.0048             nan     0.1000   -0.0001
   800        0.0043             nan     0.1000   -0.0000
   820        0.0038             nan     0.1000   -0.0000
   840        0.0034             nan     0.1000   -0.0000
   860        0.0030             nan     0.1000   -0.0000
   880        0.0026             nan     0.1000   -0.0000
   900        0.0024             nan     0.1000   -0.0000
   920        0.0021             nan     0.1000   -0.0000
   940        0.0019             nan     0.1000   -0.0000
   960        0.0017             nan     0.1000   -0.0000
   980        0.0015             nan     0.1000   -0.0000
  1000        0.0013             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3135             nan     0.1000    0.0248
     2        1.2710             nan     0.1000    0.0172
     3        1.2388             nan     0.1000    0.0168
     4        1.2281             nan     0.1000    0.0005
     5        1.1965             nan     0.1000    0.0112
     6        1.1701             nan     0.1000    0.0134
     7        1.1544             nan     0.1000    0.0000
     8        1.1315             nan     0.1000    0.0050
     9        1.1128             nan     0.1000    0.0042
    10        1.0887             nan     0.1000    0.0094
    20        0.9502             nan     0.1000    0.0005
    40        0.8191             nan     0.1000   -0.0020
    60        0.7575             nan     0.1000   -0.0033
    80        0.7046             nan     0.1000   -0.0030
   100        0.6711             nan     0.1000   -0.0037
   120        0.6355             nan     0.1000   -0.0038
   140        0.6139             nan     0.1000   -0.0035
   160        0.5925             nan     0.1000   -0.0022
   180        0.5666             nan     0.1000   -0.0006
   200        0.5528             nan     0.1000   -0.0008
   220        0.5320             nan     0.1000   -0.0020
   240        0.5167             nan     0.1000   -0.0008
   260        0.5050             nan     0.1000   -0.0023
   280        0.4941             nan     0.1000   -0.0024
   300        0.4854             nan     0.1000   -0.0039
   320        0.4691             nan     0.1000   -0.0015
   340        0.4552             nan     0.1000   -0.0022
   360        0.4420             nan     0.1000   -0.0027
   380        0.4289             nan     0.1000   -0.0015
   400        0.4204             nan     0.1000   -0.0028
   420        0.4087             nan     0.1000   -0.0009
   440        0.4015             nan     0.1000   -0.0022
   460        0.3927             nan     0.1000   -0.0039
   480        0.3838             nan     0.1000   -0.0030
   500        0.3751             nan     0.1000   -0.0015
   520        0.3675             nan     0.1000   -0.0017
   540        0.3613             nan     0.1000   -0.0013
   560        0.3542             nan     0.1000   -0.0026
   580        0.3512             nan     0.1000   -0.0012
   600        0.3473             nan     0.1000   -0.0018
   620        0.3380             nan     0.1000   -0.0009
   640        0.3306             nan     0.1000   -0.0008
   660        0.3243             nan     0.1000   -0.0023
   680        0.3191             nan     0.1000   -0.0001
   700        0.3173             nan     0.1000   -0.0032
   720        0.3103             nan     0.1000   -0.0012
   740        0.3073             nan     0.1000   -0.0023
   760        0.3034             nan     0.1000   -0.0018
   780        0.2972             nan     0.1000   -0.0046
   800        0.2940             nan     0.1000   -0.0015
   820        0.2900             nan     0.1000   -0.0018
   840        0.2865             nan     0.1000   -0.0013
   860        0.2802             nan     0.1000   -0.0022
   880        0.2736             nan     0.1000   -0.0021
   900        0.2711             nan     0.1000   -0.0017
   920        0.2670             nan     0.1000   -0.0023
   940        0.2634             nan     0.1000   -0.0027
   960        0.2614             nan     0.1000   -0.0014
   980        0.2582             nan     0.1000   -0.0007
  1000        0.2547             nan     0.1000   -0.0016

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3098             nan     0.1000    0.0299
     2        1.2647             nan     0.1000    0.0137
     3        1.2238             nan     0.1000    0.0141
     4        1.1775             nan     0.1000    0.0200
     5        1.1411             nan     0.1000    0.0160
     6        1.1111             nan     0.1000    0.0016
     7        1.0766             nan     0.1000    0.0106
     8        1.0506             nan     0.1000    0.0013
     9        1.0276             nan     0.1000    0.0078
    10        1.0075             nan     0.1000    0.0009
    20        0.8438             nan     0.1000    0.0042
    40        0.7055             nan     0.1000   -0.0028
    60        0.6175             nan     0.1000   -0.0028
    80        0.5487             nan     0.1000   -0.0024
   100        0.4929             nan     0.1000   -0.0034
   120        0.4476             nan     0.1000   -0.0023
   140        0.4130             nan     0.1000   -0.0057
   160        0.3805             nan     0.1000   -0.0034
   180        0.3480             nan     0.1000   -0.0027
   200        0.3246             nan     0.1000   -0.0006
   220        0.3016             nan     0.1000   -0.0029
   240        0.2773             nan     0.1000   -0.0017
   260        0.2585             nan     0.1000   -0.0015
   280        0.2427             nan     0.1000   -0.0013
   300        0.2243             nan     0.1000   -0.0024
   320        0.2131             nan     0.1000   -0.0026
   340        0.1991             nan     0.1000   -0.0017
   360        0.1878             nan     0.1000   -0.0008
   380        0.1765             nan     0.1000   -0.0008
   400        0.1634             nan     0.1000   -0.0006
   420        0.1508             nan     0.1000   -0.0009
   440        0.1404             nan     0.1000   -0.0012
   460        0.1296             nan     0.1000   -0.0019
   480        0.1221             nan     0.1000   -0.0008
   500        0.1129             nan     0.1000   -0.0004
   520        0.1071             nan     0.1000   -0.0013
   540        0.1018             nan     0.1000   -0.0007
   560        0.0971             nan     0.1000   -0.0006
   580        0.0922             nan     0.1000   -0.0003
   600        0.0870             nan     0.1000   -0.0011
   620        0.0833             nan     0.1000   -0.0016
   640        0.0787             nan     0.1000   -0.0009
   660        0.0752             nan     0.1000   -0.0003
   680        0.0701             nan     0.1000   -0.0003
   700        0.0666             nan     0.1000   -0.0004
   720        0.0636             nan     0.1000   -0.0005
   740        0.0585             nan     0.1000   -0.0004
   760        0.0546             nan     0.1000   -0.0006
   780        0.0517             nan     0.1000   -0.0004
   800        0.0492             nan     0.1000   -0.0004
   820        0.0466             nan     0.1000   -0.0004
   840        0.0445             nan     0.1000   -0.0003
   860        0.0427             nan     0.1000   -0.0002
   880        0.0407             nan     0.1000   -0.0005
   900        0.0388             nan     0.1000   -0.0001
   920        0.0372             nan     0.1000   -0.0005
   940        0.0353             nan     0.1000   -0.0002
   960        0.0334             nan     0.1000   -0.0004
   980        0.0315             nan     0.1000   -0.0003
  1000        0.0305             nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3067             nan     0.1000    0.0351
     2        1.2522             nan     0.1000    0.0182
     3        1.2113             nan     0.1000    0.0134
     4        1.1699             nan     0.1000    0.0138
     5        1.1236             nan     0.1000    0.0181
     6        1.0866             nan     0.1000    0.0098
     7        1.0461             nan     0.1000    0.0080
     8        1.0189             nan     0.1000    0.0065
     9        0.9976             nan     0.1000    0.0021
    10        0.9711             nan     0.1000    0.0073
    20        0.7874             nan     0.1000   -0.0030
    40        0.6107             nan     0.1000   -0.0002
    60        0.5084             nan     0.1000   -0.0023
    80        0.4352             nan     0.1000   -0.0034
   100        0.3785             nan     0.1000   -0.0034
   120        0.3325             nan     0.1000   -0.0033
   140        0.2954             nan     0.1000   -0.0029
   160        0.2593             nan     0.1000   -0.0019
   180        0.2297             nan     0.1000   -0.0011
   200        0.2071             nan     0.1000   -0.0019
   220        0.1825             nan     0.1000   -0.0012
   240        0.1659             nan     0.1000   -0.0011
   260        0.1474             nan     0.1000   -0.0011
   280        0.1338             nan     0.1000   -0.0016
   300        0.1232             nan     0.1000   -0.0011
   320        0.1103             nan     0.1000   -0.0014
   340        0.1005             nan     0.1000   -0.0013
   360        0.0893             nan     0.1000   -0.0008
   380        0.0802             nan     0.1000   -0.0009
   400        0.0740             nan     0.1000   -0.0009
   420        0.0664             nan     0.1000   -0.0005
   440        0.0596             nan     0.1000   -0.0005
   460        0.0543             nan     0.1000   -0.0004
   480        0.0489             nan     0.1000   -0.0011
   500        0.0444             nan     0.1000   -0.0004
   520        0.0404             nan     0.1000   -0.0003
   540        0.0372             nan     0.1000   -0.0003
   560        0.0337             nan     0.1000   -0.0004
   580        0.0311             nan     0.1000   -0.0003
   600        0.0284             nan     0.1000   -0.0004
   620        0.0251             nan     0.1000   -0.0003
   640        0.0227             nan     0.1000   -0.0002
   660        0.0209             nan     0.1000   -0.0004
   680        0.0189             nan     0.1000   -0.0002
   700        0.0167             nan     0.1000   -0.0001
   720        0.0153             nan     0.1000   -0.0002
   740        0.0141             nan     0.1000   -0.0001
   760        0.0128             nan     0.1000   -0.0001
   780        0.0117             nan     0.1000   -0.0001
   800        0.0105             nan     0.1000   -0.0001
   820        0.0095             nan     0.1000   -0.0001
   840        0.0088             nan     0.1000   -0.0001
   860        0.0079             nan     0.1000   -0.0001
   880        0.0072             nan     0.1000   -0.0001
   900        0.0066             nan     0.1000   -0.0000
   920        0.0060             nan     0.1000   -0.0000
   940        0.0057             nan     0.1000   -0.0001
   960        0.0052             nan     0.1000   -0.0000
   980        0.0047             nan     0.1000   -0.0000
  1000        0.0044             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3010             nan     0.1000    0.0298
     2        1.2446             nan     0.1000    0.0283
     3        1.2068             nan     0.1000    0.0170
     4        1.1707             nan     0.1000    0.0141
     5        1.1386             nan     0.1000    0.0069
     6        1.1100             nan     0.1000    0.0059
     7        1.0682             nan     0.1000    0.0142
     8        1.0427             nan     0.1000    0.0057
     9        1.0029             nan     0.1000    0.0027
    10        0.9789             nan     0.1000    0.0107
    20        0.8392             nan     0.1000   -0.0002
    40        0.6886             nan     0.1000    0.0005
    60        0.6230             nan     0.1000   -0.0027
    80        0.5868             nan     0.1000   -0.0022
   100        0.5488             nan     0.1000   -0.0014
   120        0.5311             nan     0.1000   -0.0028
   140        0.5054             nan     0.1000   -0.0040
   160        0.4911             nan     0.1000   -0.0010
   180        0.4743             nan     0.1000   -0.0011
   200        0.4582             nan     0.1000   -0.0022
   220        0.4499             nan     0.1000   -0.0030
   240        0.4354             nan     0.1000   -0.0021
   260        0.4234             nan     0.1000   -0.0010
   280        0.4118             nan     0.1000   -0.0007
   300        0.4003             nan     0.1000   -0.0023
   320        0.3965             nan     0.1000   -0.0040
   340        0.3853             nan     0.1000   -0.0021
   360        0.3739             nan     0.1000   -0.0028
   380        0.3682             nan     0.1000   -0.0024
   400        0.3589             nan     0.1000   -0.0051
   420        0.3497             nan     0.1000   -0.0031
   440        0.3404             nan     0.1000   -0.0032
   460        0.3291             nan     0.1000   -0.0020
   480        0.3260             nan     0.1000   -0.0026
   500        0.3168             nan     0.1000   -0.0019
   520        0.3074             nan     0.1000   -0.0021
   540        0.3015             nan     0.1000   -0.0012
   560        0.2974             nan     0.1000   -0.0017
   580        0.2883             nan     0.1000   -0.0012
   600        0.2850             nan     0.1000   -0.0032
   620        0.2770             nan     0.1000   -0.0007
   640        0.2716             nan     0.1000   -0.0017
   660        0.2635             nan     0.1000   -0.0013
   680        0.2543             nan     0.1000   -0.0022
   700        0.2491             nan     0.1000   -0.0020
   720        0.2418             nan     0.1000   -0.0005
   740        0.2369             nan     0.1000   -0.0011
   760        0.2321             nan     0.1000   -0.0011
   780        0.2284             nan     0.1000   -0.0014
   800        0.2233             nan     0.1000   -0.0019
   820        0.2209             nan     0.1000   -0.0020
   840        0.2173             nan     0.1000   -0.0020
   860        0.2123             nan     0.1000   -0.0009
   880        0.2076             nan     0.1000   -0.0011
   900        0.2061             nan     0.1000   -0.0009
   920        0.2018             nan     0.1000   -0.0023
   940        0.1973             nan     0.1000   -0.0024
   960        0.1938             nan     0.1000   -0.0004
   980        0.1944             nan     0.1000   -0.0015
  1000        0.1890             nan     0.1000   -0.0010

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2863             nan     0.1000    0.0406
     2        1.2141             nan     0.1000    0.0279
     3        1.1488             nan     0.1000    0.0266
     4        1.1031             nan     0.1000    0.0165
     5        1.0613             nan     0.1000    0.0131
     6        1.0153             nan     0.1000    0.0155
     7        0.9811             nan     0.1000    0.0115
     8        0.9523             nan     0.1000    0.0103
     9        0.9232             nan     0.1000    0.0058
    10        0.9039             nan     0.1000    0.0048
    20        0.7346             nan     0.1000   -0.0001
    40        0.5933             nan     0.1000   -0.0032
    60        0.5038             nan     0.1000   -0.0033
    80        0.4463             nan     0.1000   -0.0029
   100        0.3899             nan     0.1000   -0.0009
   120        0.3548             nan     0.1000   -0.0021
   140        0.3267             nan     0.1000   -0.0021
   160        0.2931             nan     0.1000   -0.0024
   180        0.2761             nan     0.1000   -0.0014
   200        0.2514             nan     0.1000   -0.0026
   220        0.2291             nan     0.1000   -0.0019
   240        0.2105             nan     0.1000   -0.0012
   260        0.1935             nan     0.1000   -0.0020
   280        0.1838             nan     0.1000   -0.0015
   300        0.1655             nan     0.1000   -0.0016
   320        0.1572             nan     0.1000   -0.0004
   340        0.1420             nan     0.1000   -0.0002
   360        0.1311             nan     0.1000   -0.0014
   380        0.1197             nan     0.1000   -0.0005
   400        0.1088             nan     0.1000   -0.0011
   420        0.1017             nan     0.1000   -0.0009
   440        0.0944             nan     0.1000   -0.0008
   460        0.0863             nan     0.1000   -0.0008
   480        0.0791             nan     0.1000   -0.0005
   500        0.0754             nan     0.1000   -0.0004
   520        0.0707             nan     0.1000   -0.0003
   540        0.0665             nan     0.1000   -0.0004
   560        0.0627             nan     0.1000   -0.0006
   580        0.0573             nan     0.1000   -0.0005
   600        0.0539             nan     0.1000   -0.0006
   620        0.0503             nan     0.1000   -0.0004
   640        0.0483             nan     0.1000   -0.0006
   660        0.0451             nan     0.1000   -0.0006
   680        0.0421             nan     0.1000   -0.0005
   700        0.0403             nan     0.1000   -0.0005
   720        0.0375             nan     0.1000   -0.0002
   740        0.0346             nan     0.1000   -0.0001
   760        0.0325             nan     0.1000   -0.0002
   780        0.0306             nan     0.1000   -0.0004
   800        0.0287             nan     0.1000   -0.0002
   820        0.0266             nan     0.1000   -0.0001
   840        0.0258             nan     0.1000   -0.0004
   860        0.0237             nan     0.1000   -0.0003
   880        0.0224             nan     0.1000   -0.0001
   900        0.0210             nan     0.1000   -0.0001
   920        0.0198             nan     0.1000   -0.0002
   940        0.0185             nan     0.1000   -0.0003
   960        0.0174             nan     0.1000   -0.0002
   980        0.0164             nan     0.1000   -0.0001
  1000        0.0153             nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2830             nan     0.1000    0.0401
     2        1.2104             nan     0.1000    0.0319
     3        1.1485             nan     0.1000    0.0279
     4        1.0857             nan     0.1000    0.0260
     5        1.0407             nan     0.1000    0.0232
     6        0.9951             nan     0.1000    0.0156
     7        0.9591             nan     0.1000    0.0138
     8        0.9187             nan     0.1000    0.0095
     9        0.8901             nan     0.1000    0.0077
    10        0.8690             nan     0.1000    0.0061
    20        0.6878             nan     0.1000   -0.0020
    40        0.5175             nan     0.1000   -0.0057
    60        0.4256             nan     0.1000   -0.0022
    80        0.3564             nan     0.1000   -0.0023
   100        0.3040             nan     0.1000   -0.0037
   120        0.2668             nan     0.1000   -0.0010
   140        0.2246             nan     0.1000   -0.0019
   160        0.1930             nan     0.1000   -0.0022
   180        0.1696             nan     0.1000   -0.0005
   200        0.1451             nan     0.1000   -0.0015
   220        0.1293             nan     0.1000   -0.0013
   240        0.1141             nan     0.1000   -0.0013
   260        0.1036             nan     0.1000   -0.0018
   280        0.0906             nan     0.1000   -0.0011
   300        0.0795             nan     0.1000   -0.0017
   320        0.0694             nan     0.1000   -0.0008
   340        0.0620             nan     0.1000   -0.0006
   360        0.0539             nan     0.1000   -0.0007
   380        0.0473             nan     0.1000   -0.0009
   400        0.0427             nan     0.1000   -0.0003
   420        0.0377             nan     0.1000   -0.0004
   440        0.0338             nan     0.1000   -0.0002
   460        0.0307             nan     0.1000   -0.0002
   480        0.0271             nan     0.1000   -0.0002
   500        0.0244             nan     0.1000   -0.0003
   520        0.0218             nan     0.1000   -0.0004
   540        0.0195             nan     0.1000   -0.0002
   560        0.0170             nan     0.1000   -0.0002
   580        0.0155             nan     0.1000   -0.0001
   600        0.0139             nan     0.1000   -0.0001
   620        0.0122             nan     0.1000   -0.0001
   640        0.0111             nan     0.1000   -0.0001
   660        0.0098             nan     0.1000   -0.0002
   680        0.0087             nan     0.1000   -0.0000
   700        0.0078             nan     0.1000   -0.0001
   720        0.0072             nan     0.1000   -0.0000
   740        0.0064             nan     0.1000   -0.0001
   760        0.0058             nan     0.1000   -0.0001
   780        0.0052             nan     0.1000   -0.0000
   800        0.0046             nan     0.1000   -0.0000
   820        0.0042             nan     0.1000   -0.0001
   840        0.0037             nan     0.1000   -0.0000
   860        0.0033             nan     0.1000   -0.0000
   880        0.0029             nan     0.1000   -0.0000
   900        0.0026             nan     0.1000   -0.0000
   920        0.0024             nan     0.1000   -0.0000
   940        0.0022             nan     0.1000   -0.0000
   960        0.0019             nan     0.1000   -0.0000
   980        0.0017             nan     0.1000   -0.0000
  1000        0.0015             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3368             nan     0.1000    0.0155
     2        1.2699             nan     0.1000    0.0237
     3        1.2379             nan     0.1000    0.0104
     4        1.2000             nan     0.1000    0.0185
     5        1.1668             nan     0.1000    0.0114
     6        1.1384             nan     0.1000    0.0040
     7        1.1069             nan     0.1000    0.0123
     8        1.0866             nan     0.1000    0.0038
     9        1.0593             nan     0.1000    0.0109
    10        1.0406             nan     0.1000    0.0031
    20        0.9010             nan     0.1000    0.0033
    40        0.7474             nan     0.1000   -0.0017
    60        0.6744             nan     0.1000    0.0011
    80        0.6246             nan     0.1000   -0.0015
   100        0.5904             nan     0.1000   -0.0020
   120        0.5777             nan     0.1000   -0.0063
   140        0.5528             nan     0.1000   -0.0013
   160        0.5299             nan     0.1000   -0.0009
   180        0.5126             nan     0.1000   -0.0014
   200        0.4933             nan     0.1000   -0.0018
   220        0.4753             nan     0.1000   -0.0029
   240        0.4570             nan     0.1000   -0.0008
   260        0.4480             nan     0.1000   -0.0032
   280        0.4455             nan     0.1000   -0.0018
   300        0.4339             nan     0.1000   -0.0034
   320        0.4250             nan     0.1000   -0.0019
   340        0.4129             nan     0.1000   -0.0007
   360        0.4020             nan     0.1000   -0.0013
   380        0.3924             nan     0.1000   -0.0007
   400        0.3867             nan     0.1000   -0.0017
   420        0.3743             nan     0.1000   -0.0022
   440        0.3660             nan     0.1000   -0.0038
   460        0.3551             nan     0.1000   -0.0037
   480        0.3473             nan     0.1000   -0.0034
   500        0.3414             nan     0.1000   -0.0015
   520        0.3392             nan     0.1000   -0.0015
   540        0.3290             nan     0.1000   -0.0034
   560        0.3253             nan     0.1000   -0.0028
   580        0.3188             nan     0.1000   -0.0033
   600        0.3113             nan     0.1000   -0.0014
   620        0.3073             nan     0.1000   -0.0006
   640        0.2960             nan     0.1000   -0.0009
   660        0.2936             nan     0.1000   -0.0014
   680        0.2891             nan     0.1000   -0.0022
   700        0.2799             nan     0.1000   -0.0011
   720        0.2767             nan     0.1000   -0.0024
   740        0.2722             nan     0.1000   -0.0033
   760        0.2672             nan     0.1000   -0.0028
   780        0.2595             nan     0.1000   -0.0015
   800        0.2549             nan     0.1000   -0.0013
   820        0.2483             nan     0.1000   -0.0024
   840        0.2436             nan     0.1000   -0.0010
   860        0.2371             nan     0.1000   -0.0009
   880        0.2318             nan     0.1000   -0.0003
   900        0.2288             nan     0.1000   -0.0011
   920        0.2272             nan     0.1000   -0.0009
   940        0.2238             nan     0.1000   -0.0012
   960        0.2191             nan     0.1000   -0.0008
   980        0.2167             nan     0.1000   -0.0020
  1000        0.2110             nan     0.1000   -0.0017

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3063             nan     0.1000    0.0336
     2        1.2520             nan     0.1000    0.0206
     3        1.1935             nan     0.1000    0.0228
     4        1.1527             nan     0.1000    0.0052
     5        1.1149             nan     0.1000    0.0106
     6        1.0744             nan     0.1000    0.0143
     7        1.0465             nan     0.1000    0.0128
     8        1.0116             nan     0.1000    0.0113
     9        0.9871             nan     0.1000    0.0087
    10        0.9633             nan     0.1000    0.0080
    20        0.7807             nan     0.1000   -0.0013
    40        0.6036             nan     0.1000   -0.0058
    60        0.5176             nan     0.1000   -0.0028
    80        0.4539             nan     0.1000   -0.0064
   100        0.4181             nan     0.1000   -0.0043
   120        0.3799             nan     0.1000   -0.0020
   140        0.3509             nan     0.1000   -0.0014
   160        0.3157             nan     0.1000   -0.0022
   180        0.2806             nan     0.1000   -0.0022
   200        0.2566             nan     0.1000   -0.0023
   220        0.2424             nan     0.1000   -0.0026
   240        0.2261             nan     0.1000   -0.0020
   260        0.2072             nan     0.1000   -0.0004
   280        0.1938             nan     0.1000   -0.0020
   300        0.1782             nan     0.1000   -0.0012
   320        0.1671             nan     0.1000   -0.0020
   340        0.1526             nan     0.1000   -0.0003
   360        0.1446             nan     0.1000   -0.0008
   380        0.1345             nan     0.1000   -0.0003
   400        0.1226             nan     0.1000   -0.0019
   420        0.1142             nan     0.1000   -0.0009
   440        0.1043             nan     0.1000   -0.0013
   460        0.0969             nan     0.1000   -0.0004
   480        0.0896             nan     0.1000   -0.0009
   500        0.0842             nan     0.1000   -0.0007
   520        0.0792             nan     0.1000   -0.0004
   540        0.0714             nan     0.1000   -0.0005
   560        0.0659             nan     0.1000   -0.0009
   580        0.0623             nan     0.1000   -0.0008
   600        0.0577             nan     0.1000   -0.0005
   620        0.0545             nan     0.1000   -0.0003
   640        0.0510             nan     0.1000   -0.0005
   660        0.0480             nan     0.1000   -0.0005
   680        0.0451             nan     0.1000   -0.0004
   700        0.0423             nan     0.1000   -0.0001
   720        0.0396             nan     0.1000   -0.0003
   740        0.0369             nan     0.1000   -0.0002
   760        0.0342             nan     0.1000   -0.0001
   780        0.0318             nan     0.1000   -0.0002
   800        0.0296             nan     0.1000   -0.0002
   820        0.0279             nan     0.1000   -0.0000
   840        0.0259             nan     0.1000   -0.0001
   860        0.0245             nan     0.1000   -0.0001
   880        0.0233             nan     0.1000   -0.0001
   900        0.0219             nan     0.1000   -0.0002
   920        0.0200             nan     0.1000   -0.0001
   940        0.0191             nan     0.1000   -0.0002
   960        0.0179             nan     0.1000   -0.0001
   980        0.0168             nan     0.1000   -0.0001
  1000        0.0159             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2989             nan     0.1000    0.0271
     2        1.2362             nan     0.1000    0.0200
     3        1.1734             nan     0.1000    0.0299
     4        1.1271             nan     0.1000    0.0237
     5        1.0879             nan     0.1000    0.0109
     6        1.0436             nan     0.1000    0.0150
     7        1.0144             nan     0.1000    0.0097
     8        0.9875             nan     0.1000    0.0016
     9        0.9586             nan     0.1000    0.0126
    10        0.9230             nan     0.1000    0.0094
    20        0.7246             nan     0.1000    0.0069
    40        0.5375             nan     0.1000   -0.0046
    60        0.4395             nan     0.1000   -0.0051
    80        0.3576             nan     0.1000   -0.0038
   100        0.2938             nan     0.1000   -0.0028
   120        0.2515             nan     0.1000   -0.0028
   140        0.2194             nan     0.1000   -0.0016
   160        0.1881             nan     0.1000   -0.0007
   180        0.1605             nan     0.1000   -0.0015
   200        0.1430             nan     0.1000   -0.0009
   220        0.1235             nan     0.1000   -0.0011
   240        0.1087             nan     0.1000   -0.0009
   260        0.0945             nan     0.1000   -0.0011
   280        0.0832             nan     0.1000   -0.0011
   300        0.0736             nan     0.1000   -0.0009
   320        0.0666             nan     0.1000   -0.0006
   340        0.0586             nan     0.1000   -0.0006
   360        0.0525             nan     0.1000   -0.0008
   380        0.0472             nan     0.1000   -0.0006
   400        0.0417             nan     0.1000   -0.0008
   420        0.0375             nan     0.1000   -0.0002
   440        0.0337             nan     0.1000   -0.0004
   460        0.0297             nan     0.1000   -0.0004
   480        0.0266             nan     0.1000   -0.0003
   500        0.0233             nan     0.1000   -0.0002
   520        0.0205             nan     0.1000   -0.0002
   540        0.0179             nan     0.1000   -0.0001
   560        0.0161             nan     0.1000   -0.0003
   580        0.0146             nan     0.1000   -0.0001
   600        0.0132             nan     0.1000   -0.0001
   620        0.0116             nan     0.1000   -0.0000
   640        0.0103             nan     0.1000   -0.0002
   660        0.0090             nan     0.1000   -0.0000
   680        0.0079             nan     0.1000   -0.0001
   700        0.0072             nan     0.1000   -0.0001
   720        0.0064             nan     0.1000   -0.0001
   740        0.0056             nan     0.1000   -0.0001
   760        0.0049             nan     0.1000   -0.0000
   780        0.0045             nan     0.1000   -0.0001
   800        0.0040             nan     0.1000   -0.0000
   820        0.0035             nan     0.1000   -0.0000
   840        0.0031             nan     0.1000   -0.0001
   860        0.0028             nan     0.1000   -0.0000
   880        0.0024             nan     0.1000   -0.0000
   900        0.0022             nan     0.1000   -0.0000
   920        0.0020             nan     0.1000   -0.0000
   940        0.0017             nan     0.1000   -0.0000
   960        0.0016             nan     0.1000   -0.0000
   980        0.0014             nan     0.1000   -0.0000
  1000        0.0013             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3029             nan     0.1000    0.0355
     2        1.2455             nan     0.1000    0.0283
     3        1.1934             nan     0.1000    0.0220
     4        1.1654             nan     0.1000    0.0067
     5        1.1345             nan     0.1000    0.0140
     6        1.1039             nan     0.1000    0.0108
     7        1.0707             nan     0.1000    0.0154
     8        1.0433             nan     0.1000    0.0103
     9        1.0270             nan     0.1000    0.0018
    10        1.0056             nan     0.1000    0.0041
    20        0.8719             nan     0.1000    0.0045
    40        0.7345             nan     0.1000   -0.0018
    60        0.6643             nan     0.1000   -0.0020
    80        0.6173             nan     0.1000   -0.0004
   100        0.5841             nan     0.1000   -0.0019
   120        0.5412             nan     0.1000   -0.0011
   140        0.5148             nan     0.1000   -0.0010
   160        0.4880             nan     0.1000   -0.0060
   180        0.4705             nan     0.1000   -0.0036
   200        0.4474             nan     0.1000   -0.0045
   220        0.4273             nan     0.1000   -0.0034
   240        0.4101             nan     0.1000   -0.0018
   260        0.3974             nan     0.1000   -0.0026
   280        0.3836             nan     0.1000   -0.0037
   300        0.3687             nan     0.1000   -0.0021
   320        0.3608             nan     0.1000   -0.0032
   340        0.3540             nan     0.1000   -0.0038
   360        0.3453             nan     0.1000   -0.0022
   380        0.3373             nan     0.1000   -0.0009
   400        0.3243             nan     0.1000   -0.0013
   420        0.3167             nan     0.1000   -0.0030
   440        0.3092             nan     0.1000   -0.0020
   460        0.3045             nan     0.1000   -0.0029
   480        0.2980             nan     0.1000   -0.0010
   500        0.2889             nan     0.1000   -0.0020
   520        0.2820             nan     0.1000   -0.0028
   540        0.2750             nan     0.1000   -0.0009
   560        0.2683             nan     0.1000   -0.0032
   580        0.2637             nan     0.1000   -0.0005
   600        0.2568             nan     0.1000   -0.0017
   620        0.2526             nan     0.1000   -0.0001
   640        0.2473             nan     0.1000   -0.0015
   660        0.2427             nan     0.1000   -0.0009
   680        0.2371             nan     0.1000   -0.0020
   700        0.2341             nan     0.1000   -0.0015
   720        0.2299             nan     0.1000   -0.0020
   740        0.2235             nan     0.1000   -0.0016
   760        0.2181             nan     0.1000   -0.0006
   780        0.2133             nan     0.1000   -0.0019
   800        0.2093             nan     0.1000   -0.0015
   820        0.2087             nan     0.1000   -0.0010
   840        0.2006             nan     0.1000   -0.0024
   860        0.1949             nan     0.1000   -0.0012
   880        0.1922             nan     0.1000   -0.0013
   900        0.1883             nan     0.1000   -0.0019
   920        0.1824             nan     0.1000   -0.0018
   940        0.1787             nan     0.1000   -0.0015
   960        0.1740             nan     0.1000   -0.0015
   980        0.1714             nan     0.1000   -0.0016
  1000        0.1688             nan     0.1000   -0.0027

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2924             nan     0.1000    0.0364
     2        1.2350             nan     0.1000    0.0218
     3        1.1838             nan     0.1000    0.0222
     4        1.1330             nan     0.1000    0.0170
     5        1.0933             nan     0.1000    0.0144
     6        1.0591             nan     0.1000    0.0160
     7        1.0241             nan     0.1000    0.0150
     8        0.9907             nan     0.1000    0.0138
     9        0.9618             nan     0.1000    0.0091
    10        0.9361             nan     0.1000    0.0085
    20        0.7564             nan     0.1000    0.0014
    40        0.6111             nan     0.1000   -0.0001
    60        0.5229             nan     0.1000   -0.0037
    80        0.4672             nan     0.1000   -0.0047
   100        0.4114             nan     0.1000   -0.0026
   120        0.3610             nan     0.1000   -0.0022
   140        0.3182             nan     0.1000   -0.0013
   160        0.2877             nan     0.1000   -0.0022
   180        0.2646             nan     0.1000   -0.0026
   200        0.2438             nan     0.1000   -0.0030
   220        0.2212             nan     0.1000   -0.0014
   240        0.2003             nan     0.1000   -0.0018
   260        0.1833             nan     0.1000   -0.0016
   280        0.1662             nan     0.1000   -0.0018
   300        0.1525             nan     0.1000   -0.0008
   320        0.1426             nan     0.1000   -0.0015
   340        0.1293             nan     0.1000   -0.0011
   360        0.1204             nan     0.1000   -0.0006
   380        0.1103             nan     0.1000   -0.0012
   400        0.1013             nan     0.1000   -0.0009
   420        0.0937             nan     0.1000   -0.0009
   440        0.0886             nan     0.1000   -0.0009
   460        0.0829             nan     0.1000   -0.0008
   480        0.0766             nan     0.1000   -0.0007
   500        0.0707             nan     0.1000   -0.0010
   520        0.0659             nan     0.1000   -0.0004
   540        0.0620             nan     0.1000   -0.0008
   560        0.0574             nan     0.1000   -0.0001
   580        0.0535             nan     0.1000   -0.0003
   600        0.0504             nan     0.1000   -0.0006
   620        0.0476             nan     0.1000   -0.0004
   640        0.0438             nan     0.1000   -0.0005
   660        0.0395             nan     0.1000   -0.0002
   680        0.0372             nan     0.1000   -0.0002
   700        0.0347             nan     0.1000   -0.0002
   720        0.0329             nan     0.1000   -0.0002
   740        0.0310             nan     0.1000   -0.0002
   760        0.0283             nan     0.1000   -0.0001
   780        0.0268             nan     0.1000   -0.0003
   800        0.0259             nan     0.1000   -0.0001
   820        0.0240             nan     0.1000   -0.0001
   840        0.0223             nan     0.1000   -0.0003
   860        0.0204             nan     0.1000   -0.0002
   880        0.0192             nan     0.1000   -0.0003
   900        0.0180             nan     0.1000   -0.0002
   920        0.0169             nan     0.1000   -0.0001
   940        0.0157             nan     0.1000   -0.0001
   960        0.0142             nan     0.1000   -0.0001
   980        0.0132             nan     0.1000   -0.0001
  1000        0.0122             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2892             nan     0.1000    0.0345
     2        1.2183             nan     0.1000    0.0347
     3        1.1554             nan     0.1000    0.0253
     4        1.0999             nan     0.1000    0.0169
     5        1.0571             nan     0.1000    0.0169
     6        1.0305             nan     0.1000    0.0082
     7        0.9937             nan     0.1000    0.0098
     8        0.9614             nan     0.1000    0.0108
     9        0.9292             nan     0.1000    0.0104
    10        0.9032             nan     0.1000    0.0026
    20        0.7133             nan     0.1000    0.0008
    40        0.5402             nan     0.1000   -0.0008
    60        0.4304             nan     0.1000   -0.0034
    80        0.3500             nan     0.1000   -0.0036
   100        0.2857             nan     0.1000    0.0003
   120        0.2322             nan     0.1000   -0.0023
   140        0.1993             nan     0.1000   -0.0026
   160        0.1803             nan     0.1000   -0.0025
   180        0.1549             nan     0.1000   -0.0023
   200        0.1319             nan     0.1000   -0.0011
   220        0.1179             nan     0.1000   -0.0013
   240        0.0984             nan     0.1000   -0.0007
   260        0.0870             nan     0.1000   -0.0003
   280        0.0761             nan     0.1000   -0.0006
   300        0.0674             nan     0.1000   -0.0004
   320        0.0604             nan     0.1000   -0.0004
   340        0.0537             nan     0.1000   -0.0003
   360        0.0480             nan     0.1000   -0.0008
   380        0.0406             nan     0.1000   -0.0002
   400        0.0366             nan     0.1000   -0.0004
   420        0.0333             nan     0.1000   -0.0005
   440        0.0297             nan     0.1000   -0.0005
   460        0.0269             nan     0.1000   -0.0005
   480        0.0241             nan     0.1000   -0.0003
   500        0.0214             nan     0.1000   -0.0002
   520        0.0196             nan     0.1000   -0.0002
   540        0.0174             nan     0.1000   -0.0002
   560        0.0153             nan     0.1000   -0.0003
   580        0.0138             nan     0.1000   -0.0001
   600        0.0122             nan     0.1000   -0.0001
   620        0.0107             nan     0.1000   -0.0001
   640        0.0096             nan     0.1000    0.0000
   660        0.0086             nan     0.1000   -0.0001
   680        0.0077             nan     0.1000   -0.0001
   700        0.0068             nan     0.1000   -0.0001
   720        0.0060             nan     0.1000   -0.0000
   740        0.0055             nan     0.1000   -0.0001
   760        0.0050             nan     0.1000   -0.0001
   780        0.0044             nan     0.1000   -0.0000
   800        0.0038             nan     0.1000   -0.0000
   820        0.0035             nan     0.1000   -0.0001
   840        0.0031             nan     0.1000   -0.0000
   860        0.0027             nan     0.1000   -0.0000
   880        0.0024             nan     0.1000   -0.0000
   900        0.0022             nan     0.1000   -0.0000
   920        0.0020             nan     0.1000   -0.0000
   940        0.0017             nan     0.1000   -0.0000
   960        0.0016             nan     0.1000   -0.0000
   980        0.0014             nan     0.1000   -0.0000
  1000        0.0012             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3087             nan     0.1000    0.0320
     2        1.2755             nan     0.1000    0.0124
     3        1.2251             nan     0.1000    0.0248
     4        1.1800             nan     0.1000    0.0184
     5        1.1523             nan     0.1000    0.0073
     6        1.1142             nan     0.1000    0.0131
     7        1.0930             nan     0.1000    0.0060
     8        1.0679             nan     0.1000    0.0075
     9        1.0404             nan     0.1000    0.0078
    10        1.0206             nan     0.1000    0.0065
    20        0.8895             nan     0.1000   -0.0005
    40        0.7471             nan     0.1000    0.0016
    60        0.6803             nan     0.1000   -0.0012
    80        0.6487             nan     0.1000   -0.0039
   100        0.6124             nan     0.1000   -0.0019
   120        0.5753             nan     0.1000   -0.0033
   140        0.5582             nan     0.1000   -0.0039
   160        0.5369             nan     0.1000   -0.0016
   180        0.5209             nan     0.1000   -0.0034
   200        0.5049             nan     0.1000   -0.0023
   220        0.4915             nan     0.1000   -0.0028
   240        0.4806             nan     0.1000   -0.0019
   260        0.4675             nan     0.1000   -0.0016
   280        0.4556             nan     0.1000   -0.0052
   300        0.4418             nan     0.1000   -0.0021
   320        0.4314             nan     0.1000   -0.0031
   340        0.4152             nan     0.1000   -0.0012
   360        0.4058             nan     0.1000   -0.0029
   380        0.3914             nan     0.1000   -0.0034
   400        0.3831             nan     0.1000   -0.0019
   420        0.3699             nan     0.1000   -0.0028
   440        0.3631             nan     0.1000   -0.0020
   460        0.3541             nan     0.1000   -0.0020
   480        0.3503             nan     0.1000   -0.0034
   500        0.3386             nan     0.1000   -0.0025
   520        0.3343             nan     0.1000   -0.0016
   540        0.3260             nan     0.1000   -0.0019
   560        0.3166             nan     0.1000   -0.0015
   580        0.3124             nan     0.1000   -0.0026
   600        0.3056             nan     0.1000   -0.0016
   620        0.2990             nan     0.1000   -0.0015
   640        0.2938             nan     0.1000   -0.0013
   660        0.2886             nan     0.1000   -0.0017
   680        0.2844             nan     0.1000   -0.0017
   700        0.2797             nan     0.1000   -0.0048
   720        0.2731             nan     0.1000   -0.0025
   740        0.2639             nan     0.1000   -0.0038
   760        0.2605             nan     0.1000   -0.0011
   780        0.2572             nan     0.1000   -0.0019
   800        0.2503             nan     0.1000   -0.0019
   820        0.2495             nan     0.1000   -0.0025
   840        0.2437             nan     0.1000   -0.0010
   860        0.2402             nan     0.1000   -0.0019
   880        0.2350             nan     0.1000   -0.0008
   900        0.2318             nan     0.1000   -0.0023
   920        0.2256             nan     0.1000   -0.0005
   940        0.2198             nan     0.1000   -0.0015
   960        0.2164             nan     0.1000   -0.0018
   980        0.2132             nan     0.1000   -0.0013
  1000        0.2105             nan     0.1000   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3062             nan     0.1000    0.0353
     2        1.2432             nan     0.1000    0.0244
     3        1.1883             nan     0.1000    0.0257
     4        1.1478             nan     0.1000    0.0168
     5        1.1032             nan     0.1000    0.0166
     6        1.0601             nan     0.1000    0.0164
     7        1.0306             nan     0.1000    0.0044
     8        1.0057             nan     0.1000    0.0098
     9        0.9791             nan     0.1000    0.0033
    10        0.9574             nan     0.1000    0.0072
    20        0.8008             nan     0.1000    0.0058
    40        0.6526             nan     0.1000   -0.0036
    60        0.5689             nan     0.1000   -0.0070
    80        0.5087             nan     0.1000   -0.0029
   100        0.4495             nan     0.1000   -0.0037
   120        0.4064             nan     0.1000   -0.0022
   140        0.3640             nan     0.1000   -0.0035
   160        0.3351             nan     0.1000   -0.0059
   180        0.3016             nan     0.1000   -0.0013
   200        0.2782             nan     0.1000   -0.0020
   220        0.2489             nan     0.1000   -0.0007
   240        0.2306             nan     0.1000   -0.0020
   260        0.2137             nan     0.1000   -0.0025
   280        0.1991             nan     0.1000   -0.0025
   300        0.1851             nan     0.1000   -0.0016
   320        0.1712             nan     0.1000   -0.0022
   340        0.1564             nan     0.1000   -0.0015
   360        0.1426             nan     0.1000   -0.0009
   380        0.1343             nan     0.1000   -0.0019
   400        0.1264             nan     0.1000   -0.0013
   420        0.1158             nan     0.1000   -0.0018
   440        0.1062             nan     0.1000   -0.0013
   460        0.0980             nan     0.1000   -0.0005
   480        0.0931             nan     0.1000   -0.0013
   500        0.0876             nan     0.1000   -0.0004
   520        0.0791             nan     0.1000   -0.0007
   540        0.0742             nan     0.1000   -0.0008
   560        0.0691             nan     0.1000   -0.0009
   580        0.0650             nan     0.1000   -0.0011
   600        0.0602             nan     0.1000   -0.0001
   620        0.0565             nan     0.1000   -0.0005
   640        0.0524             nan     0.1000   -0.0006
   660        0.0493             nan     0.1000   -0.0004
   680        0.0460             nan     0.1000   -0.0007
   700        0.0432             nan     0.1000   -0.0004
   720        0.0413             nan     0.1000   -0.0006
   740        0.0390             nan     0.1000   -0.0006
   760        0.0365             nan     0.1000   -0.0002
   780        0.0348             nan     0.1000   -0.0002
   800        0.0327             nan     0.1000   -0.0004
   820        0.0304             nan     0.1000   -0.0002
   840        0.0281             nan     0.1000   -0.0002
   860        0.0259             nan     0.1000   -0.0002
   880        0.0243             nan     0.1000   -0.0002
   900        0.0224             nan     0.1000   -0.0002
   920        0.0213             nan     0.1000   -0.0002
   940        0.0201             nan     0.1000   -0.0002
   960        0.0187             nan     0.1000   -0.0002
   980        0.0173             nan     0.1000   -0.0002
  1000        0.0161             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2999             nan     0.1000    0.0295
     2        1.2297             nan     0.1000    0.0298
     3        1.1699             nan     0.1000    0.0229
     4        1.1226             nan     0.1000    0.0180
     5        1.0746             nan     0.1000    0.0170
     6        1.0354             nan     0.1000    0.0106
     7        0.9938             nan     0.1000    0.0130
     8        0.9643             nan     0.1000    0.0117
     9        0.9327             nan     0.1000    0.0079
    10        0.9030             nan     0.1000    0.0078
    20        0.7245             nan     0.1000   -0.0004
    40        0.5416             nan     0.1000   -0.0015
    60        0.4431             nan     0.1000   -0.0028
    80        0.3669             nan     0.1000   -0.0004
   100        0.3095             nan     0.1000   -0.0021
   120        0.2699             nan     0.1000   -0.0041
   140        0.2338             nan     0.1000   -0.0011
   160        0.2065             nan     0.1000   -0.0030
   180        0.1818             nan     0.1000   -0.0029
   200        0.1594             nan     0.1000   -0.0016
   220        0.1415             nan     0.1000   -0.0026
   240        0.1227             nan     0.1000   -0.0015
   260        0.1087             nan     0.1000   -0.0011
   280        0.0982             nan     0.1000   -0.0012
   300        0.0858             nan     0.1000   -0.0009
   320        0.0778             nan     0.1000   -0.0006
   340        0.0688             nan     0.1000   -0.0007
   360        0.0599             nan     0.1000   -0.0009
   380        0.0537             nan     0.1000   -0.0006
   400        0.0470             nan     0.1000   -0.0005
   420        0.0422             nan     0.1000   -0.0003
   440        0.0381             nan     0.1000   -0.0004
   460        0.0341             nan     0.1000   -0.0005
   480        0.0308             nan     0.1000   -0.0002
   500        0.0277             nan     0.1000   -0.0002
   520        0.0246             nan     0.1000   -0.0002
   540        0.0222             nan     0.1000   -0.0002
   560        0.0200             nan     0.1000   -0.0001
   580        0.0176             nan     0.1000   -0.0002
   600        0.0157             nan     0.1000   -0.0002
   620        0.0142             nan     0.1000   -0.0001
   640        0.0123             nan     0.1000   -0.0001
   660        0.0108             nan     0.1000   -0.0001
   680        0.0096             nan     0.1000   -0.0001
   700        0.0087             nan     0.1000   -0.0001
   720        0.0077             nan     0.1000   -0.0001
   740        0.0069             nan     0.1000   -0.0001
   760        0.0062             nan     0.1000   -0.0000
   780        0.0054             nan     0.1000   -0.0000
   800        0.0048             nan     0.1000   -0.0000
   820        0.0044             nan     0.1000   -0.0001
   840        0.0039             nan     0.1000   -0.0000
   860        0.0035             nan     0.1000   -0.0000
   880        0.0032             nan     0.1000   -0.0001
   900        0.0028             nan     0.1000   -0.0000
   920        0.0025             nan     0.1000   -0.0000
   940        0.0023             nan     0.1000   -0.0000
   960        0.0020             nan     0.1000   -0.0000
   980        0.0018             nan     0.1000   -0.0000
  1000        0.0016             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3173             nan     0.1000    0.0229
     2        1.2830             nan     0.1000    0.0199
     3        1.2302             nan     0.1000    0.0144
     4        1.2047             nan     0.1000    0.0027
     5        1.1711             nan     0.1000    0.0078
     6        1.1378             nan     0.1000    0.0135
     7        1.1157             nan     0.1000    0.0088
     8        1.0944             nan     0.1000    0.0080
     9        1.0716             nan     0.1000    0.0095
    10        1.0558             nan     0.1000   -0.0019
    20        0.9286             nan     0.1000    0.0010
    40        0.7963             nan     0.1000   -0.0002
    60        0.7188             nan     0.1000   -0.0004
    80        0.6708             nan     0.1000   -0.0019
   100        0.6227             nan     0.1000   -0.0029
   120        0.5881             nan     0.1000    0.0005
   140        0.5579             nan     0.1000   -0.0012
   160        0.5356             nan     0.1000   -0.0011
   180        0.5115             nan     0.1000   -0.0044
   200        0.4962             nan     0.1000   -0.0040
   220        0.4798             nan     0.1000    0.0001
   240        0.4648             nan     0.1000   -0.0015
   260        0.4533             nan     0.1000   -0.0020
   280        0.4393             nan     0.1000   -0.0005
   300        0.4253             nan     0.1000   -0.0021
   320        0.4143             nan     0.1000   -0.0056
   340        0.3990             nan     0.1000   -0.0016
   360        0.3883             nan     0.1000   -0.0016
   380        0.3805             nan     0.1000   -0.0025
   400        0.3728             nan     0.1000   -0.0009
   420        0.3579             nan     0.1000   -0.0017
   440        0.3511             nan     0.1000   -0.0029
   460        0.3414             nan     0.1000   -0.0006
   480        0.3353             nan     0.1000   -0.0015
   500        0.3271             nan     0.1000   -0.0011
   520        0.3199             nan     0.1000   -0.0041
   540        0.3142             nan     0.1000   -0.0021
   560        0.3096             nan     0.1000   -0.0009
   580        0.3004             nan     0.1000   -0.0008
   600        0.2994             nan     0.1000   -0.0018
   620        0.2893             nan     0.1000   -0.0014
   640        0.2800             nan     0.1000   -0.0009
   660        0.2726             nan     0.1000   -0.0035
   680        0.2673             nan     0.1000   -0.0015
   700        0.2622             nan     0.1000   -0.0022
   720        0.2542             nan     0.1000   -0.0029
   740        0.2475             nan     0.1000   -0.0010
   760        0.2438             nan     0.1000   -0.0009
   780        0.2400             nan     0.1000   -0.0017
   800        0.2376             nan     0.1000   -0.0014
   820        0.2328             nan     0.1000   -0.0006
   840        0.2280             nan     0.1000   -0.0009
   860        0.2248             nan     0.1000   -0.0027
   880        0.2226             nan     0.1000   -0.0019
   900        0.2159             nan     0.1000   -0.0013
   920        0.2128             nan     0.1000   -0.0042
   940        0.2105             nan     0.1000   -0.0011
   960        0.2052             nan     0.1000   -0.0033
   980        0.2013             nan     0.1000   -0.0011
  1000        0.1987             nan     0.1000   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3029             nan     0.1000    0.0282
     2        1.2470             nan     0.1000    0.0241
     3        1.1939             nan     0.1000    0.0167
     4        1.1573             nan     0.1000    0.0145
     5        1.1361             nan     0.1000    0.0006
     6        1.0952             nan     0.1000    0.0166
     7        1.0668             nan     0.1000    0.0104
     8        1.0397             nan     0.1000    0.0068
     9        1.0159             nan     0.1000    0.0080
    10        0.9896             nan     0.1000    0.0040
    20        0.8118             nan     0.1000   -0.0022
    40        0.6773             nan     0.1000   -0.0013
    60        0.5663             nan     0.1000    0.0000
    80        0.4985             nan     0.1000   -0.0037
   100        0.4505             nan     0.1000   -0.0020
   120        0.4053             nan     0.1000   -0.0029
   140        0.3709             nan     0.1000   -0.0039
   160        0.3449             nan     0.1000   -0.0035
   180        0.3221             nan     0.1000   -0.0033
   200        0.2991             nan     0.1000   -0.0024
   220        0.2777             nan     0.1000   -0.0019
   240        0.2658             nan     0.1000   -0.0024
   260        0.2470             nan     0.1000   -0.0004
   280        0.2321             nan     0.1000   -0.0034
   300        0.2184             nan     0.1000   -0.0018
   320        0.2011             nan     0.1000   -0.0004
   340        0.1863             nan     0.1000   -0.0015
   360        0.1726             nan     0.1000   -0.0012
   380        0.1657             nan     0.1000   -0.0014
   400        0.1540             nan     0.1000   -0.0010
   420        0.1432             nan     0.1000   -0.0020
   440        0.1317             nan     0.1000   -0.0019
   460        0.1231             nan     0.1000   -0.0009
   480        0.1140             nan     0.1000   -0.0013
   500        0.1064             nan     0.1000   -0.0005
   520        0.0999             nan     0.1000   -0.0015
   540        0.0930             nan     0.1000   -0.0008
   560        0.0876             nan     0.1000   -0.0004
   580        0.0831             nan     0.1000   -0.0008
   600        0.0786             nan     0.1000   -0.0004
   620        0.0739             nan     0.1000   -0.0005
   640        0.0705             nan     0.1000   -0.0007
   660        0.0660             nan     0.1000   -0.0004
   680        0.0624             nan     0.1000   -0.0008
   700        0.0586             nan     0.1000   -0.0002
   720        0.0545             nan     0.1000   -0.0005
   740        0.0512             nan     0.1000   -0.0007
   760        0.0484             nan     0.1000   -0.0004
   780        0.0460             nan     0.1000   -0.0003
   800        0.0424             nan     0.1000   -0.0003
   820        0.0403             nan     0.1000   -0.0005
   840        0.0377             nan     0.1000   -0.0003
   860        0.0358             nan     0.1000   -0.0002
   880        0.0339             nan     0.1000   -0.0002
   900        0.0319             nan     0.1000   -0.0003
   920        0.0298             nan     0.1000   -0.0000
   940        0.0284             nan     0.1000   -0.0001
   960        0.0267             nan     0.1000   -0.0001
   980        0.0255             nan     0.1000   -0.0003
  1000        0.0238             nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3123             nan     0.1000    0.0280
     2        1.2437             nan     0.1000    0.0308
     3        1.1916             nan     0.1000    0.0223
     4        1.1520             nan     0.1000    0.0127
     5        1.1069             nan     0.1000    0.0112
     6        1.0752             nan     0.1000    0.0104
     7        1.0367             nan     0.1000    0.0128
     8        1.0013             nan     0.1000    0.0105
     9        0.9699             nan     0.1000    0.0098
    10        0.9410             nan     0.1000    0.0069
    20        0.7707             nan     0.1000    0.0014
    40        0.5925             nan     0.1000   -0.0055
    60        0.4839             nan     0.1000   -0.0050
    80        0.4216             nan     0.1000   -0.0056
   100        0.3640             nan     0.1000   -0.0039
   120        0.3076             nan     0.1000   -0.0024
   140        0.2625             nan     0.1000   -0.0049
   160        0.2224             nan     0.1000   -0.0015
   180        0.1893             nan     0.1000   -0.0010
   200        0.1692             nan     0.1000   -0.0008
   220        0.1548             nan     0.1000   -0.0016
   240        0.1396             nan     0.1000   -0.0008
   260        0.1242             nan     0.1000   -0.0010
   280        0.1127             nan     0.1000   -0.0016
   300        0.0996             nan     0.1000   -0.0010
   320        0.0875             nan     0.1000   -0.0008
   340        0.0792             nan     0.1000   -0.0005
   360        0.0690             nan     0.1000   -0.0004
   380        0.0625             nan     0.1000   -0.0005
   400        0.0548             nan     0.1000   -0.0005
   420        0.0497             nan     0.1000   -0.0004
   440        0.0442             nan     0.1000   -0.0003
   460        0.0396             nan     0.1000   -0.0002
   480        0.0351             nan     0.1000   -0.0004
   500        0.0312             nan     0.1000   -0.0003
   520        0.0276             nan     0.1000   -0.0001
   540        0.0251             nan     0.1000   -0.0001
   560        0.0229             nan     0.1000   -0.0006
   580        0.0201             nan     0.1000   -0.0002
   600        0.0182             nan     0.1000   -0.0002
   620        0.0167             nan     0.1000   -0.0002
   640        0.0148             nan     0.1000   -0.0002
   660        0.0136             nan     0.1000   -0.0001
   680        0.0122             nan     0.1000   -0.0002
   700        0.0110             nan     0.1000   -0.0001
   720        0.0101             nan     0.1000   -0.0001
   740        0.0090             nan     0.1000   -0.0000
   760        0.0082             nan     0.1000   -0.0001
   780        0.0075             nan     0.1000   -0.0001
   800        0.0066             nan     0.1000   -0.0001
   820        0.0060             nan     0.1000   -0.0001
   840        0.0055             nan     0.1000   -0.0001
   860        0.0050             nan     0.1000   -0.0001
   880        0.0045             nan     0.1000   -0.0000
   900        0.0041             nan     0.1000   -0.0000
   920        0.0036             nan     0.1000   -0.0000
   940        0.0033             nan     0.1000   -0.0000
   960        0.0030             nan     0.1000   -0.0000
   980        0.0027             nan     0.1000   -0.0000
  1000        0.0024             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3185             nan     0.1000    0.0314
     2        1.2663             nan     0.1000    0.0261
     3        1.2273             nan     0.1000    0.0197
     4        1.1893             nan     0.1000    0.0130
     5        1.1520             nan     0.1000    0.0135
     6        1.1286             nan     0.1000    0.0107
     7        1.1030             nan     0.1000    0.0095
     8        1.0780             nan     0.1000    0.0116
     9        1.0582             nan     0.1000    0.0075
    10        1.0387             nan     0.1000    0.0072
    20        0.9064             nan     0.1000    0.0010
    40        0.7777             nan     0.1000   -0.0009
    60        0.6893             nan     0.1000   -0.0047
    80        0.6398             nan     0.1000   -0.0044
   100        0.5995             nan     0.1000   -0.0031
   120        0.5653             nan     0.1000   -0.0012
   140        0.5406             nan     0.1000   -0.0013
   160        0.5156             nan     0.1000   -0.0020
   180        0.4997             nan     0.1000   -0.0024
   200        0.4851             nan     0.1000   -0.0022
   220        0.4667             nan     0.1000   -0.0022
   240        0.4566             nan     0.1000   -0.0016
   260        0.4373             nan     0.1000   -0.0032
   280        0.4206             nan     0.1000   -0.0034
   300        0.4055             nan     0.1000   -0.0021
   320        0.3969             nan     0.1000   -0.0026
   340        0.3836             nan     0.1000   -0.0027
   360        0.3723             nan     0.1000   -0.0021
   380        0.3629             nan     0.1000   -0.0043
   400        0.3527             nan     0.1000   -0.0030
   420        0.3418             nan     0.1000   -0.0021
   440        0.3312             nan     0.1000   -0.0012
   460        0.3231             nan     0.1000   -0.0017
   480        0.3160             nan     0.1000   -0.0032
   500        0.3045             nan     0.1000   -0.0011
   520        0.2978             nan     0.1000   -0.0018
   540        0.2896             nan     0.1000   -0.0024
   560        0.2788             nan     0.1000   -0.0020
   580        0.2728             nan     0.1000   -0.0026
   600        0.2620             nan     0.1000   -0.0022
   620        0.2580             nan     0.1000   -0.0023
   640        0.2481             nan     0.1000   -0.0010
   660        0.2410             nan     0.1000   -0.0014
   680        0.2381             nan     0.1000   -0.0028
   700        0.2332             nan     0.1000   -0.0018
   720        0.2289             nan     0.1000   -0.0021
   740        0.2242             nan     0.1000   -0.0013
   760        0.2181             nan     0.1000   -0.0016
   780        0.2144             nan     0.1000   -0.0008
   800        0.2100             nan     0.1000   -0.0014
   820        0.2045             nan     0.1000   -0.0031
   840        0.1996             nan     0.1000   -0.0011
   860        0.1955             nan     0.1000   -0.0014
   880        0.1939             nan     0.1000   -0.0015
   900        0.1887             nan     0.1000   -0.0014
   920        0.1835             nan     0.1000   -0.0019
   940        0.1779             nan     0.1000   -0.0012
   960        0.1745             nan     0.1000   -0.0020
   980        0.1725             nan     0.1000   -0.0013
  1000        0.1703             nan     0.1000   -0.0007

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2967             nan     0.1000    0.0347
     2        1.2390             nan     0.1000    0.0248
     3        1.1797             nan     0.1000    0.0258
     4        1.1333             nan     0.1000    0.0217
     5        1.0941             nan     0.1000    0.0131
     6        1.0563             nan     0.1000    0.0151
     7        1.0257             nan     0.1000    0.0073
     8        0.9977             nan     0.1000    0.0082
     9        0.9765             nan     0.1000    0.0045
    10        0.9588             nan     0.1000    0.0036
    20        0.7908             nan     0.1000    0.0043
    40        0.6108             nan     0.1000   -0.0034
    60        0.5286             nan     0.1000   -0.0031
    80        0.4642             nan     0.1000   -0.0048
   100        0.4075             nan     0.1000   -0.0022
   120        0.3680             nan     0.1000   -0.0031
   140        0.3388             nan     0.1000   -0.0010
   160        0.3144             nan     0.1000   -0.0017
   180        0.2839             nan     0.1000   -0.0040
   200        0.2601             nan     0.1000   -0.0001
   220        0.2356             nan     0.1000   -0.0014
   240        0.2212             nan     0.1000   -0.0028
   260        0.2025             nan     0.1000   -0.0011
   280        0.1855             nan     0.1000   -0.0018
   300        0.1698             nan     0.1000   -0.0021
   320        0.1543             nan     0.1000   -0.0013
   340        0.1430             nan     0.1000   -0.0009
   360        0.1311             nan     0.1000   -0.0011
   380        0.1215             nan     0.1000   -0.0013
   400        0.1128             nan     0.1000   -0.0014
   420        0.1038             nan     0.1000   -0.0007
   440        0.0975             nan     0.1000   -0.0013
   460        0.0885             nan     0.1000   -0.0001
   480        0.0837             nan     0.1000   -0.0007
   500        0.0785             nan     0.1000   -0.0007
   520        0.0715             nan     0.1000   -0.0007
   540        0.0678             nan     0.1000   -0.0008
   560        0.0620             nan     0.1000   -0.0008
   580        0.0584             nan     0.1000   -0.0009
   600        0.0545             nan     0.1000   -0.0000
   620        0.0501             nan     0.1000   -0.0003
   640        0.0468             nan     0.1000   -0.0005
   660        0.0433             nan     0.1000   -0.0004
   680        0.0418             nan     0.1000   -0.0005
   700        0.0387             nan     0.1000   -0.0004
   720        0.0351             nan     0.1000   -0.0003
   740        0.0326             nan     0.1000   -0.0001
   760        0.0303             nan     0.1000   -0.0002
   780        0.0279             nan     0.1000   -0.0002
   800        0.0259             nan     0.1000   -0.0003
   820        0.0242             nan     0.1000   -0.0001
   840        0.0226             nan     0.1000   -0.0003
   860        0.0211             nan     0.1000   -0.0002
   880        0.0193             nan     0.1000   -0.0001
   900        0.0178             nan     0.1000   -0.0001
   920        0.0166             nan     0.1000   -0.0001
   940        0.0152             nan     0.1000   -0.0002
   960        0.0141             nan     0.1000   -0.0000
   980        0.0132             nan     0.1000   -0.0001
  1000        0.0123             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2988             nan     0.1000    0.0336
     2        1.2264             nan     0.1000    0.0312
     3        1.1790             nan     0.1000    0.0165
     4        1.1287             nan     0.1000    0.0238
     5        1.0831             nan     0.1000    0.0158
     6        1.0443             nan     0.1000    0.0137
     7        1.0049             nan     0.1000    0.0122
     8        0.9701             nan     0.1000    0.0097
     9        0.9371             nan     0.1000    0.0113
    10        0.9059             nan     0.1000    0.0116
    20        0.7251             nan     0.1000   -0.0021
    40        0.5520             nan     0.1000   -0.0032
    60        0.4387             nan     0.1000   -0.0018
    80        0.3520             nan     0.1000   -0.0031
   100        0.2980             nan     0.1000   -0.0038
   120        0.2542             nan     0.1000   -0.0005
   140        0.2161             nan     0.1000   -0.0031
   160        0.1798             nan     0.1000   -0.0021
   180        0.1580             nan     0.1000   -0.0036
   200        0.1385             nan     0.1000   -0.0011
   220        0.1191             nan     0.1000   -0.0011
   240        0.1034             nan     0.1000   -0.0005
   260        0.0904             nan     0.1000   -0.0004
   280        0.0769             nan     0.1000   -0.0005
   300        0.0674             nan     0.1000   -0.0001
   320        0.0595             nan     0.1000   -0.0006
   340        0.0524             nan     0.1000   -0.0007
   360        0.0457             nan     0.1000   -0.0004
   380        0.0395             nan     0.1000   -0.0003
   400        0.0348             nan     0.1000   -0.0001
   420        0.0312             nan     0.1000   -0.0002
   440        0.0275             nan     0.1000   -0.0002
   460        0.0249             nan     0.1000   -0.0002
   480        0.0225             nan     0.1000   -0.0003
   500        0.0196             nan     0.1000   -0.0001
   520        0.0171             nan     0.1000   -0.0002
   540        0.0151             nan     0.1000   -0.0001
   560        0.0134             nan     0.1000   -0.0001
   580        0.0118             nan     0.1000   -0.0001
   600        0.0107             nan     0.1000   -0.0002
   620        0.0094             nan     0.1000   -0.0001
   640        0.0082             nan     0.1000   -0.0000
   660        0.0072             nan     0.1000   -0.0001
   680        0.0064             nan     0.1000   -0.0000
   700        0.0059             nan     0.1000   -0.0001
   720        0.0053             nan     0.1000   -0.0001
   740        0.0046             nan     0.1000   -0.0000
   760        0.0041             nan     0.1000   -0.0000
   780        0.0036             nan     0.1000   -0.0000
   800        0.0031             nan     0.1000   -0.0000
   820        0.0028             nan     0.1000   -0.0000
   840        0.0026             nan     0.1000   -0.0000
   860        0.0022             nan     0.1000   -0.0000
   880        0.0020             nan     0.1000   -0.0000
   900        0.0018             nan     0.1000   -0.0000
   920        0.0016             nan     0.1000   -0.0000
   940        0.0014             nan     0.1000   -0.0000
   960        0.0012             nan     0.1000   -0.0000
   980        0.0011             nan     0.1000   -0.0000
  1000        0.0010             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3051             nan     0.1000    0.0289
     2        1.2461             nan     0.1000    0.0220
     3        1.2096             nan     0.1000    0.0175
     4        1.1772             nan     0.1000    0.0130
     5        1.1629             nan     0.1000    0.0026
     6        1.1363             nan     0.1000    0.0092
     7        1.1075             nan     0.1000    0.0088
     8        1.0866             nan     0.1000    0.0084
     9        1.0593             nan     0.1000    0.0059
    10        1.0430             nan     0.1000    0.0016
    20        0.9218             nan     0.1000   -0.0005
    40        0.8027             nan     0.1000   -0.0023
    60        0.7393             nan     0.1000   -0.0022
    80        0.7001             nan     0.1000   -0.0022
   100        0.6690             nan     0.1000   -0.0014
   120        0.6347             nan     0.1000   -0.0045
   140        0.6144             nan     0.1000   -0.0016
   160        0.5987             nan     0.1000   -0.0026
   180        0.5730             nan     0.1000   -0.0026
   200        0.5572             nan     0.1000   -0.0017
   220        0.5395             nan     0.1000   -0.0042
   240        0.5234             nan     0.1000   -0.0012
   260        0.5093             nan     0.1000   -0.0053
   280        0.4939             nan     0.1000   -0.0024
   300        0.4795             nan     0.1000   -0.0023
   320        0.4683             nan     0.1000   -0.0032
   340        0.4579             nan     0.1000   -0.0013
   360        0.4486             nan     0.1000   -0.0032
   380        0.4375             nan     0.1000   -0.0044
   400        0.4288             nan     0.1000   -0.0049
   420        0.4215             nan     0.1000   -0.0013
   440        0.4105             nan     0.1000   -0.0021
   460        0.4004             nan     0.1000   -0.0008
   480        0.3968             nan     0.1000   -0.0016
   500        0.3892             nan     0.1000   -0.0037
   520        0.3795             nan     0.1000    0.0000
   540        0.3731             nan     0.1000   -0.0020
   560        0.3643             nan     0.1000   -0.0016
   580        0.3606             nan     0.1000   -0.0021
   600        0.3529             nan     0.1000   -0.0030
   620        0.3512             nan     0.1000   -0.0036
   640        0.3406             nan     0.1000   -0.0017
   660        0.3328             nan     0.1000   -0.0030
   680        0.3299             nan     0.1000   -0.0017
   700        0.3255             nan     0.1000   -0.0011
   720        0.3170             nan     0.1000   -0.0006
   740        0.3105             nan     0.1000   -0.0005
   760        0.3070             nan     0.1000   -0.0009
   780        0.2988             nan     0.1000   -0.0005
   800        0.2948             nan     0.1000   -0.0029
   820        0.2879             nan     0.1000   -0.0017
   840        0.2829             nan     0.1000   -0.0015
   860        0.2767             nan     0.1000   -0.0023
   880        0.2740             nan     0.1000   -0.0029
   900        0.2677             nan     0.1000   -0.0015
   920        0.2629             nan     0.1000   -0.0014
   940        0.2586             nan     0.1000   -0.0026
   960        0.2533             nan     0.1000   -0.0009
   980        0.2521             nan     0.1000   -0.0009
  1000        0.2452             nan     0.1000   -0.0010

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3186             nan     0.1000    0.0225
     2        1.2468             nan     0.1000    0.0285
     3        1.2056             nan     0.1000    0.0157
     4        1.1545             nan     0.1000    0.0205
     5        1.1250             nan     0.1000    0.0099
     6        1.1004             nan     0.1000    0.0022
     7        1.0676             nan     0.1000    0.0079
     8        1.0412             nan     0.1000    0.0059
     9        1.0111             nan     0.1000    0.0075
    10        0.9877             nan     0.1000    0.0076
    20        0.8450             nan     0.1000   -0.0046
    40        0.6802             nan     0.1000   -0.0020
    60        0.5912             nan     0.1000   -0.0043
    80        0.5306             nan     0.1000   -0.0031
   100        0.4864             nan     0.1000   -0.0042
   120        0.4413             nan     0.1000   -0.0026
   140        0.4054             nan     0.1000   -0.0022
   160        0.3790             nan     0.1000   -0.0028
   180        0.3521             nan     0.1000   -0.0008
   200        0.3284             nan     0.1000   -0.0024
   220        0.3053             nan     0.1000   -0.0030
   240        0.2855             nan     0.1000   -0.0038
   260        0.2690             nan     0.1000   -0.0032
   280        0.2469             nan     0.1000   -0.0009
   300        0.2285             nan     0.1000   -0.0022
   320        0.2122             nan     0.1000   -0.0003
   340        0.2009             nan     0.1000   -0.0018
   360        0.1872             nan     0.1000   -0.0015
   380        0.1742             nan     0.1000   -0.0012
   400        0.1637             nan     0.1000   -0.0020
   420        0.1533             nan     0.1000   -0.0012
   440        0.1439             nan     0.1000   -0.0004
   460        0.1355             nan     0.1000   -0.0018
   480        0.1268             nan     0.1000   -0.0002
   500        0.1197             nan     0.1000   -0.0011
   520        0.1113             nan     0.1000   -0.0011
   540        0.1047             nan     0.1000   -0.0017
   560        0.0990             nan     0.1000   -0.0004
   580        0.0938             nan     0.1000   -0.0006
   600        0.0879             nan     0.1000   -0.0002
   620        0.0841             nan     0.1000   -0.0009
   640        0.0794             nan     0.1000   -0.0008
   660        0.0751             nan     0.1000   -0.0007
   680        0.0711             nan     0.1000   -0.0011
   700        0.0679             nan     0.1000   -0.0006
   720        0.0636             nan     0.1000   -0.0004
   740        0.0599             nan     0.1000   -0.0003
   760        0.0566             nan     0.1000   -0.0005
   780        0.0541             nan     0.1000   -0.0003
   800        0.0513             nan     0.1000   -0.0002
   820        0.0489             nan     0.1000   -0.0002
   840        0.0457             nan     0.1000   -0.0003
   860        0.0439             nan     0.1000   -0.0003
   880        0.0412             nan     0.1000   -0.0003
   900        0.0388             nan     0.1000   -0.0001
   920        0.0366             nan     0.1000   -0.0002
   940        0.0345             nan     0.1000   -0.0002
   960        0.0330             nan     0.1000   -0.0001
   980        0.0318             nan     0.1000   -0.0002
  1000        0.0305             nan     0.1000   -0.0003

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2893             nan     0.1000    0.0387
     2        1.2275             nan     0.1000    0.0185
     3        1.1716             nan     0.1000    0.0138
     4        1.1152             nan     0.1000    0.0197
     5        1.0801             nan     0.1000    0.0139
     6        1.0427             nan     0.1000    0.0114
     7        1.0136             nan     0.1000    0.0089
     8        0.9912             nan     0.1000    0.0020
     9        0.9607             nan     0.1000    0.0091
    10        0.9334             nan     0.1000    0.0067
    20        0.7716             nan     0.1000   -0.0044
    40        0.6044             nan     0.1000   -0.0045
    60        0.5041             nan     0.1000   -0.0028
    80        0.4367             nan     0.1000   -0.0028
   100        0.3797             nan     0.1000   -0.0001
   120        0.3275             nan     0.1000   -0.0064
   140        0.2822             nan     0.1000   -0.0011
   160        0.2461             nan     0.1000   -0.0013
   180        0.2175             nan     0.1000   -0.0025
   200        0.1915             nan     0.1000   -0.0015
   220        0.1721             nan     0.1000   -0.0019
   240        0.1520             nan     0.1000   -0.0020
   260        0.1363             nan     0.1000   -0.0011
   280        0.1225             nan     0.1000   -0.0011
   300        0.1106             nan     0.1000   -0.0006
   320        0.0984             nan     0.1000   -0.0011
   340        0.0917             nan     0.1000   -0.0015
   360        0.0839             nan     0.1000   -0.0006
   380        0.0762             nan     0.1000   -0.0005
   400        0.0691             nan     0.1000   -0.0009
   420        0.0631             nan     0.1000   -0.0007
   440        0.0581             nan     0.1000   -0.0005
   460        0.0533             nan     0.1000   -0.0008
   480        0.0479             nan     0.1000   -0.0002
   500        0.0443             nan     0.1000   -0.0002
   520        0.0401             nan     0.1000   -0.0004
   540        0.0364             nan     0.1000   -0.0003
   560        0.0334             nan     0.1000   -0.0003
   580        0.0302             nan     0.1000   -0.0003
   600        0.0274             nan     0.1000   -0.0002
   620        0.0246             nan     0.1000   -0.0003
   640        0.0226             nan     0.1000   -0.0002
   660        0.0206             nan     0.1000   -0.0003
   680        0.0185             nan     0.1000   -0.0003
   700        0.0171             nan     0.1000   -0.0003
   720        0.0153             nan     0.1000   -0.0001
   740        0.0137             nan     0.1000   -0.0001
   760        0.0127             nan     0.1000   -0.0001
   780        0.0116             nan     0.1000   -0.0000
   800        0.0108             nan     0.1000   -0.0001
   820        0.0099             nan     0.1000   -0.0001
   840        0.0089             nan     0.1000   -0.0001
   860        0.0080             nan     0.1000   -0.0001
   880        0.0074             nan     0.1000   -0.0001
   900        0.0069             nan     0.1000   -0.0001
   920        0.0062             nan     0.1000   -0.0000
   940        0.0057             nan     0.1000   -0.0000
   960        0.0051             nan     0.1000   -0.0001
   980        0.0046             nan     0.1000   -0.0000
  1000        0.0041             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3258             nan     0.1000    0.0163
     2        1.2614             nan     0.1000    0.0282
     3        1.2184             nan     0.1000    0.0226
     4        1.1761             nan     0.1000    0.0184
     5        1.1495             nan     0.1000    0.0111
     6        1.1256             nan     0.1000    0.0134
     7        1.1017             nan     0.1000    0.0072
     8        1.0719             nan     0.1000    0.0128
     9        1.0470             nan     0.1000    0.0067
    10        1.0233             nan     0.1000    0.0083
    20        0.8767             nan     0.1000    0.0003
    40        0.7401             nan     0.1000    0.0007
    60        0.6713             nan     0.1000   -0.0013
    80        0.6302             nan     0.1000   -0.0035
   100        0.6069             nan     0.1000   -0.0073
   120        0.5762             nan     0.1000   -0.0009
   140        0.5558             nan     0.1000   -0.0041
   160        0.5376             nan     0.1000   -0.0026
   180        0.5178             nan     0.1000   -0.0020
   200        0.5018             nan     0.1000   -0.0051
   220        0.4854             nan     0.1000   -0.0020
   240        0.4679             nan     0.1000   -0.0044
   260        0.4576             nan     0.1000   -0.0031
   280        0.4478             nan     0.1000   -0.0022
   300        0.4376             nan     0.1000   -0.0019
   320        0.4263             nan     0.1000   -0.0032
   340        0.4195             nan     0.1000   -0.0046
   360        0.4094             nan     0.1000   -0.0021
   380        0.4038             nan     0.1000   -0.0013
   400        0.3941             nan     0.1000   -0.0042
   420        0.3827             nan     0.1000   -0.0028
   440        0.3776             nan     0.1000   -0.0031
   460        0.3683             nan     0.1000   -0.0017
   480        0.3596             nan     0.1000   -0.0018
   500        0.3532             nan     0.1000   -0.0009
   520        0.3494             nan     0.1000   -0.0036
   540        0.3423             nan     0.1000   -0.0031
   560        0.3349             nan     0.1000   -0.0022
   580        0.3288             nan     0.1000   -0.0015
   600        0.3245             nan     0.1000   -0.0011
   620        0.3186             nan     0.1000   -0.0020
   640        0.3122             nan     0.1000   -0.0023
   660        0.3068             nan     0.1000   -0.0007
   680        0.3034             nan     0.1000   -0.0030
   700        0.2987             nan     0.1000   -0.0025
   720        0.2910             nan     0.1000   -0.0013
   740        0.2896             nan     0.1000   -0.0013
   760        0.2819             nan     0.1000   -0.0026
   780        0.2754             nan     0.1000   -0.0019
   800        0.2733             nan     0.1000   -0.0018
   820        0.2705             nan     0.1000   -0.0016
   840        0.2662             nan     0.1000   -0.0012
   860        0.2623             nan     0.1000   -0.0020
   880        0.2560             nan     0.1000   -0.0015
   900        0.2534             nan     0.1000   -0.0015
   920        0.2502             nan     0.1000   -0.0024
   940        0.2467             nan     0.1000   -0.0008
   960        0.2420             nan     0.1000   -0.0013
   980        0.2396             nan     0.1000   -0.0018
  1000        0.2358             nan     0.1000   -0.0015

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3030             nan     0.1000    0.0333
     2        1.2360             nan     0.1000    0.0291
     3        1.1842             nan     0.1000    0.0235
     4        1.1381             nan     0.1000    0.0151
     5        1.0926             nan     0.1000    0.0156
     6        1.0486             nan     0.1000    0.0153
     7        1.0101             nan     0.1000    0.0148
     8        0.9786             nan     0.1000    0.0107
     9        0.9566             nan     0.1000    0.0047
    10        0.9266             nan     0.1000    0.0120
    20        0.7816             nan     0.1000    0.0019
    40        0.6118             nan     0.1000   -0.0021
    60        0.5244             nan     0.1000   -0.0040
    80        0.4709             nan     0.1000   -0.0016
   100        0.4202             nan     0.1000   -0.0023
   120        0.3823             nan     0.1000   -0.0040
   140        0.3474             nan     0.1000   -0.0022
   160        0.3145             nan     0.1000   -0.0029
   180        0.2868             nan     0.1000   -0.0015
   200        0.2655             nan     0.1000   -0.0034
   220        0.2478             nan     0.1000   -0.0029
   240        0.2242             nan     0.1000   -0.0023
   260        0.2058             nan     0.1000   -0.0024
   280        0.1890             nan     0.1000   -0.0029
   300        0.1745             nan     0.1000   -0.0011
   320        0.1677             nan     0.1000   -0.0015
   340        0.1536             nan     0.1000   -0.0013
   360        0.1426             nan     0.1000   -0.0023
   380        0.1327             nan     0.1000   -0.0014
   400        0.1223             nan     0.1000   -0.0004
   420        0.1125             nan     0.1000   -0.0012
   440        0.1064             nan     0.1000   -0.0011
   460        0.1003             nan     0.1000   -0.0002
   480        0.0941             nan     0.1000   -0.0015
   500        0.0861             nan     0.1000   -0.0008
   520        0.0808             nan     0.1000   -0.0009
   540        0.0765             nan     0.1000   -0.0007
   560        0.0735             nan     0.1000   -0.0009
   580        0.0692             nan     0.1000   -0.0005
   600        0.0648             nan     0.1000   -0.0003
   620        0.0603             nan     0.1000   -0.0007
   640        0.0558             nan     0.1000   -0.0008
   660        0.0531             nan     0.1000   -0.0006
   680        0.0495             nan     0.1000   -0.0007
   700        0.0462             nan     0.1000   -0.0003
   720        0.0429             nan     0.1000   -0.0004
   740        0.0406             nan     0.1000   -0.0002
   760        0.0384             nan     0.1000   -0.0002
   780        0.0359             nan     0.1000   -0.0002
   800        0.0334             nan     0.1000   -0.0001
   820        0.0312             nan     0.1000   -0.0005
   840        0.0295             nan     0.1000   -0.0001
   860        0.0278             nan     0.1000   -0.0002
   880        0.0255             nan     0.1000   -0.0001
   900        0.0236             nan     0.1000   -0.0001
   920        0.0221             nan     0.1000   -0.0003
   940        0.0211             nan     0.1000   -0.0002
   960        0.0205             nan     0.1000   -0.0003
   980        0.0194             nan     0.1000   -0.0001
  1000        0.0183             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2903             nan     0.1000    0.0378
     2        1.2102             nan     0.1000    0.0340
     3        1.1642             nan     0.1000    0.0205
     4        1.1106             nan     0.1000    0.0170
     5        1.0587             nan     0.1000    0.0196
     6        1.0122             nan     0.1000    0.0139
     7        0.9712             nan     0.1000    0.0157
     8        0.9455             nan     0.1000    0.0057
     9        0.9160             nan     0.1000    0.0084
    10        0.8919             nan     0.1000    0.0000
    20        0.6980             nan     0.1000    0.0002
    40        0.5458             nan     0.1000   -0.0007
    60        0.4493             nan     0.1000   -0.0071
    80        0.3824             nan     0.1000   -0.0036
   100        0.3284             nan     0.1000   -0.0040
   120        0.2865             nan     0.1000   -0.0035
   140        0.2454             nan     0.1000   -0.0019
   160        0.2183             nan     0.1000   -0.0043
   180        0.1893             nan     0.1000   -0.0016
   200        0.1660             nan     0.1000   -0.0016
   220        0.1396             nan     0.1000   -0.0004
   240        0.1215             nan     0.1000   -0.0009
   260        0.1065             nan     0.1000   -0.0013
   280        0.0962             nan     0.1000   -0.0011
   300        0.0861             nan     0.1000   -0.0009
   320        0.0783             nan     0.1000   -0.0006
   340        0.0696             nan     0.1000   -0.0007
   360        0.0622             nan     0.1000   -0.0009
   380        0.0552             nan     0.1000   -0.0004
   400        0.0490             nan     0.1000   -0.0004
   420        0.0421             nan     0.1000   -0.0004
   440        0.0378             nan     0.1000   -0.0006
   460        0.0338             nan     0.1000   -0.0005
   480        0.0303             nan     0.1000   -0.0002
   500        0.0271             nan     0.1000   -0.0003
   520        0.0242             nan     0.1000   -0.0003
   540        0.0214             nan     0.1000   -0.0002
   560        0.0189             nan     0.1000   -0.0001
   580        0.0173             nan     0.1000   -0.0002
   600        0.0150             nan     0.1000   -0.0001
   620        0.0134             nan     0.1000   -0.0002
   640        0.0119             nan     0.1000   -0.0001
   660        0.0111             nan     0.1000   -0.0002
   680        0.0099             nan     0.1000   -0.0001
   700        0.0088             nan     0.1000   -0.0001
   720        0.0079             nan     0.1000   -0.0000
   740        0.0072             nan     0.1000   -0.0001
   760        0.0065             nan     0.1000   -0.0001
   780        0.0059             nan     0.1000   -0.0001
   800        0.0052             nan     0.1000   -0.0001
   820        0.0048             nan     0.1000   -0.0001
   840        0.0043             nan     0.1000   -0.0000
   860        0.0038             nan     0.1000   -0.0000
   880        0.0034             nan     0.1000   -0.0000
   900        0.0030             nan     0.1000   -0.0001
   920        0.0027             nan     0.1000   -0.0000
   940        0.0025             nan     0.1000   -0.0000
   960        0.0022             nan     0.1000   -0.0000
   980        0.0019             nan     0.1000   -0.0000
  1000        0.0018             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3224             nan     0.1000    0.0313
     2        1.2770             nan     0.1000    0.0095
     3        1.2341             nan     0.1000    0.0219
     4        1.1841             nan     0.1000    0.0177
     5        1.1655             nan     0.1000    0.0056
     6        1.1319             nan     0.1000    0.0139
     7        1.1093             nan     0.1000    0.0056
     8        1.0943             nan     0.1000    0.0031
     9        1.0714             nan     0.1000    0.0083
    10        1.0474             nan     0.1000    0.0095
    20        0.9031             nan     0.1000    0.0047
    40        0.7534             nan     0.1000    0.0006
    60        0.6742             nan     0.1000   -0.0025
    80        0.6200             nan     0.1000   -0.0059
   100        0.5793             nan     0.1000   -0.0012
   120        0.5499             nan     0.1000   -0.0029
   140        0.5241             nan     0.1000   -0.0027
   160        0.4903             nan     0.1000   -0.0009
   180        0.4615             nan     0.1000    0.0003
   200        0.4472             nan     0.1000   -0.0016
   220        0.4347             nan     0.1000   -0.0029
   240        0.4221             nan     0.1000   -0.0003
   260        0.4103             nan     0.1000   -0.0018
   280        0.3929             nan     0.1000   -0.0011
   300        0.3819             nan     0.1000   -0.0023
   320        0.3691             nan     0.1000   -0.0027
   340        0.3590             nan     0.1000   -0.0037
   360        0.3454             nan     0.1000   -0.0023
   380        0.3366             nan     0.1000   -0.0022
   400        0.3288             nan     0.1000   -0.0027
   420        0.3249             nan     0.1000   -0.0032
   440        0.3146             nan     0.1000   -0.0032
   460        0.3103             nan     0.1000   -0.0008
   480        0.3046             nan     0.1000   -0.0013
   500        0.2992             nan     0.1000   -0.0029
   520        0.2882             nan     0.1000   -0.0020
   540        0.2802             nan     0.1000   -0.0006
   560        0.2727             nan     0.1000    0.0001
   580        0.2662             nan     0.1000   -0.0008
   600        0.2594             nan     0.1000   -0.0013
   620        0.2558             nan     0.1000   -0.0007
   640        0.2516             nan     0.1000   -0.0020
   660        0.2425             nan     0.1000   -0.0015
   680        0.2377             nan     0.1000   -0.0012
   700        0.2343             nan     0.1000   -0.0019
   720        0.2311             nan     0.1000   -0.0030
   740        0.2246             nan     0.1000   -0.0012
   760        0.2220             nan     0.1000   -0.0015
   780        0.2171             nan     0.1000   -0.0022
   800        0.2113             nan     0.1000   -0.0026
   820        0.2086             nan     0.1000   -0.0013
   840        0.2033             nan     0.1000   -0.0020
   860        0.1980             nan     0.1000   -0.0003
   880        0.1986             nan     0.1000   -0.0011
   900        0.1945             nan     0.1000   -0.0020
   920        0.1910             nan     0.1000   -0.0022
   940        0.1870             nan     0.1000   -0.0015
   960        0.1834             nan     0.1000   -0.0020
   980        0.1790             nan     0.1000   -0.0016
  1000        0.1753             nan     0.1000   -0.0013

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3086             nan     0.1000    0.0343
     2        1.2381             nan     0.1000    0.0291
     3        1.1908             nan     0.1000    0.0171
     4        1.1477             nan     0.1000    0.0224
     5        1.1137             nan     0.1000    0.0171
     6        1.0778             nan     0.1000    0.0147
     7        1.0472             nan     0.1000    0.0107
     8        1.0177             nan     0.1000    0.0104
     9        0.9845             nan     0.1000    0.0110
    10        0.9621             nan     0.1000    0.0064
    20        0.7706             nan     0.1000    0.0023
    40        0.6103             nan     0.1000   -0.0028
    60        0.5113             nan     0.1000   -0.0021
    80        0.4577             nan     0.1000   -0.0016
   100        0.4052             nan     0.1000   -0.0020
   120        0.3632             nan     0.1000   -0.0022
   140        0.3373             nan     0.1000   -0.0034
   160        0.2999             nan     0.1000   -0.0006
   180        0.2743             nan     0.1000   -0.0046
   200        0.2480             nan     0.1000   -0.0021
   220        0.2237             nan     0.1000   -0.0017
   240        0.2002             nan     0.1000   -0.0023
   260        0.1827             nan     0.1000   -0.0028
   280        0.1697             nan     0.1000   -0.0026
   300        0.1518             nan     0.1000   -0.0017
   320        0.1393             nan     0.1000   -0.0013
   340        0.1262             nan     0.1000   -0.0000
   360        0.1158             nan     0.1000   -0.0009
   380        0.1052             nan     0.1000   -0.0005
   400        0.0962             nan     0.1000   -0.0003
   420        0.0897             nan     0.1000   -0.0016
   440        0.0835             nan     0.1000   -0.0009
   460        0.0776             nan     0.1000   -0.0004
   480        0.0723             nan     0.1000   -0.0005
   500        0.0659             nan     0.1000   -0.0003
   520        0.0597             nan     0.1000   -0.0002
   540        0.0558             nan     0.1000   -0.0005
   560        0.0521             nan     0.1000   -0.0006
   580        0.0485             nan     0.1000   -0.0002
   600        0.0451             nan     0.1000   -0.0006
   620        0.0423             nan     0.1000   -0.0004
   640        0.0385             nan     0.1000   -0.0004
   660        0.0356             nan     0.1000   -0.0003
   680        0.0331             nan     0.1000   -0.0006
   700        0.0307             nan     0.1000   -0.0001
   720        0.0292             nan     0.1000   -0.0002
   740        0.0270             nan     0.1000   -0.0005
   760        0.0247             nan     0.1000   -0.0001
   780        0.0227             nan     0.1000   -0.0002
   800        0.0216             nan     0.1000   -0.0001
   820        0.0201             nan     0.1000   -0.0001
   840        0.0184             nan     0.1000   -0.0001
   860        0.0173             nan     0.1000   -0.0002
   880        0.0164             nan     0.1000   -0.0001
   900        0.0153             nan     0.1000   -0.0001
   920        0.0140             nan     0.1000   -0.0001
   940        0.0131             nan     0.1000   -0.0001
   960        0.0123             nan     0.1000   -0.0001
   980        0.0115             nan     0.1000   -0.0001
  1000        0.0108             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2986             nan     0.1000    0.0405
     2        1.2274             nan     0.1000    0.0231
     3        1.1692             nan     0.1000    0.0229
     4        1.1160             nan     0.1000    0.0177
     5        1.0781             nan     0.1000    0.0102
     6        1.0326             nan     0.1000    0.0126
     7        0.9958             nan     0.1000    0.0152
     8        0.9678             nan     0.1000    0.0058
     9        0.9479             nan     0.1000   -0.0015
    10        0.9203             nan     0.1000    0.0125
    20        0.7339             nan     0.1000   -0.0051
    40        0.5491             nan     0.1000   -0.0044
    60        0.4352             nan     0.1000   -0.0006
    80        0.3525             nan     0.1000   -0.0020
   100        0.2985             nan     0.1000   -0.0029
   120        0.2459             nan     0.1000   -0.0020
   140        0.2020             nan     0.1000   -0.0016
   160        0.1745             nan     0.1000   -0.0015
   180        0.1523             nan     0.1000   -0.0029
   200        0.1314             nan     0.1000   -0.0013
   220        0.1111             nan     0.1000   -0.0012
   240        0.0984             nan     0.1000   -0.0008
   260        0.0824             nan     0.1000   -0.0009
   280        0.0718             nan     0.1000   -0.0011
   300        0.0637             nan     0.1000   -0.0008
   320        0.0564             nan     0.1000   -0.0004
   340        0.0480             nan     0.1000   -0.0004
   360        0.0443             nan     0.1000   -0.0003
   380        0.0384             nan     0.1000   -0.0002
   400        0.0344             nan     0.1000   -0.0006
   420        0.0305             nan     0.1000   -0.0003
   440        0.0263             nan     0.1000   -0.0001
   460        0.0238             nan     0.1000   -0.0004
   480        0.0212             nan     0.1000   -0.0002
   500        0.0188             nan     0.1000   -0.0002
   520        0.0165             nan     0.1000   -0.0002
   540        0.0145             nan     0.1000   -0.0001
   560        0.0128             nan     0.1000   -0.0002
   580        0.0116             nan     0.1000   -0.0001
   600        0.0103             nan     0.1000   -0.0001
   620        0.0091             nan     0.1000   -0.0001
   640        0.0082             nan     0.1000   -0.0001
   660        0.0073             nan     0.1000   -0.0001
   680        0.0065             nan     0.1000   -0.0000
   700        0.0058             nan     0.1000   -0.0001
   720        0.0051             nan     0.1000   -0.0000
   740        0.0046             nan     0.1000   -0.0001
   760        0.0041             nan     0.1000   -0.0000
   780        0.0036             nan     0.1000   -0.0000
   800        0.0032             nan     0.1000   -0.0000
   820        0.0029             nan     0.1000   -0.0000
   840        0.0026             nan     0.1000   -0.0000
   860        0.0023             nan     0.1000   -0.0000
   880        0.0020             nan     0.1000   -0.0000
   900        0.0018             nan     0.1000   -0.0000
   920        0.0016             nan     0.1000   -0.0000
   940        0.0014             nan     0.1000   -0.0000
   960        0.0013             nan     0.1000   -0.0000
   980        0.0011             nan     0.1000   -0.0000
  1000        0.0010             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3082             nan     0.1000    0.0340
     2        1.2481             nan     0.1000    0.0236
     3        1.2029             nan     0.1000    0.0188
     4        1.1734             nan     0.1000    0.0121
     5        1.1416             nan     0.1000    0.0180
     6        1.1241             nan     0.1000    0.0067
     7        1.0968             nan     0.1000    0.0140
     8        1.0751             nan     0.1000    0.0061
     9        1.0471             nan     0.1000    0.0077
    10        1.0263             nan     0.1000    0.0072
    20        0.9101             nan     0.1000    0.0028
    40        0.7863             nan     0.1000   -0.0022
    60        0.7119             nan     0.1000   -0.0031
    80        0.6620             nan     0.1000   -0.0023
   100        0.6397             nan     0.1000   -0.0033
   120        0.6113             nan     0.1000   -0.0013
   140        0.5850             nan     0.1000   -0.0011
   160        0.5649             nan     0.1000   -0.0040
   180        0.5477             nan     0.1000   -0.0008
   200        0.5339             nan     0.1000   -0.0055
   220        0.5162             nan     0.1000   -0.0015
   240        0.5015             nan     0.1000   -0.0024
   260        0.4862             nan     0.1000   -0.0015
   280        0.4768             nan     0.1000   -0.0026
   300        0.4656             nan     0.1000   -0.0041
   320        0.4576             nan     0.1000   -0.0029
   340        0.4477             nan     0.1000   -0.0009
   360        0.4367             nan     0.1000   -0.0013
   380        0.4250             nan     0.1000   -0.0035
   400        0.4161             nan     0.1000   -0.0014
   420        0.4092             nan     0.1000   -0.0024
   440        0.3980             nan     0.1000   -0.0023
   460        0.3943             nan     0.1000   -0.0030
   480        0.3871             nan     0.1000   -0.0032
   500        0.3784             nan     0.1000   -0.0021
   520        0.3698             nan     0.1000   -0.0034
   540        0.3638             nan     0.1000   -0.0017
   560        0.3544             nan     0.1000   -0.0023
   580        0.3430             nan     0.1000   -0.0020
   600        0.3362             nan     0.1000   -0.0030
   620        0.3324             nan     0.1000   -0.0009
   640        0.3244             nan     0.1000   -0.0013
   660        0.3200             nan     0.1000   -0.0012
   680        0.3165             nan     0.1000   -0.0013
   700        0.3079             nan     0.1000   -0.0013
   720        0.3000             nan     0.1000   -0.0011
   740        0.2959             nan     0.1000   -0.0008
   760        0.2898             nan     0.1000   -0.0027
   780        0.2837             nan     0.1000   -0.0022
   800        0.2808             nan     0.1000   -0.0010
   820        0.2756             nan     0.1000   -0.0019
   840        0.2734             nan     0.1000   -0.0011
   860        0.2710             nan     0.1000   -0.0029
   880        0.2662             nan     0.1000   -0.0012
   900        0.2600             nan     0.1000   -0.0016
   920        0.2546             nan     0.1000   -0.0022
   940        0.2501             nan     0.1000   -0.0007
   960        0.2483             nan     0.1000   -0.0019
   980        0.2445             nan     0.1000   -0.0010
  1000        0.2400             nan     0.1000   -0.0010

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3054             nan     0.1000    0.0329
     2        1.2611             nan     0.1000    0.0154
     3        1.2005             nan     0.1000    0.0282
     4        1.1460             nan     0.1000    0.0250
     5        1.1192             nan     0.1000    0.0039
     6        1.0894             nan     0.1000    0.0067
     7        1.0583             nan     0.1000    0.0134
     8        1.0222             nan     0.1000    0.0052
     9        0.9926             nan     0.1000    0.0136
    10        0.9692             nan     0.1000    0.0063
    20        0.8051             nan     0.1000   -0.0001
    40        0.6572             nan     0.1000   -0.0047
    60        0.5790             nan     0.1000   -0.0049
    80        0.5139             nan     0.1000   -0.0069
   100        0.4645             nan     0.1000   -0.0023
   120        0.4206             nan     0.1000   -0.0035
   140        0.3752             nan     0.1000   -0.0024
   160        0.3483             nan     0.1000   -0.0039
   180        0.3181             nan     0.1000   -0.0016
   200        0.2893             nan     0.1000   -0.0021
   220        0.2682             nan     0.1000   -0.0019
   240        0.2502             nan     0.1000   -0.0025
   260        0.2333             nan     0.1000   -0.0012
   280        0.2176             nan     0.1000   -0.0012
   300        0.1994             nan     0.1000   -0.0015
   320        0.1857             nan     0.1000   -0.0020
   340        0.1748             nan     0.1000   -0.0010
   360        0.1622             nan     0.1000   -0.0025
   380        0.1509             nan     0.1000   -0.0014
   400        0.1435             nan     0.1000   -0.0015
   420        0.1350             nan     0.1000   -0.0014
   440        0.1262             nan     0.1000   -0.0020
   460        0.1199             nan     0.1000   -0.0012
   480        0.1105             nan     0.1000   -0.0010
   500        0.1055             nan     0.1000   -0.0013
   520        0.0996             nan     0.1000   -0.0005
   540        0.0944             nan     0.1000   -0.0009
   560        0.0888             nan     0.1000   -0.0007
   580        0.0829             nan     0.1000   -0.0005
   600        0.0781             nan     0.1000   -0.0008
   620        0.0728             nan     0.1000   -0.0010
   640        0.0686             nan     0.1000   -0.0006
   660        0.0650             nan     0.1000   -0.0006
   680        0.0615             nan     0.1000   -0.0005
   700        0.0571             nan     0.1000   -0.0005
   720        0.0528             nan     0.1000   -0.0004
   740        0.0507             nan     0.1000   -0.0005
   760        0.0479             nan     0.1000   -0.0003
   780        0.0455             nan     0.1000   -0.0002
   800        0.0432             nan     0.1000   -0.0003
   820        0.0399             nan     0.1000   -0.0001
   840        0.0380             nan     0.1000   -0.0007
   860        0.0352             nan     0.1000   -0.0002
   880        0.0332             nan     0.1000   -0.0004
   900        0.0316             nan     0.1000   -0.0002
   920        0.0297             nan     0.1000   -0.0005
   940        0.0278             nan     0.1000   -0.0002
   960        0.0262             nan     0.1000   -0.0001
   980        0.0253             nan     0.1000   -0.0001
  1000        0.0242             nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2987             nan     0.1000    0.0376
     2        1.2371             nan     0.1000    0.0346
     3        1.1841             nan     0.1000    0.0205
     4        1.1310             nan     0.1000    0.0225
     5        1.0868             nan     0.1000    0.0146
     6        1.0516             nan     0.1000    0.0121
     7        1.0181             nan     0.1000    0.0105
     8        0.9817             nan     0.1000    0.0080
     9        0.9525             nan     0.1000    0.0097
    10        0.9314             nan     0.1000    0.0028
    20        0.7523             nan     0.1000    0.0008
    40        0.5922             nan     0.1000   -0.0013
    60        0.4820             nan     0.1000   -0.0034
    80        0.4051             nan     0.1000   -0.0010
   100        0.3491             nan     0.1000   -0.0022
   120        0.2955             nan     0.1000   -0.0026
   140        0.2548             nan     0.1000   -0.0029
   160        0.2211             nan     0.1000   -0.0026
   180        0.1949             nan     0.1000   -0.0017
   200        0.1692             nan     0.1000   -0.0013
   220        0.1521             nan     0.1000   -0.0008
   240        0.1325             nan     0.1000   -0.0018
   260        0.1185             nan     0.1000   -0.0006
   280        0.1062             nan     0.1000   -0.0002
   300        0.0964             nan     0.1000   -0.0012
   320        0.0871             nan     0.1000   -0.0007
   340        0.0786             nan     0.1000   -0.0008
   360        0.0690             nan     0.1000   -0.0010
   380        0.0632             nan     0.1000   -0.0005
   400        0.0557             nan     0.1000   -0.0005
   420        0.0507             nan     0.1000   -0.0005
   440        0.0443             nan     0.1000   -0.0004
   460        0.0395             nan     0.1000   -0.0002
   480        0.0354             nan     0.1000   -0.0002
   500        0.0331             nan     0.1000   -0.0004
   520        0.0298             nan     0.1000   -0.0004
   540        0.0266             nan     0.1000   -0.0005
   560        0.0241             nan     0.1000   -0.0001
   580        0.0216             nan     0.1000   -0.0002
   600        0.0192             nan     0.1000   -0.0001
   620        0.0173             nan     0.1000   -0.0002
   640        0.0157             nan     0.1000   -0.0001
   660        0.0141             nan     0.1000   -0.0001
   680        0.0128             nan     0.1000   -0.0001
   700        0.0116             nan     0.1000   -0.0001
   720        0.0104             nan     0.1000   -0.0002
   740        0.0094             nan     0.1000   -0.0001
   760        0.0084             nan     0.1000   -0.0001
   780        0.0076             nan     0.1000   -0.0001
   800        0.0070             nan     0.1000   -0.0000
   820        0.0062             nan     0.1000   -0.0001
   840        0.0056             nan     0.1000   -0.0000
   860        0.0049             nan     0.1000   -0.0000
   880        0.0043             nan     0.1000   -0.0000
   900        0.0039             nan     0.1000   -0.0000
   920        0.0036             nan     0.1000   -0.0000
   940        0.0032             nan     0.1000   -0.0000
   960        0.0029             nan     0.1000   -0.0000
   980        0.0026             nan     0.1000   -0.0000
  1000        0.0024             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3203             nan     0.1000    0.0258
     2        1.2761             nan     0.1000    0.0157
     3        1.2394             nan     0.1000    0.0148
     4        1.2020             nan     0.1000    0.0175
     5        1.1671             nan     0.1000    0.0109
     6        1.1356             nan     0.1000    0.0148
     7        1.1218             nan     0.1000    0.0029
     8        1.0969             nan     0.1000    0.0067
     9        1.0748             nan     0.1000    0.0109
    10        1.0524             nan     0.1000    0.0115
    20        0.9112             nan     0.1000   -0.0004
    40        0.7722             nan     0.1000    0.0036
    60        0.6955             nan     0.1000    0.0005
    80        0.6438             nan     0.1000   -0.0041
   100        0.6048             nan     0.1000   -0.0012
   120        0.5816             nan     0.1000    0.0001
   140        0.5516             nan     0.1000   -0.0045
   160        0.5301             nan     0.1000   -0.0038
   180        0.5119             nan     0.1000   -0.0034
   200        0.4966             nan     0.1000   -0.0030
   220        0.4810             nan     0.1000   -0.0034
   240        0.4707             nan     0.1000   -0.0063
   260        0.4576             nan     0.1000   -0.0036
   280        0.4504             nan     0.1000   -0.0025
   300        0.4423             nan     0.1000   -0.0037
   320        0.4364             nan     0.1000   -0.0022
   340        0.4237             nan     0.1000   -0.0021
   360        0.4105             nan     0.1000   -0.0006
   380        0.4028             nan     0.1000   -0.0023
   400        0.3961             nan     0.1000   -0.0020
   420        0.3854             nan     0.1000   -0.0028
   440        0.3822             nan     0.1000   -0.0012
   460        0.3726             nan     0.1000   -0.0007
   480        0.3668             nan     0.1000   -0.0017
   500        0.3566             nan     0.1000   -0.0016
   520        0.3522             nan     0.1000   -0.0039
   540        0.3427             nan     0.1000   -0.0030
   560        0.3348             nan     0.1000   -0.0029
   580        0.3301             nan     0.1000   -0.0048
   600        0.3249             nan     0.1000   -0.0012
   620        0.3177             nan     0.1000   -0.0013
   640        0.3113             nan     0.1000   -0.0023
   660        0.3070             nan     0.1000   -0.0022
   680        0.3022             nan     0.1000   -0.0017
   700        0.2950             nan     0.1000   -0.0025
   720        0.2915             nan     0.1000   -0.0013
   740        0.2855             nan     0.1000   -0.0013
   760        0.2784             nan     0.1000   -0.0020
   780        0.2723             nan     0.1000   -0.0014
   800        0.2658             nan     0.1000   -0.0016
   820        0.2610             nan     0.1000   -0.0020
   840        0.2575             nan     0.1000   -0.0035
   860        0.2536             nan     0.1000   -0.0005
   880        0.2520             nan     0.1000   -0.0016
   900        0.2473             nan     0.1000   -0.0019
   920        0.2424             nan     0.1000   -0.0009
   940        0.2379             nan     0.1000   -0.0019
   960        0.2332             nan     0.1000   -0.0009
   980        0.2296             nan     0.1000   -0.0014
  1000        0.2254             nan     0.1000   -0.0016

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3045             nan     0.1000    0.0334
     2        1.2458             nan     0.1000    0.0253
     3        1.1963             nan     0.1000    0.0169
     4        1.1476             nan     0.1000    0.0157
     5        1.1113             nan     0.1000    0.0153
     6        1.0759             nan     0.1000    0.0147
     7        1.0462             nan     0.1000    0.0081
     8        1.0110             nan     0.1000    0.0123
     9        0.9863             nan     0.1000    0.0077
    10        0.9549             nan     0.1000    0.0079
    20        0.7971             nan     0.1000    0.0003
    40        0.6279             nan     0.1000   -0.0033
    60        0.5547             nan     0.1000   -0.0026
    80        0.4897             nan     0.1000   -0.0032
   100        0.4399             nan     0.1000   -0.0013
   120        0.3915             nan     0.1000   -0.0026
   140        0.3608             nan     0.1000   -0.0033
   160        0.3323             nan     0.1000   -0.0015
   180        0.3065             nan     0.1000   -0.0015
   200        0.2865             nan     0.1000   -0.0026
   220        0.2696             nan     0.1000   -0.0012
   240        0.2517             nan     0.1000   -0.0010
   260        0.2308             nan     0.1000   -0.0025
   280        0.2161             nan     0.1000   -0.0019
   300        0.2009             nan     0.1000   -0.0017
   320        0.1866             nan     0.1000   -0.0014
   340        0.1746             nan     0.1000   -0.0015
   360        0.1620             nan     0.1000   -0.0009
   380        0.1507             nan     0.1000   -0.0018
   400        0.1419             nan     0.1000   -0.0021
   420        0.1332             nan     0.1000   -0.0011
   440        0.1233             nan     0.1000   -0.0008
   460        0.1132             nan     0.1000   -0.0006
   480        0.1046             nan     0.1000   -0.0007
   500        0.0958             nan     0.1000   -0.0008
   520        0.0900             nan     0.1000   -0.0008
   540        0.0830             nan     0.1000   -0.0012
   560        0.0777             nan     0.1000   -0.0006
   580        0.0722             nan     0.1000   -0.0006
   600        0.0689             nan     0.1000   -0.0008
   620        0.0641             nan     0.1000   -0.0008
   640        0.0597             nan     0.1000   -0.0006
   660        0.0549             nan     0.1000   -0.0002
   680        0.0528             nan     0.1000   -0.0004
   700        0.0492             nan     0.1000   -0.0003
   720        0.0451             nan     0.1000   -0.0004
   740        0.0422             nan     0.1000   -0.0003
   760        0.0396             nan     0.1000   -0.0005
   780        0.0375             nan     0.1000   -0.0003
   800        0.0359             nan     0.1000   -0.0004
   820        0.0339             nan     0.1000   -0.0004
   840        0.0321             nan     0.1000   -0.0001
   860        0.0300             nan     0.1000   -0.0001
   880        0.0285             nan     0.1000   -0.0001
   900        0.0272             nan     0.1000   -0.0002
   920        0.0257             nan     0.1000   -0.0002
   940        0.0246             nan     0.1000   -0.0002
   960        0.0230             nan     0.1000   -0.0002
   980        0.0218             nan     0.1000   -0.0003
  1000        0.0208             nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3025             nan     0.1000    0.0274
     2        1.2390             nan     0.1000    0.0168
     3        1.1777             nan     0.1000    0.0266
     4        1.1236             nan     0.1000    0.0235
     5        1.0769             nan     0.1000    0.0143
     6        1.0404             nan     0.1000    0.0106
     7        0.9958             nan     0.1000    0.0147
     8        0.9666             nan     0.1000    0.0073
     9        0.9362             nan     0.1000    0.0076
    10        0.9141             nan     0.1000    0.0040
    20        0.7448             nan     0.1000    0.0009
    40        0.5708             nan     0.1000   -0.0054
    60        0.4650             nan     0.1000   -0.0017
    80        0.4030             nan     0.1000   -0.0045
   100        0.3425             nan     0.1000   -0.0029
   120        0.3041             nan     0.1000   -0.0006
   140        0.2633             nan     0.1000   -0.0038
   160        0.2304             nan     0.1000   -0.0022
   180        0.2023             nan     0.1000   -0.0016
   200        0.1792             nan     0.1000   -0.0013
   220        0.1559             nan     0.1000   -0.0010
   240        0.1363             nan     0.1000   -0.0018
   260        0.1193             nan     0.1000   -0.0010
   280        0.1056             nan     0.1000   -0.0018
   300        0.0943             nan     0.1000   -0.0010
   320        0.0858             nan     0.1000   -0.0014
   340        0.0761             nan     0.1000   -0.0007
   360        0.0697             nan     0.1000   -0.0005
   380        0.0608             nan     0.1000    0.0001
   400        0.0537             nan     0.1000   -0.0005
   420        0.0490             nan     0.1000   -0.0009
   440        0.0447             nan     0.1000   -0.0003
   460        0.0395             nan     0.1000   -0.0005
   480        0.0350             nan     0.1000   -0.0003
   500        0.0316             nan     0.1000   -0.0003
   520        0.0289             nan     0.1000   -0.0004
   540        0.0262             nan     0.1000   -0.0004
   560        0.0230             nan     0.1000   -0.0003
   580        0.0200             nan     0.1000   -0.0001
   600        0.0182             nan     0.1000   -0.0002
   620        0.0159             nan     0.1000   -0.0002
   640        0.0143             nan     0.1000   -0.0000
   660        0.0129             nan     0.1000   -0.0001
   680        0.0118             nan     0.1000   -0.0002
   700        0.0108             nan     0.1000   -0.0002
   720        0.0098             nan     0.1000   -0.0002
   740        0.0089             nan     0.1000   -0.0002
   760        0.0080             nan     0.1000   -0.0001
   780        0.0072             nan     0.1000   -0.0000
   800        0.0064             nan     0.1000   -0.0000
   820        0.0058             nan     0.1000   -0.0001
   840        0.0053             nan     0.1000   -0.0000
   860        0.0047             nan     0.1000   -0.0000
   880        0.0043             nan     0.1000   -0.0000
   900        0.0039             nan     0.1000   -0.0000
   920        0.0035             nan     0.1000   -0.0000
   940        0.0031             nan     0.1000   -0.0000
   960        0.0028             nan     0.1000   -0.0000
   980        0.0025             nan     0.1000   -0.0000
  1000        0.0021             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3166             nan     0.1000    0.0296
     2        1.2730             nan     0.1000    0.0136
     3        1.2295             nan     0.1000    0.0140
     4        1.2071             nan     0.1000    0.0059
     5        1.1652             nan     0.1000    0.0195
     6        1.1272             nan     0.1000    0.0135
     7        1.0967             nan     0.1000    0.0134
     8        1.0751             nan     0.1000    0.0042
     9        1.0544             nan     0.1000    0.0062
    10        1.0349             nan     0.1000    0.0065
    20        0.8972             nan     0.1000    0.0013
    40        0.7508             nan     0.1000   -0.0015
    60        0.6872             nan     0.1000   -0.0046
    80        0.6339             nan     0.1000   -0.0047
   100        0.5903             nan     0.1000   -0.0008
   120        0.5627             nan     0.1000   -0.0097
   140        0.5498             nan     0.1000   -0.0027
   160        0.5260             nan     0.1000   -0.0011
   180        0.5043             nan     0.1000   -0.0008
   200        0.4889             nan     0.1000   -0.0012
   220        0.4720             nan     0.1000   -0.0024
   240        0.4508             nan     0.1000   -0.0012
   260        0.4359             nan     0.1000   -0.0049
   280        0.4219             nan     0.1000   -0.0047
   300        0.4097             nan     0.1000   -0.0027
   320        0.3954             nan     0.1000   -0.0018
   340        0.3851             nan     0.1000   -0.0058
   360        0.3722             nan     0.1000   -0.0032
   380        0.3610             nan     0.1000   -0.0015
   400        0.3539             nan     0.1000   -0.0013
   420        0.3439             nan     0.1000   -0.0015
   440        0.3368             nan     0.1000    0.0000
   460        0.3282             nan     0.1000   -0.0019
   480        0.3180             nan     0.1000   -0.0025
   500        0.3102             nan     0.1000   -0.0026
   520        0.3010             nan     0.1000   -0.0016
   540        0.2911             nan     0.1000   -0.0022
   560        0.2910             nan     0.1000   -0.0017
   580        0.2819             nan     0.1000   -0.0009
   600        0.2742             nan     0.1000   -0.0020
   620        0.2713             nan     0.1000   -0.0007
   640        0.2653             nan     0.1000   -0.0012
   660        0.2574             nan     0.1000   -0.0018
   680        0.2552             nan     0.1000   -0.0022
   700        0.2494             nan     0.1000   -0.0015
   720        0.2452             nan     0.1000   -0.0010
   740        0.2366             nan     0.1000   -0.0023
   760        0.2298             nan     0.1000   -0.0027
   780        0.2245             nan     0.1000   -0.0013
   800        0.2197             nan     0.1000   -0.0009
   820        0.2136             nan     0.1000   -0.0009
   840        0.2092             nan     0.1000   -0.0024
   860        0.2053             nan     0.1000   -0.0016
   880        0.1988             nan     0.1000   -0.0017
   900        0.1942             nan     0.1000   -0.0012
   920        0.1912             nan     0.1000   -0.0016
   940        0.1873             nan     0.1000   -0.0011
   960        0.1831             nan     0.1000   -0.0038
   980        0.1792             nan     0.1000   -0.0006
  1000        0.1780             nan     0.1000   -0.0015

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3111             nan     0.1000    0.0347
     2        1.2581             nan     0.1000    0.0155
     3        1.2131             nan     0.1000    0.0118
     4        1.1621             nan     0.1000    0.0175
     5        1.1253             nan     0.1000    0.0191
     6        1.0845             nan     0.1000    0.0126
     7        1.0596             nan     0.1000    0.0061
     8        1.0270             nan     0.1000    0.0127
     9        1.0034             nan     0.1000    0.0035
    10        0.9830             nan     0.1000    0.0035
    20        0.7928             nan     0.1000    0.0009
    40        0.6264             nan     0.1000   -0.0003
    60        0.5403             nan     0.1000   -0.0031
    80        0.4805             nan     0.1000   -0.0029
   100        0.4308             nan     0.1000   -0.0041
   120        0.3907             nan     0.1000   -0.0013
   140        0.3545             nan     0.1000   -0.0048
   160        0.3282             nan     0.1000   -0.0019
   180        0.2965             nan     0.1000   -0.0027
   200        0.2690             nan     0.1000   -0.0016
   220        0.2502             nan     0.1000   -0.0031
   240        0.2257             nan     0.1000   -0.0030
   260        0.2017             nan     0.1000   -0.0020
   280        0.1889             nan     0.1000   -0.0006
   300        0.1711             nan     0.1000   -0.0017
   320        0.1573             nan     0.1000   -0.0005
   340        0.1465             nan     0.1000   -0.0015
   360        0.1342             nan     0.1000   -0.0017
   380        0.1244             nan     0.1000   -0.0014
   400        0.1153             nan     0.1000   -0.0006
   420        0.1085             nan     0.1000   -0.0008
   440        0.0991             nan     0.1000   -0.0009
   460        0.0914             nan     0.1000   -0.0006
   480        0.0836             nan     0.1000   -0.0007
   500        0.0797             nan     0.1000   -0.0004
   520        0.0742             nan     0.1000   -0.0007
   540        0.0680             nan     0.1000   -0.0006
   560        0.0627             nan     0.1000   -0.0005
   580        0.0569             nan     0.1000   -0.0005
   600        0.0525             nan     0.1000   -0.0005
   620        0.0485             nan     0.1000   -0.0006
   640        0.0451             nan     0.1000   -0.0002
   660        0.0424             nan     0.1000   -0.0006
   680        0.0393             nan     0.1000   -0.0001
   700        0.0366             nan     0.1000   -0.0002
   720        0.0341             nan     0.1000   -0.0003
   740        0.0313             nan     0.1000   -0.0003
   760        0.0289             nan     0.1000   -0.0004
   780        0.0276             nan     0.1000   -0.0004
   800        0.0260             nan     0.1000   -0.0004
   820        0.0236             nan     0.1000   -0.0002
   840        0.0222             nan     0.1000   -0.0000
   860        0.0206             nan     0.1000   -0.0002
   880        0.0194             nan     0.1000   -0.0001
   900        0.0183             nan     0.1000   -0.0002
   920        0.0171             nan     0.1000   -0.0001
   940        0.0159             nan     0.1000   -0.0002
   960        0.0149             nan     0.1000   -0.0001
   980        0.0137             nan     0.1000   -0.0001
  1000        0.0127             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3168             nan     0.1000    0.0312
     2        1.2386             nan     0.1000    0.0321
     3        1.1785             nan     0.1000    0.0239
     4        1.1259             nan     0.1000    0.0203
     5        1.0853             nan     0.1000    0.0109
     6        1.0469             nan     0.1000    0.0098
     7        1.0156             nan     0.1000    0.0078
     8        0.9809             nan     0.1000    0.0118
     9        0.9416             nan     0.1000    0.0101
    10        0.9057             nan     0.1000    0.0097
    20        0.7152             nan     0.1000    0.0015
    40        0.5254             nan     0.1000   -0.0011
    60        0.4371             nan     0.1000   -0.0030
    80        0.3660             nan     0.1000   -0.0011
   100        0.3137             nan     0.1000   -0.0007
   120        0.2693             nan     0.1000   -0.0008
   140        0.2318             nan     0.1000   -0.0039
   160        0.1982             nan     0.1000   -0.0029
   180        0.1719             nan     0.1000   -0.0014
   200        0.1437             nan     0.1000   -0.0002
   220        0.1255             nan     0.1000   -0.0007
   240        0.1073             nan     0.1000   -0.0019
   260        0.0939             nan     0.1000   -0.0005
   280        0.0833             nan     0.1000   -0.0009
   300        0.0760             nan     0.1000   -0.0006
   320        0.0677             nan     0.1000   -0.0006
   340        0.0592             nan     0.1000   -0.0005
   360        0.0540             nan     0.1000   -0.0005
   380        0.0501             nan     0.1000   -0.0008
   400        0.0432             nan     0.1000   -0.0004
   420        0.0386             nan     0.1000   -0.0006
   440        0.0338             nan     0.1000   -0.0004
   460        0.0300             nan     0.1000   -0.0004
   480        0.0260             nan     0.1000   -0.0002
   500        0.0234             nan     0.1000   -0.0002
   520        0.0206             nan     0.1000   -0.0002
   540        0.0183             nan     0.1000   -0.0003
   560        0.0167             nan     0.1000   -0.0003
   580        0.0156             nan     0.1000   -0.0001
   600        0.0138             nan     0.1000   -0.0002
   620        0.0128             nan     0.1000   -0.0003
   640        0.0115             nan     0.1000   -0.0000
   660        0.0099             nan     0.1000   -0.0002
   680        0.0090             nan     0.1000   -0.0001
   700        0.0080             nan     0.1000   -0.0001
   720        0.0071             nan     0.1000   -0.0000
   740        0.0062             nan     0.1000   -0.0001
   760        0.0057             nan     0.1000   -0.0001
   780        0.0048             nan     0.1000   -0.0000
   800        0.0044             nan     0.1000   -0.0000
   820        0.0038             nan     0.1000   -0.0000
   840        0.0033             nan     0.1000   -0.0001
   860        0.0030             nan     0.1000   -0.0000
   880        0.0027             nan     0.1000   -0.0000
   900        0.0024             nan     0.1000   -0.0000
   920        0.0022             nan     0.1000   -0.0000
   940        0.0019             nan     0.1000   -0.0000
   960        0.0017             nan     0.1000   -0.0000
   980        0.0015             nan     0.1000   -0.0000
  1000        0.0013             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3171             nan     0.1000    0.0311
     2        1.2705             nan     0.1000    0.0125
     3        1.2251             nan     0.1000    0.0226
     4        1.1855             nan     0.1000    0.0152
     5        1.1480             nan     0.1000    0.0164
     6        1.1155             nan     0.1000    0.0115
     7        1.0881             nan     0.1000    0.0097
     8        1.0627             nan     0.1000    0.0091
     9        1.0477             nan     0.1000    0.0045
    10        1.0294             nan     0.1000    0.0069
    20        0.9018             nan     0.1000    0.0020
    40        0.7761             nan     0.1000   -0.0018
    60        0.7113             nan     0.1000   -0.0019
    80        0.6600             nan     0.1000   -0.0008
   100        0.6233             nan     0.1000   -0.0015
   120        0.5897             nan     0.1000   -0.0017
   140        0.5653             nan     0.1000   -0.0024
   160        0.5496             nan     0.1000   -0.0011
   180        0.5295             nan     0.1000   -0.0009
   200        0.5083             nan     0.1000   -0.0017
   220        0.4938             nan     0.1000   -0.0017
   240        0.4808             nan     0.1000   -0.0033
   260        0.4628             nan     0.1000   -0.0035
   280        0.4501             nan     0.1000   -0.0015
   300        0.4304             nan     0.1000   -0.0023
   320        0.4189             nan     0.1000   -0.0015
   340        0.4098             nan     0.1000   -0.0010
   360        0.3985             nan     0.1000   -0.0013
   380        0.3896             nan     0.1000   -0.0021
   400        0.3782             nan     0.1000   -0.0016
   420        0.3702             nan     0.1000   -0.0023
   440        0.3584             nan     0.1000    0.0001
   460        0.3519             nan     0.1000   -0.0000
   480        0.3435             nan     0.1000   -0.0028
   500        0.3391             nan     0.1000   -0.0021
   520        0.3351             nan     0.1000   -0.0019
   540        0.3242             nan     0.1000   -0.0032
   560        0.3144             nan     0.1000   -0.0020
   580        0.3082             nan     0.1000   -0.0011
   600        0.3018             nan     0.1000   -0.0025
   620        0.2983             nan     0.1000   -0.0017
   640        0.2940             nan     0.1000   -0.0030
   660        0.2883             nan     0.1000   -0.0006
   680        0.2824             nan     0.1000   -0.0012
   700        0.2777             nan     0.1000   -0.0006
   720        0.2716             nan     0.1000   -0.0010
   740        0.2668             nan     0.1000   -0.0010
   760        0.2627             nan     0.1000   -0.0014
   780        0.2565             nan     0.1000   -0.0008
   800        0.2515             nan     0.1000   -0.0007
   820        0.2487             nan     0.1000   -0.0022
   840        0.2434             nan     0.1000   -0.0005
   860        0.2393             nan     0.1000   -0.0023
   880        0.2346             nan     0.1000   -0.0006
   900        0.2326             nan     0.1000   -0.0007
   920        0.2278             nan     0.1000   -0.0011
   940        0.2253             nan     0.1000   -0.0010
   960        0.2235             nan     0.1000   -0.0011
   980        0.2200             nan     0.1000   -0.0011
  1000        0.2169             nan     0.1000   -0.0021

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3110             nan     0.1000    0.0272
     2        1.2514             nan     0.1000    0.0273
     3        1.1996             nan     0.1000    0.0132
     4        1.1574             nan     0.1000    0.0199
     5        1.1162             nan     0.1000    0.0159
     6        1.0769             nan     0.1000    0.0139
     7        1.0486             nan     0.1000    0.0103
     8        1.0239             nan     0.1000    0.0096
     9        0.9973             nan     0.1000    0.0095
    10        0.9747             nan     0.1000    0.0062
    20        0.8144             nan     0.1000    0.0023
    40        0.6527             nan     0.1000   -0.0034
    60        0.5679             nan     0.1000   -0.0020
    80        0.5032             nan     0.1000   -0.0012
   100        0.4614             nan     0.1000   -0.0030
   120        0.4141             nan     0.1000   -0.0027
   140        0.3805             nan     0.1000   -0.0030
   160        0.3472             nan     0.1000   -0.0017
   180        0.3182             nan     0.1000   -0.0032
   200        0.2865             nan     0.1000   -0.0020
   220        0.2636             nan     0.1000   -0.0021
   240        0.2421             nan     0.1000   -0.0026
   260        0.2237             nan     0.1000   -0.0007
   280        0.2066             nan     0.1000   -0.0021
   300        0.1930             nan     0.1000   -0.0008
   320        0.1769             nan     0.1000   -0.0019
   340        0.1637             nan     0.1000   -0.0007
   360        0.1531             nan     0.1000   -0.0012
   380        0.1458             nan     0.1000   -0.0018
   400        0.1334             nan     0.1000   -0.0006
   420        0.1244             nan     0.1000   -0.0011
   440        0.1179             nan     0.1000   -0.0017
   460        0.1076             nan     0.1000   -0.0016
   480        0.0989             nan     0.1000   -0.0010
   500        0.0925             nan     0.1000   -0.0004
   520        0.0861             nan     0.1000   -0.0003
   540        0.0805             nan     0.1000   -0.0007
   560        0.0756             nan     0.1000   -0.0005
   580        0.0698             nan     0.1000   -0.0006
   600        0.0649             nan     0.1000   -0.0009
   620        0.0607             nan     0.1000   -0.0004
   640        0.0563             nan     0.1000   -0.0004
   660        0.0533             nan     0.1000   -0.0006
   680        0.0504             nan     0.1000   -0.0005
   700        0.0467             nan     0.1000   -0.0003
   720        0.0441             nan     0.1000   -0.0004
   740        0.0415             nan     0.1000   -0.0004
   760        0.0393             nan     0.1000   -0.0002
   780        0.0370             nan     0.1000   -0.0004
   800        0.0352             nan     0.1000   -0.0003
   820        0.0331             nan     0.1000   -0.0003
   840        0.0307             nan     0.1000   -0.0002
   860        0.0289             nan     0.1000   -0.0002
   880        0.0272             nan     0.1000   -0.0001
   900        0.0258             nan     0.1000   -0.0003
   920        0.0245             nan     0.1000   -0.0002
   940        0.0229             nan     0.1000   -0.0001
   960        0.0216             nan     0.1000   -0.0003
   980        0.0200             nan     0.1000   -0.0001
  1000        0.0190             nan     0.1000   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2925             nan     0.1000    0.0398
     2        1.2375             nan     0.1000    0.0213
     3        1.1761             nan     0.1000    0.0245
     4        1.1189             nan     0.1000    0.0195
     5        1.0804             nan     0.1000    0.0157
     6        1.0469             nan     0.1000    0.0161
     7        1.0103             nan     0.1000    0.0169
     8        0.9756             nan     0.1000    0.0138
     9        0.9507             nan     0.1000    0.0081
    10        0.9222             nan     0.1000    0.0060
    20        0.7487             nan     0.1000   -0.0022
    40        0.5715             nan     0.1000   -0.0056
    60        0.4688             nan     0.1000   -0.0027
    80        0.4018             nan     0.1000   -0.0062
   100        0.3448             nan     0.1000   -0.0024
   120        0.2995             nan     0.1000   -0.0020
   140        0.2629             nan     0.1000   -0.0016
   160        0.2294             nan     0.1000   -0.0014
   180        0.1975             nan     0.1000   -0.0010
   200        0.1703             nan     0.1000   -0.0009
   220        0.1509             nan     0.1000   -0.0010
   240        0.1307             nan     0.1000   -0.0021
   260        0.1173             nan     0.1000   -0.0017
   280        0.1015             nan     0.1000   -0.0007
   300        0.0891             nan     0.1000   -0.0007
   320        0.0766             nan     0.1000   -0.0009
   340        0.0685             nan     0.1000   -0.0011
   360        0.0606             nan     0.1000   -0.0006
   380        0.0547             nan     0.1000   -0.0006
   400        0.0488             nan     0.1000   -0.0005
   420        0.0435             nan     0.1000   -0.0004
   440        0.0394             nan     0.1000   -0.0009
   460        0.0349             nan     0.1000   -0.0003
   480        0.0321             nan     0.1000   -0.0003
   500        0.0288             nan     0.1000   -0.0005
   520        0.0255             nan     0.1000   -0.0001
   540        0.0226             nan     0.1000   -0.0002
   560        0.0201             nan     0.1000   -0.0002
   580        0.0182             nan     0.1000   -0.0003
   600        0.0168             nan     0.1000   -0.0002
   620        0.0152             nan     0.1000   -0.0002
   640        0.0135             nan     0.1000   -0.0001
   660        0.0122             nan     0.1000   -0.0001
   680        0.0107             nan     0.1000   -0.0001
   700        0.0097             nan     0.1000   -0.0001
   720        0.0088             nan     0.1000   -0.0001
   740        0.0079             nan     0.1000   -0.0000
   760        0.0073             nan     0.1000   -0.0000
   780        0.0066             nan     0.1000   -0.0001
   800        0.0059             nan     0.1000   -0.0001
   820        0.0053             nan     0.1000   -0.0001
   840        0.0048             nan     0.1000   -0.0000
   860        0.0044             nan     0.1000   -0.0000
   880        0.0039             nan     0.1000   -0.0000
   900        0.0036             nan     0.1000   -0.0000
   920        0.0033             nan     0.1000   -0.0000
   940        0.0029             nan     0.1000   -0.0000
   960        0.0027             nan     0.1000   -0.0000
   980        0.0025             nan     0.1000   -0.0000
  1000        0.0022             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3075             nan     0.1000    0.0295
     2        1.2543             nan     0.1000    0.0232
     3        1.2222             nan     0.1000    0.0181
     4        1.1958             nan     0.1000    0.0099
     5        1.1669             nan     0.1000    0.0150
     6        1.1383             nan     0.1000    0.0130
     7        1.1171             nan     0.1000    0.0100
     8        1.0915             nan     0.1000    0.0081
     9        1.0691             nan     0.1000    0.0060
    10        1.0553             nan     0.1000    0.0036
    20        0.9118             nan     0.1000   -0.0002
    40        0.7810             nan     0.1000   -0.0006
    60        0.7015             nan     0.1000   -0.0014
    80        0.6553             nan     0.1000   -0.0041
   100        0.6171             nan     0.1000   -0.0014
   120        0.5827             nan     0.1000   -0.0017
   140        0.5610             nan     0.1000   -0.0027
   160        0.5420             nan     0.1000   -0.0013
   180        0.5266             nan     0.1000   -0.0024
   200        0.5131             nan     0.1000   -0.0032
   220        0.5045             nan     0.1000   -0.0024
   240        0.4940             nan     0.1000   -0.0010
   260        0.4806             nan     0.1000   -0.0009
   280        0.4705             nan     0.1000   -0.0052
   300        0.4583             nan     0.1000   -0.0019
   320        0.4462             nan     0.1000   -0.0021
   340        0.4362             nan     0.1000   -0.0017
   360        0.4294             nan     0.1000   -0.0032
   380        0.4222             nan     0.1000   -0.0022
   400        0.4152             nan     0.1000   -0.0006
   420        0.4050             nan     0.1000   -0.0030
   440        0.3979             nan     0.1000   -0.0031
   460        0.3903             nan     0.1000   -0.0019
   480        0.3848             nan     0.1000   -0.0022
   500        0.3782             nan     0.1000   -0.0020
   520        0.3690             nan     0.1000   -0.0010
   540        0.3668             nan     0.1000   -0.0016
   560        0.3626             nan     0.1000   -0.0016
   580        0.3595             nan     0.1000   -0.0033
   600        0.3532             nan     0.1000   -0.0015
   620        0.3545             nan     0.1000   -0.0019
   640        0.3459             nan     0.1000   -0.0007
   660        0.3363             nan     0.1000   -0.0029
   680        0.3349             nan     0.1000   -0.0029
   700        0.3285             nan     0.1000   -0.0012
   720        0.3225             nan     0.1000   -0.0023
   740        0.3199             nan     0.1000   -0.0024
   760        0.3141             nan     0.1000   -0.0014
   780        0.3101             nan     0.1000   -0.0012
   800        0.3029             nan     0.1000   -0.0021
   820        0.3000             nan     0.1000   -0.0017
   840        0.2938             nan     0.1000   -0.0029
   860        0.2883             nan     0.1000   -0.0006
   880        0.2839             nan     0.1000   -0.0025
   900        0.2806             nan     0.1000   -0.0011
   920        0.2757             nan     0.1000   -0.0012
   940        0.2703             nan     0.1000   -0.0022
   960        0.2663             nan     0.1000   -0.0020
   980        0.2616             nan     0.1000   -0.0012
  1000        0.2579             nan     0.1000   -0.0010

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3075             nan     0.1000    0.0317
     2        1.2480             nan     0.1000    0.0323
     3        1.1948             nan     0.1000    0.0243
     4        1.1541             nan     0.1000    0.0161
     5        1.1082             nan     0.1000    0.0142
     6        1.0803             nan     0.1000    0.0073
     7        1.0517             nan     0.1000    0.0110
     8        1.0238             nan     0.1000    0.0020
     9        0.9939             nan     0.1000    0.0130
    10        0.9761             nan     0.1000    0.0001
    20        0.8258             nan     0.1000    0.0010
    40        0.6738             nan     0.1000   -0.0006
    60        0.5819             nan     0.1000   -0.0008
    80        0.5198             nan     0.1000   -0.0030
   100        0.4688             nan     0.1000   -0.0032
   120        0.4278             nan     0.1000   -0.0009
   140        0.3833             nan     0.1000   -0.0030
   160        0.3575             nan     0.1000   -0.0049
   180        0.3343             nan     0.1000   -0.0029
   200        0.3112             nan     0.1000   -0.0025
   220        0.2903             nan     0.1000   -0.0020
   240        0.2699             nan     0.1000   -0.0045
   260        0.2512             nan     0.1000   -0.0036
   280        0.2351             nan     0.1000   -0.0013
   300        0.2195             nan     0.1000   -0.0033
   320        0.2026             nan     0.1000   -0.0030
   340        0.1889             nan     0.1000   -0.0020
   360        0.1768             nan     0.1000   -0.0018
   380        0.1647             nan     0.1000   -0.0006
   400        0.1552             nan     0.1000   -0.0011
   420        0.1440             nan     0.1000   -0.0011
   440        0.1360             nan     0.1000   -0.0011
   460        0.1276             nan     0.1000   -0.0016
   480        0.1188             nan     0.1000   -0.0011
   500        0.1123             nan     0.1000   -0.0012
   520        0.1063             nan     0.1000   -0.0008
   540        0.1007             nan     0.1000   -0.0008
   560        0.0937             nan     0.1000   -0.0002
   580        0.0892             nan     0.1000   -0.0006
   600        0.0841             nan     0.1000   -0.0004
   620        0.0783             nan     0.1000   -0.0006
   640        0.0724             nan     0.1000   -0.0007
   660        0.0676             nan     0.1000   -0.0008
   680        0.0632             nan     0.1000   -0.0006
   700        0.0602             nan     0.1000   -0.0007
   720        0.0570             nan     0.1000   -0.0004
   740        0.0542             nan     0.1000   -0.0004
   760        0.0514             nan     0.1000   -0.0007
   780        0.0486             nan     0.1000   -0.0004
   800        0.0461             nan     0.1000   -0.0005
   820        0.0433             nan     0.1000   -0.0002
   840        0.0408             nan     0.1000   -0.0003
   860        0.0389             nan     0.1000   -0.0004
   880        0.0369             nan     0.1000   -0.0004
   900        0.0353             nan     0.1000   -0.0003
   920        0.0329             nan     0.1000   -0.0002
   940        0.0309             nan     0.1000   -0.0002
   960        0.0297             nan     0.1000   -0.0002
   980        0.0276             nan     0.1000   -0.0001
  1000        0.0265             nan     0.1000   -0.0003

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2898             nan     0.1000    0.0369
     2        1.2258             nan     0.1000    0.0215
     3        1.1754             nan     0.1000    0.0161
     4        1.1218             nan     0.1000    0.0181
     5        1.0822             nan     0.1000    0.0134
     6        1.0512             nan     0.1000    0.0077
     7        1.0182             nan     0.1000    0.0131
     8        0.9912             nan     0.1000    0.0054
     9        0.9653             nan     0.1000    0.0044
    10        0.9404             nan     0.1000    0.0081
    20        0.7785             nan     0.1000    0.0018
    40        0.5845             nan     0.1000   -0.0043
    60        0.4805             nan     0.1000   -0.0052
    80        0.4077             nan     0.1000   -0.0010
   100        0.3524             nan     0.1000   -0.0025
   120        0.3058             nan     0.1000   -0.0011
   140        0.2678             nan     0.1000   -0.0028
   160        0.2320             nan     0.1000   -0.0016
   180        0.2011             nan     0.1000   -0.0020
   200        0.1767             nan     0.1000   -0.0015
   220        0.1570             nan     0.1000   -0.0015
   240        0.1401             nan     0.1000   -0.0012
   260        0.1230             nan     0.1000   -0.0013
   280        0.1140             nan     0.1000   -0.0016
   300        0.1038             nan     0.1000   -0.0022
   320        0.0929             nan     0.1000   -0.0008
   340        0.0825             nan     0.1000   -0.0006
   360        0.0754             nan     0.1000   -0.0017
   380        0.0672             nan     0.1000   -0.0002
   400        0.0618             nan     0.1000   -0.0009
   420        0.0546             nan     0.1000   -0.0005
   440        0.0489             nan     0.1000   -0.0001
   460        0.0439             nan     0.1000   -0.0002
   480        0.0398             nan     0.1000   -0.0004
   500        0.0359             nan     0.1000   -0.0002
   520        0.0328             nan     0.1000   -0.0002
   540        0.0301             nan     0.1000   -0.0004
   560        0.0262             nan     0.1000   -0.0003
   580        0.0239             nan     0.1000   -0.0002
   600        0.0217             nan     0.1000   -0.0003
   620        0.0195             nan     0.1000   -0.0002
   640        0.0179             nan     0.1000   -0.0001
   660        0.0162             nan     0.1000   -0.0002
   680        0.0139             nan     0.1000   -0.0001
   700        0.0125             nan     0.1000   -0.0000
   720        0.0113             nan     0.1000   -0.0001
   740        0.0102             nan     0.1000   -0.0001
   760        0.0095             nan     0.1000   -0.0001
   780        0.0087             nan     0.1000   -0.0001
   800        0.0079             nan     0.1000   -0.0001
   820        0.0071             nan     0.1000   -0.0000
   840        0.0064             nan     0.1000   -0.0001
   860        0.0057             nan     0.1000   -0.0001
   880        0.0053             nan     0.1000   -0.0001
   900        0.0047             nan     0.1000   -0.0001
   920        0.0042             nan     0.1000   -0.0001
   940        0.0039             nan     0.1000   -0.0000
   960        0.0035             nan     0.1000   -0.0000
   980        0.0032             nan     0.1000   -0.0000
  1000        0.0029             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3141             nan     0.1000    0.0273
     2        1.2640             nan     0.1000    0.0218
     3        1.2223             nan     0.1000    0.0167
     4        1.1903             nan     0.1000    0.0125
     5        1.1663             nan     0.1000    0.0094
     6        1.1488             nan     0.1000    0.0030
     7        1.1274             nan     0.1000    0.0014
     8        1.1111             nan     0.1000    0.0071
     9        1.0849             nan     0.1000    0.0108
    10        1.0699             nan     0.1000    0.0029
    20        0.9296             nan     0.1000    0.0024
    40        0.7991             nan     0.1000   -0.0012
    60        0.7329             nan     0.1000   -0.0029
    80        0.6721             nan     0.1000   -0.0018
   100        0.6422             nan     0.1000   -0.0040
   120        0.6136             nan     0.1000   -0.0045
   140        0.5922             nan     0.1000   -0.0033
   160        0.5739             nan     0.1000   -0.0029
   180        0.5534             nan     0.1000   -0.0041
   200        0.5341             nan     0.1000   -0.0018
   220        0.5202             nan     0.1000   -0.0027
   240        0.5060             nan     0.1000   -0.0023
   260        0.4957             nan     0.1000   -0.0065
   280        0.4869             nan     0.1000   -0.0027
   300        0.4805             nan     0.1000   -0.0048
   320        0.4622             nan     0.1000   -0.0041
   340        0.4529             nan     0.1000   -0.0036
   360        0.4438             nan     0.1000   -0.0022
   380        0.4311             nan     0.1000   -0.0043
   400        0.4215             nan     0.1000   -0.0056
   420        0.4128             nan     0.1000   -0.0024
   440        0.4027             nan     0.1000   -0.0044
   460        0.3971             nan     0.1000   -0.0025
   480        0.3859             nan     0.1000   -0.0016
   500        0.3798             nan     0.1000   -0.0022
   520        0.3722             nan     0.1000   -0.0022
   540        0.3619             nan     0.1000   -0.0032
   560        0.3542             nan     0.1000   -0.0026
   580        0.3511             nan     0.1000   -0.0012
   600        0.3444             nan     0.1000   -0.0025
   620        0.3354             nan     0.1000   -0.0026
   640        0.3295             nan     0.1000   -0.0007
   660        0.3201             nan     0.1000   -0.0012
   680        0.3187             nan     0.1000   -0.0015
   700        0.3122             nan     0.1000   -0.0026
   720        0.3092             nan     0.1000   -0.0047
   740        0.3045             nan     0.1000   -0.0015
   760        0.2977             nan     0.1000   -0.0020
   780        0.2933             nan     0.1000   -0.0012
   800        0.2882             nan     0.1000   -0.0023
   820        0.2833             nan     0.1000   -0.0036
   840        0.2780             nan     0.1000   -0.0019
   860        0.2750             nan     0.1000   -0.0009
   880        0.2712             nan     0.1000   -0.0025
   900        0.2710             nan     0.1000   -0.0017
   920        0.2674             nan     0.1000   -0.0024
   940        0.2613             nan     0.1000   -0.0007
   960        0.2598             nan     0.1000   -0.0025
   980        0.2572             nan     0.1000   -0.0032
  1000        0.2535             nan     0.1000   -0.0008

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3075             nan     0.1000    0.0293
     2        1.2373             nan     0.1000    0.0252
     3        1.1985             nan     0.1000    0.0110
     4        1.1582             nan     0.1000    0.0135
     5        1.1170             nan     0.1000    0.0156
     6        1.0850             nan     0.1000    0.0070
     7        1.0600             nan     0.1000    0.0068
     8        1.0281             nan     0.1000    0.0060
     9        0.9981             nan     0.1000    0.0066
    10        0.9781             nan     0.1000    0.0052
    20        0.8185             nan     0.1000   -0.0046
    40        0.6773             nan     0.1000   -0.0009
    60        0.5799             nan     0.1000   -0.0024
    80        0.5221             nan     0.1000   -0.0019
   100        0.4732             nan     0.1000   -0.0056
   120        0.4292             nan     0.1000   -0.0025
   140        0.3871             nan     0.1000   -0.0014
   160        0.3588             nan     0.1000   -0.0019
   180        0.3340             nan     0.1000   -0.0029
   200        0.3085             nan     0.1000   -0.0012
   220        0.2854             nan     0.1000   -0.0009
   240        0.2638             nan     0.1000   -0.0013
   260        0.2463             nan     0.1000   -0.0017
   280        0.2333             nan     0.1000   -0.0013
   300        0.2164             nan     0.1000   -0.0025
   320        0.1995             nan     0.1000   -0.0018
   340        0.1857             nan     0.1000   -0.0024
   360        0.1715             nan     0.1000   -0.0005
   380        0.1584             nan     0.1000   -0.0013
   400        0.1485             nan     0.1000   -0.0006
   420        0.1382             nan     0.1000   -0.0009
   440        0.1290             nan     0.1000   -0.0019
   460        0.1202             nan     0.1000   -0.0015
   480        0.1132             nan     0.1000   -0.0002
   500        0.1091             nan     0.1000   -0.0010
   520        0.1016             nan     0.1000   -0.0007
   540        0.0945             nan     0.1000   -0.0011
   560        0.0887             nan     0.1000   -0.0010
   580        0.0809             nan     0.1000   -0.0005
   600        0.0766             nan     0.1000   -0.0007
   620        0.0716             nan     0.1000   -0.0007
   640        0.0674             nan     0.1000   -0.0006
   660        0.0634             nan     0.1000   -0.0006
   680        0.0587             nan     0.1000   -0.0003
   700        0.0553             nan     0.1000   -0.0004
   720        0.0516             nan     0.1000   -0.0006
   740        0.0491             nan     0.1000   -0.0003
   760        0.0466             nan     0.1000   -0.0002
   780        0.0438             nan     0.1000   -0.0005
   800        0.0412             nan     0.1000   -0.0003
   820        0.0388             nan     0.1000   -0.0004
   840        0.0370             nan     0.1000   -0.0004
   860        0.0347             nan     0.1000   -0.0002
   880        0.0330             nan     0.1000   -0.0002
   900        0.0305             nan     0.1000   -0.0003
   920        0.0290             nan     0.1000   -0.0002
   940        0.0269             nan     0.1000   -0.0005
   960        0.0250             nan     0.1000   -0.0003
   980        0.0236             nan     0.1000   -0.0001
  1000        0.0221             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2949             nan     0.1000    0.0324
     2        1.2362             nan     0.1000    0.0225
     3        1.1806             nan     0.1000    0.0221
     4        1.1382             nan     0.1000    0.0125
     5        1.0920             nan     0.1000    0.0170
     6        1.0523             nan     0.1000    0.0067
     7        1.0202             nan     0.1000    0.0146
     8        0.9811             nan     0.1000    0.0126
     9        0.9596             nan     0.1000    0.0006
    10        0.9242             nan     0.1000    0.0121
    20        0.7414             nan     0.1000   -0.0014
    40        0.5740             nan     0.1000   -0.0001
    60        0.4773             nan     0.1000   -0.0026
    80        0.4095             nan     0.1000   -0.0031
   100        0.3535             nan     0.1000   -0.0015
   120        0.3028             nan     0.1000   -0.0026
   140        0.2548             nan     0.1000   -0.0028
   160        0.2276             nan     0.1000   -0.0041
   180        0.2008             nan     0.1000   -0.0021
   200        0.1740             nan     0.1000   -0.0021
   220        0.1572             nan     0.1000   -0.0016
   240        0.1406             nan     0.1000   -0.0011
   260        0.1216             nan     0.1000   -0.0003
   280        0.1099             nan     0.1000   -0.0005
   300        0.0979             nan     0.1000   -0.0012
   320        0.0880             nan     0.1000   -0.0001
   340        0.0805             nan     0.1000   -0.0004
   360        0.0731             nan     0.1000   -0.0009
   380        0.0668             nan     0.1000   -0.0003
   400        0.0604             nan     0.1000   -0.0003
   420        0.0540             nan     0.1000   -0.0005
   440        0.0485             nan     0.1000   -0.0002
   460        0.0425             nan     0.1000   -0.0003
   480        0.0388             nan     0.1000   -0.0003
   500        0.0348             nan     0.1000   -0.0004
   520        0.0310             nan     0.1000   -0.0002
   540        0.0282             nan     0.1000   -0.0002
   560        0.0260             nan     0.1000   -0.0004
   580        0.0231             nan     0.1000   -0.0002
   600        0.0212             nan     0.1000   -0.0001
   620        0.0197             nan     0.1000   -0.0003
   640        0.0175             nan     0.1000   -0.0001
   660        0.0153             nan     0.1000   -0.0002
   680        0.0140             nan     0.1000   -0.0002
   700        0.0124             nan     0.1000   -0.0000
   720        0.0113             nan     0.1000   -0.0000
   740        0.0101             nan     0.1000   -0.0001
   760        0.0091             nan     0.1000   -0.0001
   780        0.0080             nan     0.1000   -0.0001
   800        0.0073             nan     0.1000   -0.0001
   820        0.0066             nan     0.1000   -0.0000
   840        0.0059             nan     0.1000   -0.0000
   860        0.0053             nan     0.1000   -0.0000
   880        0.0049             nan     0.1000   -0.0001
   900        0.0044             nan     0.1000   -0.0000
   920        0.0040             nan     0.1000   -0.0000
   940        0.0036             nan     0.1000   -0.0000
   960        0.0032             nan     0.1000   -0.0000
   980        0.0029             nan     0.1000   -0.0000
  1000        0.0026             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3328             nan     0.1000    0.0085
     2        1.2718             nan     0.1000    0.0286
     3        1.2201             nan     0.1000    0.0211
     4        1.1821             nan     0.1000    0.0190
     5        1.1527             nan     0.1000    0.0145
     6        1.1228             nan     0.1000    0.0111
     7        1.0990             nan     0.1000    0.0083
     8        1.0729             nan     0.1000    0.0108
     9        1.0535             nan     0.1000    0.0073
    10        1.0362             nan     0.1000    0.0084
    20        0.8986             nan     0.1000    0.0020
    40        0.7489             nan     0.1000    0.0002
    60        0.6688             nan     0.1000   -0.0026
    80        0.6253             nan     0.1000   -0.0032
   100        0.5829             nan     0.1000   -0.0053
   120        0.5469             nan     0.1000   -0.0010
   140        0.5137             nan     0.1000   -0.0019
   160        0.4914             nan     0.1000   -0.0011
   180        0.4684             nan     0.1000   -0.0019
   200        0.4528             nan     0.1000   -0.0026
   220        0.4363             nan     0.1000   -0.0016
   240        0.4235             nan     0.1000   -0.0018
   260        0.4092             nan     0.1000   -0.0032
   280        0.3958             nan     0.1000   -0.0039
   300        0.3854             nan     0.1000   -0.0011
   320        0.3693             nan     0.1000   -0.0021
   340        0.3625             nan     0.1000   -0.0036
   360        0.3502             nan     0.1000   -0.0029
   380        0.3442             nan     0.1000   -0.0023
   400        0.3334             nan     0.1000   -0.0036
   420        0.3249             nan     0.1000   -0.0018
   440        0.3190             nan     0.1000   -0.0033
   460        0.3080             nan     0.1000   -0.0020
   480        0.2992             nan     0.1000   -0.0032
   500        0.2903             nan     0.1000   -0.0007
   520        0.2818             nan     0.1000   -0.0026
   540        0.2723             nan     0.1000   -0.0014
   560        0.2651             nan     0.1000   -0.0008
   580        0.2612             nan     0.1000   -0.0013
   600        0.2583             nan     0.1000   -0.0025
   620        0.2496             nan     0.1000   -0.0015
   640        0.2458             nan     0.1000   -0.0036
   660        0.2404             nan     0.1000   -0.0020
   680        0.2325             nan     0.1000   -0.0012
   700        0.2280             nan     0.1000   -0.0012
   720        0.2231             nan     0.1000   -0.0012
   740        0.2167             nan     0.1000   -0.0020
   760        0.2096             nan     0.1000   -0.0016
   780        0.2060             nan     0.1000   -0.0021
   800        0.2014             nan     0.1000   -0.0014
   820        0.1986             nan     0.1000   -0.0014
   840        0.1941             nan     0.1000   -0.0007
   860        0.1879             nan     0.1000   -0.0016
   880        0.1857             nan     0.1000   -0.0017
   900        0.1841             nan     0.1000   -0.0013
   920        0.1812             nan     0.1000   -0.0014
   940        0.1781             nan     0.1000   -0.0007
   960        0.1757             nan     0.1000   -0.0015
   980        0.1710             nan     0.1000   -0.0028
  1000        0.1679             nan     0.1000   -0.0012

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3080             nan     0.1000    0.0306
     2        1.2528             nan     0.1000    0.0209
     3        1.1959             nan     0.1000    0.0232
     4        1.1591             nan     0.1000    0.0061
     5        1.1292             nan     0.1000    0.0054
     6        1.0880             nan     0.1000    0.0153
     7        1.0515             nan     0.1000    0.0195
     8        1.0178             nan     0.1000    0.0140
     9        0.9889             nan     0.1000    0.0095
    10        0.9652             nan     0.1000    0.0025
    20        0.7806             nan     0.1000    0.0034
    40        0.6021             nan     0.1000   -0.0004
    60        0.5102             nan     0.1000   -0.0009
    80        0.4435             nan     0.1000   -0.0021
   100        0.3964             nan     0.1000   -0.0029
   120        0.3521             nan     0.1000   -0.0019
   140        0.3145             nan     0.1000   -0.0014
   160        0.2880             nan     0.1000   -0.0035
   180        0.2644             nan     0.1000   -0.0036
   200        0.2426             nan     0.1000   -0.0025
   220        0.2195             nan     0.1000   -0.0005
   240        0.1986             nan     0.1000   -0.0017
   260        0.1850             nan     0.1000   -0.0027
   280        0.1668             nan     0.1000   -0.0018
   300        0.1550             nan     0.1000   -0.0008
   320        0.1460             nan     0.1000   -0.0011
   340        0.1358             nan     0.1000   -0.0008
   360        0.1249             nan     0.1000   -0.0016
   380        0.1149             nan     0.1000   -0.0007
   400        0.1071             nan     0.1000   -0.0014
   420        0.1002             nan     0.1000   -0.0008
   440        0.0914             nan     0.1000   -0.0007
   460        0.0837             nan     0.1000   -0.0005
   480        0.0796             nan     0.1000   -0.0005
   500        0.0727             nan     0.1000   -0.0006
   520        0.0670             nan     0.1000   -0.0011
   540        0.0626             nan     0.1000   -0.0004
   560        0.0579             nan     0.1000   -0.0005
   580        0.0533             nan     0.1000   -0.0002
   600        0.0498             nan     0.1000   -0.0003
   620        0.0463             nan     0.1000   -0.0002
   640        0.0430             nan     0.1000   -0.0003
   660        0.0398             nan     0.1000   -0.0001
   680        0.0379             nan     0.1000   -0.0003
   700        0.0350             nan     0.1000   -0.0005
   720        0.0330             nan     0.1000   -0.0003
   740        0.0308             nan     0.1000   -0.0001
   760        0.0284             nan     0.1000   -0.0002
   780        0.0268             nan     0.1000   -0.0002
   800        0.0250             nan     0.1000   -0.0002
   820        0.0230             nan     0.1000   -0.0001
   840        0.0215             nan     0.1000   -0.0001
   860        0.0199             nan     0.1000   -0.0002
   880        0.0187             nan     0.1000   -0.0002
   900        0.0174             nan     0.1000   -0.0001
   920        0.0163             nan     0.1000   -0.0001
   940        0.0150             nan     0.1000   -0.0002
   960        0.0142             nan     0.1000   -0.0000
   980        0.0133             nan     0.1000   -0.0001
  1000        0.0128             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3121             nan     0.1000    0.0277
     2        1.2343             nan     0.1000    0.0311
     3        1.1832             nan     0.1000    0.0147
     4        1.1381             nan     0.1000    0.0218
     5        1.0896             nan     0.1000    0.0159
     6        1.0477             nan     0.1000    0.0133
     7        1.0152             nan     0.1000    0.0100
     8        0.9815             nan     0.1000    0.0096
     9        0.9522             nan     0.1000    0.0125
    10        0.9222             nan     0.1000    0.0125
    20        0.7227             nan     0.1000    0.0019
    40        0.5350             nan     0.1000   -0.0050
    60        0.4394             nan     0.1000   -0.0038
    80        0.3617             nan     0.1000   -0.0025
   100        0.2905             nan     0.1000   -0.0015
   120        0.2511             nan     0.1000   -0.0033
   140        0.2202             nan     0.1000   -0.0022
   160        0.1909             nan     0.1000   -0.0025
   180        0.1611             nan     0.1000   -0.0008
   200        0.1369             nan     0.1000   -0.0017
   220        0.1210             nan     0.1000   -0.0006
   240        0.1079             nan     0.1000   -0.0008
   260        0.0957             nan     0.1000   -0.0006
   280        0.0859             nan     0.1000   -0.0014
   300        0.0756             nan     0.1000   -0.0007
   320        0.0683             nan     0.1000   -0.0007
   340        0.0594             nan     0.1000   -0.0000
   360        0.0515             nan     0.1000   -0.0006
   380        0.0451             nan     0.1000   -0.0004
   400        0.0396             nan     0.1000   -0.0004
   420        0.0355             nan     0.1000   -0.0003
   440        0.0321             nan     0.1000   -0.0002
   460        0.0287             nan     0.1000   -0.0003
   480        0.0252             nan     0.1000   -0.0002
   500        0.0220             nan     0.1000   -0.0003
   520        0.0197             nan     0.1000   -0.0002
   540        0.0172             nan     0.1000   -0.0003
   560        0.0155             nan     0.1000   -0.0003
   580        0.0136             nan     0.1000   -0.0002
   600        0.0121             nan     0.1000   -0.0002
   620        0.0108             nan     0.1000   -0.0001
   640        0.0096             nan     0.1000   -0.0001
   660        0.0087             nan     0.1000   -0.0000
   680        0.0075             nan     0.1000   -0.0001
   700        0.0067             nan     0.1000   -0.0001
   720        0.0059             nan     0.1000   -0.0000
   740        0.0053             nan     0.1000   -0.0001
   760        0.0046             nan     0.1000   -0.0000
   780        0.0042             nan     0.1000   -0.0001
   800        0.0038             nan     0.1000   -0.0000
   820        0.0033             nan     0.1000   -0.0000
   840        0.0030             nan     0.1000   -0.0000
   860        0.0026             nan     0.1000   -0.0000
   880        0.0023             nan     0.1000   -0.0000
   900        0.0020             nan     0.1000   -0.0000
   920        0.0017             nan     0.1000   -0.0000
   940        0.0015             nan     0.1000   -0.0000
   960        0.0013             nan     0.1000   -0.0000
   980        0.0012             nan     0.1000   -0.0000
  1000        0.0011             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3287             nan     0.1000    0.0143
     2        1.2671             nan     0.1000    0.0317
     3        1.2269             nan     0.1000    0.0178
     4        1.1769             nan     0.1000    0.0250
     5        1.1461             nan     0.1000    0.0118
     6        1.1078             nan     0.1000    0.0164
     7        1.0776             nan     0.1000    0.0040
     8        1.0489             nan     0.1000    0.0140
     9        1.0223             nan     0.1000    0.0066
    10        0.9986             nan     0.1000    0.0093
    20        0.8599             nan     0.1000    0.0042
    40        0.7338             nan     0.1000    0.0004
    60        0.6497             nan     0.1000   -0.0008
    80        0.5910             nan     0.1000   -0.0002
   100        0.5580             nan     0.1000   -0.0009
   120        0.5198             nan     0.1000   -0.0017
   140        0.4901             nan     0.1000   -0.0047
   160        0.4651             nan     0.1000   -0.0018
   180        0.4504             nan     0.1000   -0.0026
   200        0.4380             nan     0.1000   -0.0019
   220        0.4170             nan     0.1000   -0.0018
   240        0.4046             nan     0.1000    0.0001
   260        0.3940             nan     0.1000   -0.0025
   280        0.3809             nan     0.1000   -0.0013
   300        0.3696             nan     0.1000   -0.0025
   320        0.3583             nan     0.1000   -0.0028
   340        0.3459             nan     0.1000   -0.0013
   360        0.3373             nan     0.1000   -0.0015
   380        0.3301             nan     0.1000   -0.0021
   400        0.3205             nan     0.1000   -0.0012
   420        0.3094             nan     0.1000   -0.0006
   440        0.2979             nan     0.1000   -0.0011
   460        0.2891             nan     0.1000   -0.0017
   480        0.2829             nan     0.1000   -0.0015
   500        0.2751             nan     0.1000   -0.0027
   520        0.2668             nan     0.1000   -0.0012
   540        0.2572             nan     0.1000   -0.0015
   560        0.2520             nan     0.1000   -0.0020
   580        0.2445             nan     0.1000   -0.0017
   600        0.2384             nan     0.1000   -0.0025
   620        0.2312             nan     0.1000   -0.0009
   640        0.2264             nan     0.1000   -0.0008
   660        0.2200             nan     0.1000   -0.0018
   680        0.2124             nan     0.1000   -0.0028
   700        0.2052             nan     0.1000   -0.0010
   720        0.2019             nan     0.1000   -0.0003
   740        0.2002             nan     0.1000   -0.0017
   760        0.1948             nan     0.1000   -0.0003
   780        0.1899             nan     0.1000   -0.0012
   800        0.1856             nan     0.1000   -0.0011
   820        0.1804             nan     0.1000   -0.0012
   840        0.1764             nan     0.1000   -0.0022
   860        0.1714             nan     0.1000   -0.0006
   880        0.1669             nan     0.1000   -0.0006
   900        0.1636             nan     0.1000   -0.0008
   920        0.1601             nan     0.1000   -0.0009
   940        0.1572             nan     0.1000   -0.0012
   960        0.1518             nan     0.1000   -0.0007
   980        0.1494             nan     0.1000   -0.0004
  1000        0.1470             nan     0.1000   -0.0007

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2964             nan     0.1000    0.0345
     2        1.2215             nan     0.1000    0.0323
     3        1.1605             nan     0.1000    0.0279
     4        1.1122             nan     0.1000    0.0161
     5        1.0730             nan     0.1000    0.0159
     6        1.0280             nan     0.1000    0.0167
     7        0.9875             nan     0.1000    0.0127
     8        0.9634             nan     0.1000    0.0048
     9        0.9409             nan     0.1000    0.0015
    10        0.9106             nan     0.1000    0.0092
    20        0.7494             nan     0.1000   -0.0030
    40        0.5873             nan     0.1000    0.0015
    60        0.5183             nan     0.1000   -0.0075
    80        0.4520             nan     0.1000   -0.0005
   100        0.3996             nan     0.1000   -0.0028
   120        0.3665             nan     0.1000   -0.0039
   140        0.3209             nan     0.1000   -0.0027
   160        0.2808             nan     0.1000   -0.0019
   180        0.2510             nan     0.1000   -0.0022
   200        0.2252             nan     0.1000   -0.0021
   220        0.2060             nan     0.1000   -0.0037
   240        0.1873             nan     0.1000   -0.0024
   260        0.1748             nan     0.1000   -0.0010
   280        0.1621             nan     0.1000   -0.0012
   300        0.1443             nan     0.1000   -0.0016
   320        0.1336             nan     0.1000   -0.0010
   340        0.1214             nan     0.1000   -0.0008
   360        0.1116             nan     0.1000   -0.0007
   380        0.1019             nan     0.1000   -0.0007
   400        0.0922             nan     0.1000   -0.0014
   420        0.0852             nan     0.1000   -0.0007
   440        0.0786             nan     0.1000   -0.0006
   460        0.0727             nan     0.1000   -0.0003
   480        0.0676             nan     0.1000   -0.0006
   500        0.0627             nan     0.1000   -0.0007
   520        0.0580             nan     0.1000   -0.0003
   540        0.0537             nan     0.1000   -0.0005
   560        0.0492             nan     0.1000   -0.0002
   580        0.0448             nan     0.1000   -0.0001
   600        0.0421             nan     0.1000   -0.0006
   620        0.0399             nan     0.1000   -0.0006
   640        0.0361             nan     0.1000   -0.0003
   660        0.0337             nan     0.1000   -0.0004
   680        0.0318             nan     0.1000   -0.0003
   700        0.0291             nan     0.1000   -0.0002
   720        0.0267             nan     0.1000   -0.0002
   740        0.0250             nan     0.1000   -0.0003
   760        0.0228             nan     0.1000   -0.0001
   780        0.0205             nan     0.1000   -0.0000
   800        0.0194             nan     0.1000   -0.0001
   820        0.0180             nan     0.1000   -0.0002
   840        0.0169             nan     0.1000   -0.0002
   860        0.0155             nan     0.1000   -0.0001
   880        0.0145             nan     0.1000   -0.0001
   900        0.0137             nan     0.1000   -0.0001
   920        0.0128             nan     0.1000   -0.0002
   940        0.0120             nan     0.1000   -0.0002
   960        0.0111             nan     0.1000   -0.0002
   980        0.0104             nan     0.1000   -0.0001
  1000        0.0096             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2936             nan     0.1000    0.0348
     2        1.2229             nan     0.1000    0.0341
     3        1.1544             nan     0.1000    0.0341
     4        1.1147             nan     0.1000    0.0148
     5        1.0676             nan     0.1000    0.0138
     6        1.0302             nan     0.1000    0.0133
     7        0.9869             nan     0.1000    0.0184
     8        0.9489             nan     0.1000    0.0136
     9        0.9226             nan     0.1000    0.0047
    10        0.8979             nan     0.1000    0.0079
    20        0.7356             nan     0.1000   -0.0009
    40        0.5435             nan     0.1000   -0.0042
    60        0.4321             nan     0.1000   -0.0022
    80        0.3730             nan     0.1000   -0.0034
   100        0.3028             nan     0.1000   -0.0037
   120        0.2513             nan     0.1000   -0.0029
   140        0.2226             nan     0.1000   -0.0020
   160        0.1866             nan     0.1000   -0.0022
   180        0.1572             nan     0.1000   -0.0016
   200        0.1362             nan     0.1000   -0.0018
   220        0.1179             nan     0.1000   -0.0004
   240        0.1044             nan     0.1000   -0.0010
   260        0.0899             nan     0.1000   -0.0004
   280        0.0812             nan     0.1000   -0.0013
   300        0.0716             nan     0.1000   -0.0008
   320        0.0625             nan     0.1000   -0.0006
   340        0.0556             nan     0.1000   -0.0007
   360        0.0487             nan     0.1000   -0.0004
   380        0.0423             nan     0.1000   -0.0003
   400        0.0379             nan     0.1000   -0.0001
   420        0.0329             nan     0.1000   -0.0002
   440        0.0297             nan     0.1000   -0.0003
   460        0.0263             nan     0.1000   -0.0003
   480        0.0232             nan     0.1000   -0.0003
   500        0.0209             nan     0.1000   -0.0004
   520        0.0184             nan     0.1000   -0.0001
   540        0.0164             nan     0.1000   -0.0001
   560        0.0146             nan     0.1000   -0.0001
   580        0.0128             nan     0.1000   -0.0001
   600        0.0113             nan     0.1000   -0.0002
   620        0.0098             nan     0.1000   -0.0000
   640        0.0086             nan     0.1000   -0.0001
   660        0.0076             nan     0.1000   -0.0000
   680        0.0067             nan     0.1000   -0.0001
   700        0.0061             nan     0.1000   -0.0000
   720        0.0054             nan     0.1000   -0.0000
   740        0.0050             nan     0.1000   -0.0000
   760        0.0043             nan     0.1000   -0.0001
   780        0.0038             nan     0.1000   -0.0000
   800        0.0033             nan     0.1000   -0.0000
   820        0.0029             nan     0.1000   -0.0000
   840        0.0026             nan     0.1000   -0.0000
   860        0.0024             nan     0.1000   -0.0000
   880        0.0021             nan     0.1000   -0.0000
   900        0.0019             nan     0.1000   -0.0000
   920        0.0017             nan     0.1000   -0.0000
   940        0.0015             nan     0.1000   -0.0000
   960        0.0013             nan     0.1000   -0.0000
   980        0.0012             nan     0.1000   -0.0000
  1000        0.0011             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3352             nan     0.1000    0.0202
     2        1.2887             nan     0.1000    0.0159
     3        1.2448             nan     0.1000    0.0192
     4        1.2025             nan     0.1000    0.0196
     5        1.1617             nan     0.1000    0.0176
     6        1.1263             nan     0.1000    0.0132
     7        1.0972             nan     0.1000    0.0095
     8        1.0800             nan     0.1000    0.0042
     9        1.0650             nan     0.1000    0.0031
    10        1.0401             nan     0.1000    0.0104
    20        0.9024             nan     0.1000    0.0024
    40        0.7718             nan     0.1000   -0.0016
    60        0.7022             nan     0.1000   -0.0006
    80        0.6534             nan     0.1000    0.0008
   100        0.6091             nan     0.1000   -0.0025
   120        0.5823             nan     0.1000   -0.0021
   140        0.5583             nan     0.1000   -0.0028
   160        0.5339             nan     0.1000   -0.0022
   180        0.5165             nan     0.1000   -0.0019
   200        0.5052             nan     0.1000   -0.0022
   220        0.4851             nan     0.1000   -0.0026
   240        0.4638             nan     0.1000   -0.0003
   260        0.4532             nan     0.1000   -0.0036
   280        0.4391             nan     0.1000   -0.0023
   300        0.4315             nan     0.1000   -0.0027
   320        0.4195             nan     0.1000   -0.0017
   340        0.4078             nan     0.1000   -0.0027
   360        0.3935             nan     0.1000   -0.0014
   380        0.3843             nan     0.1000   -0.0030
   400        0.3776             nan     0.1000   -0.0014
   420        0.3728             nan     0.1000   -0.0024
   440        0.3607             nan     0.1000   -0.0013
   460        0.3532             nan     0.1000   -0.0029
   480        0.3472             nan     0.1000   -0.0030
   500        0.3393             nan     0.1000   -0.0067
   520        0.3297             nan     0.1000   -0.0031
   540        0.3220             nan     0.1000   -0.0019
   560        0.3191             nan     0.1000   -0.0025
   580        0.3117             nan     0.1000   -0.0029
   600        0.3068             nan     0.1000   -0.0014
   620        0.2982             nan     0.1000   -0.0030
   640        0.2929             nan     0.1000   -0.0018
   660        0.2884             nan     0.1000   -0.0015
   680        0.2829             nan     0.1000   -0.0024
   700        0.2752             nan     0.1000   -0.0026
   720        0.2708             nan     0.1000   -0.0010
   740        0.2664             nan     0.1000   -0.0028
   760        0.2618             nan     0.1000   -0.0042
   780        0.2581             nan     0.1000   -0.0020
   800        0.2512             nan     0.1000   -0.0007
   820        0.2492             nan     0.1000   -0.0012
   840        0.2416             nan     0.1000   -0.0028
   860        0.2360             nan     0.1000   -0.0009
   880        0.2328             nan     0.1000   -0.0015
   900        0.2281             nan     0.1000   -0.0022
   920        0.2237             nan     0.1000   -0.0009
   940        0.2197             nan     0.1000   -0.0006
   960        0.2168             nan     0.1000   -0.0006
   980        0.2112             nan     0.1000   -0.0010
  1000        0.2087             nan     0.1000   -0.0015

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3078             nan     0.1000    0.0273
     2        1.2437             nan     0.1000    0.0251
     3        1.1863             nan     0.1000    0.0227
     4        1.1416             nan     0.1000    0.0164
     5        1.1120             nan     0.1000    0.0076
     6        1.0698             nan     0.1000    0.0198
     7        1.0329             nan     0.1000    0.0119
     8        0.9981             nan     0.1000    0.0116
     9        0.9744             nan     0.1000    0.0095
    10        0.9501             nan     0.1000    0.0055
    20        0.7746             nan     0.1000    0.0055
    40        0.6289             nan     0.1000   -0.0044
    60        0.5418             nan     0.1000   -0.0016
    80        0.4754             nan     0.1000   -0.0014
   100        0.4165             nan     0.1000   -0.0018
   120        0.3746             nan     0.1000   -0.0010
   140        0.3397             nan     0.1000   -0.0022
   160        0.3142             nan     0.1000   -0.0028
   180        0.2865             nan     0.1000   -0.0012
   200        0.2598             nan     0.1000   -0.0008
   220        0.2446             nan     0.1000   -0.0031
   240        0.2241             nan     0.1000   -0.0032
   260        0.2106             nan     0.1000   -0.0020
   280        0.1951             nan     0.1000   -0.0018
   300        0.1792             nan     0.1000   -0.0012
   320        0.1687             nan     0.1000   -0.0011
   340        0.1559             nan     0.1000   -0.0013
   360        0.1453             nan     0.1000   -0.0013
   380        0.1350             nan     0.1000   -0.0014
   400        0.1263             nan     0.1000   -0.0016
   420        0.1179             nan     0.1000   -0.0015
   440        0.1066             nan     0.1000   -0.0005
   460        0.1000             nan     0.1000   -0.0013
   480        0.0940             nan     0.1000   -0.0009
   500        0.0875             nan     0.1000   -0.0004
   520        0.0813             nan     0.1000   -0.0003
   540        0.0762             nan     0.1000   -0.0006
   560        0.0704             nan     0.1000   -0.0004
   580        0.0649             nan     0.1000   -0.0005
   600        0.0604             nan     0.1000   -0.0003
   620        0.0559             nan     0.1000   -0.0005
   640        0.0518             nan     0.1000   -0.0006
   660        0.0489             nan     0.1000   -0.0006
   680        0.0459             nan     0.1000   -0.0007
   700        0.0418             nan     0.1000   -0.0002
   720        0.0391             nan     0.1000   -0.0005
   740        0.0365             nan     0.1000   -0.0004
   760        0.0336             nan     0.1000   -0.0002
   780        0.0316             nan     0.1000   -0.0002
   800        0.0289             nan     0.1000   -0.0003
   820        0.0275             nan     0.1000   -0.0002
   840        0.0257             nan     0.1000   -0.0005
   860        0.0242             nan     0.1000   -0.0001
   880        0.0224             nan     0.1000   -0.0002
   900        0.0215             nan     0.1000   -0.0003
   920        0.0204             nan     0.1000   -0.0002
   940        0.0190             nan     0.1000   -0.0001
   960        0.0177             nan     0.1000   -0.0001
   980        0.0166             nan     0.1000   -0.0000
  1000        0.0155             nan     0.1000   -0.0001

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.2861             nan     0.1000    0.0386
     2        1.2251             nan     0.1000    0.0254
     3        1.1612             nan     0.1000    0.0203
     4        1.1170             nan     0.1000    0.0155
     5        1.0720             nan     0.1000    0.0095
     6        1.0251             nan     0.1000    0.0194
     7        0.9906             nan     0.1000    0.0134
     8        0.9598             nan     0.1000    0.0104
     9        0.9291             nan     0.1000    0.0110
    10        0.8994             nan     0.1000    0.0121
    20        0.7261             nan     0.1000    0.0033
    40        0.5595             nan     0.1000   -0.0021
    60        0.4462             nan     0.1000   -0.0020
    80        0.3755             nan     0.1000   -0.0020
   100        0.3206             nan     0.1000   -0.0057
   120        0.2778             nan     0.1000   -0.0007
   140        0.2350             nan     0.1000   -0.0022
   160        0.2026             nan     0.1000   -0.0026
   180        0.1767             nan     0.1000   -0.0018
   200        0.1555             nan     0.1000    0.0000
   220        0.1366             nan     0.1000   -0.0020
   240        0.1210             nan     0.1000   -0.0019
   260        0.1058             nan     0.1000   -0.0009
   280        0.0946             nan     0.1000   -0.0014
   300        0.0830             nan     0.1000   -0.0011
   320        0.0733             nan     0.1000   -0.0010
   340        0.0651             nan     0.1000   -0.0006
   360        0.0579             nan     0.1000   -0.0003
   380        0.0503             nan     0.1000   -0.0005
   400        0.0447             nan     0.1000   -0.0003
   420        0.0396             nan     0.1000   -0.0004
   440        0.0350             nan     0.1000   -0.0004
   460        0.0314             nan     0.1000   -0.0002
   480        0.0272             nan     0.1000   -0.0002
   500        0.0243             nan     0.1000   -0.0002
   520        0.0216             nan     0.1000   -0.0002
   540        0.0194             nan     0.1000   -0.0001
   560        0.0174             nan     0.1000   -0.0002
   580        0.0155             nan     0.1000   -0.0002
   600        0.0138             nan     0.1000   -0.0002
   620        0.0122             nan     0.1000   -0.0001
   640        0.0111             nan     0.1000   -0.0001
   660        0.0098             nan     0.1000   -0.0001
   680        0.0087             nan     0.1000   -0.0001
   700        0.0077             nan     0.1000   -0.0001
   720        0.0069             nan     0.1000   -0.0001
   740        0.0062             nan     0.1000   -0.0001
   760        0.0056             nan     0.1000   -0.0000
   780        0.0049             nan     0.1000   -0.0000
   800        0.0044             nan     0.1000   -0.0000
   820        0.0039             nan     0.1000   -0.0000
   840        0.0036             nan     0.1000   -0.0000
   860        0.0031             nan     0.1000   -0.0000
   880        0.0028             nan     0.1000   -0.0001
   900        0.0025             nan     0.1000   -0.0000
   920        0.0022             nan     0.1000   -0.0000
   940        0.0020             nan     0.1000   -0.0000
   960        0.0017             nan     0.1000   -0.0000
   980        0.0015             nan     0.1000   -0.0000
  1000        0.0014             nan     0.1000   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.3172             nan     0.1000    0.0294
     2        1.2622             nan     0.1000    0.0242
     3        1.2319             nan     0.1000    0.0095
     4        1.1877             nan     0.1000    0.0166
     5        1.1558             nan     0.1000    0.0098
     6        1.1273             nan     0.1000    0.0111
     7        1.1137             nan     0.1000    0.0028
     8        1.0861             nan     0.1000    0.0088
     9        1.0706             nan     0.1000    0.0022
    10        1.0499             nan     0.1000    0.0051
    20        0.9214             nan     0.1000    0.0011
    40        0.7920             nan     0.1000    0.0001
    60        0.7177             nan     0.1000   -0.0020
    80        0.6780             nan     0.1000   -0.0003
   100        0.6489             nan     0.1000   -0.0023</code></pre>
</div>
<div class="sourceCode cell-code" id="cb286"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb286-1"><a href="#cb286-1" aria-hidden="true" tabindex="-1"></a>mod.gbm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Stochastic Gradient Boosting 

213 samples
 13 predictor
  2 classes: 'low', 'high' 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 5 times) 
Summary of sample sizes: 170, 170, 171, 170, 171, 170, ... 
Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec     
  1                   100     0.8814638  0.7504211  0.8363768
  1                   500     0.8523699  0.7216842  0.8034783
  1                  1000     0.8349641  0.7009474  0.7913043
  2                   100     0.8702639  0.7461053  0.8329710
  2                   500     0.8345278  0.7189474  0.7931884
  2                  1000     0.8204287  0.7069474  0.7810870
  3                   100     0.8608162  0.7501053  0.8190580
  3                   500     0.8272113  0.7147368  0.8054348
  3                  1000     0.8182967  0.6945263  0.7985507

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using the largest value.
The final values used for the model were n.trees = 100, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 10.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb288"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb288-1"><a href="#cb288-1" aria-hidden="true" tabindex="-1"></a>pred.gbm<span class="ot">&lt;-</span><span class="fu">predict</span>(mod.gbm, <span class="at">newdata=</span>dt_test, <span class="at">type=</span><span class="st">"prob"</span>)</span>
<span id="cb288-2"><a href="#cb288-2" aria-hidden="true" tabindex="-1"></a>pred.gbm.class<span class="ot">&lt;-</span><span class="fu">predict</span>(mod.gbm, <span class="at">newdata=</span>dt_test)</span>
<span id="cb288-3"><a href="#cb288-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb288-4"><a href="#cb288-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(pred.gbm.class, dt_test<span class="sc">$</span>output, <span class="at">positive=</span><span class="st">"high"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction low high
      low   30    5
      high  11   44
                                          
               Accuracy : 0.8222          
                 95% CI : (0.7274, 0.8948)
    No Information Rate : 0.5444          
    P-Value [Acc &gt; NIR] : 2.84e-08        
                                          
                  Kappa : 0.6373          
                                          
 Mcnemar's Test P-Value : 0.2113          
                                          
            Sensitivity : 0.8980          
            Specificity : 0.7317          
         Pos Pred Value : 0.8000          
         Neg Pred Value : 0.8571          
             Prevalence : 0.5444          
         Detection Rate : 0.4889          
   Detection Prevalence : 0.6111          
      Balanced Accuracy : 0.8148          
                                          
       'Positive' Class : high            
                                          </code></pre>
</div>
</div>
</section>
</section>
<section id="wykresy" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="wykresy"><span class="header-section-number">2.2</span> Wykresy</h2>
<ul>
<li>Rozkład grupy wiekowej w zależności od płci</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb290"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb290-1"><a href="#cb290-1" aria-hidden="true" tabindex="-1"></a>heart2 <span class="ot">&lt;-</span> heart <span class="sc">%&gt;%</span></span>
<span id="cb290-2"><a href="#cb290-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">grupa_wiekowa =</span> <span class="fu">cut</span>(age, <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">41</span>, <span class="dv">51</span>, <span class="dv">61</span>, <span class="cn">Inf</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>), <span class="at">right =</span> <span class="cn">FALSE</span>))</span>
<span id="cb290-3"><a href="#cb290-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb290-4"><a href="#cb290-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb290-5"><a href="#cb290-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(heart2, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">factor</span>(grupa_wiekowa), <span class="at">fill =</span> sex)) <span class="sc">+</span></span>
<span id="cb290-6"><a href="#cb290-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">position =</span> <span class="st">"dodge"</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="fu">aes</span>(<span class="at">stat =</span> <span class="st">"count"</span>)) <span class="sc">+</span></span>
<span id="cb290-7"><a href="#cb290-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> ..count..), <span class="at">stat =</span> <span class="st">"count"</span>, <span class="at">position =</span> <span class="fu">position_dodge</span>(<span class="at">width =</span> <span class="fl">0.9</span>), </span>
<span id="cb290-8"><a href="#cb290-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">vjust =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb290-9"><a href="#cb290-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"pink"</span>,<span class="st">"lightblue"</span>)) <span class="sc">+</span></span>
<span id="cb290-10"><a href="#cb290-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Grupa wiekowa"</span>, <span class="at">y =</span> <span class="st">"Liczba osób"</span>, <span class="at">fill =</span> <span class="st">"Płeć"</span>) <span class="sc">+</span></span>
<span id="cb290-11"><a href="#cb290-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_bar(position = "dodge", color = "black", aes(stat = "count")):
Ignoring unknown aesthetics: stat</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.
ℹ Please use `after_stat(count)` instead.</code></pre>
</div>
<div class="cell-output-display">
<p><img src="projekt_dobry_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Pozioma oś X przedstawia grupę wiekową, natomiast oś Y reprezentuje liczbę osób z odpowiadającymi im kolorami z legendy, które oznaczają następująco: różowy = 0 dla kobiet, niebieski = 1 dla mężczyzn.</p>
<p>Możemy zauważyć, że w [??trzeciej grupie wiekowej???] występuje największy udział mężczyzn, ich liczba wynosi 94. Kobiet również najwięcej znajduje się w tej grupie, natomiast tylko o jedną mniej mamy w grupie czwartej.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>